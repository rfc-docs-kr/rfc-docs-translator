"hash": |-
  7532ffea8e6c9ec44171890ef4d7571c492ba965d751a091abd00ca8f1925cd5
"type": |-
  Content
"comment": !!null |-
  null
"original": |2-
     The sending of client and server requests can be asynchronous events.
     To avoid deadlock situations, both client and server MUST be able to
     send and receive requests simultaneously.  As an RTSP response may be
     queued up for transmission, reception or processing behind the peer
     RTSP agent's own requests, all RTSP agents are required to have a
     certain capability of handling outstanding messages.  A potential
     issue is that outstanding requests may time out despite being
     processed by the peer; this can be due to the response being caught
     in the queue behind a number of requests that the RTSP agent is
     processing but that take some time to complete.  To avoid this
     problem, an RTSP agent should buffer incoming messages locally so
     that any response messages can be processed immediately upon
     reception.  If responses are separated from requests and directly
     forwarded for processing, not only can the result be used
     immediately, the state associated with that outstanding request can
     also be released.  However, buffering a number of requests on the
     receiving RTSP agent consumes resources and enables a resource
     exhaustion attack on the agent.  Therefore, this buffer should be
     limited so that an unreasonable number of requests or total message
     size is not allowed to consume the receiving agent's resources.  In
     most APIs, having the receiving agent stop reading from the TCP
     socket will result in TCP's window being clamped, thus forcing the
     buffering onto the sending agent when the load is larger than
     expected.  However, as both RTSP message sizes and frequency may be
     changed in the future by protocol extensions, an agent should be
     careful about taking harsher measurements against a potential attack.
     When under attack, an RTSP agent can close TCP connections and
     release state associated with that TCP connection.
"fixed": |-
  The sending of client and server requests can be asynchronous events. To avoid deadlock situations, both client and server MUST be able to send and receive requests simultaneously.  As an RTSP response may be queued up for transmission, reception or processing behind the peer RTSP agent's own requests, all RTSP agents are required to have a certain capability of handling outstanding messages.  A potential issue is that outstanding requests may time out despite being processed by the peer; this can be due to the response being caught in the queue behind a number of requests that the RTSP agent is processing but that take some time to complete.  To avoid this problem, an RTSP agent should buffer incoming messages locally so that any response messages can be processed immediately upon reception.  If responses are separated from requests and directly forwarded for processing, not only can the result be used immediately, the state associated with that outstanding request can also be released.  However, buffering a number of requests on the receiving RTSP agent consumes resources and enables a resource exhaustion attack on the agent.  Therefore, this buffer should be limited so that an unreasonable number of requests or total message size is not allowed to consume the receiving agent's resources.  In most APIs, having the receiving agent stop reading from the TCP socket will result in TCP's window being clamped, thus forcing the buffering onto the sending agent when the load is larger than expected.  However, as both RTSP message sizes and frequency may be changed in the future by protocol extensions, an agent should be careful about taking harsher measurements against a potential attack. When under attack, an RTSP agent can close TCP connections and release state associated with that TCP connection.
"ko": |-
  클라이언트 및 서버 요청 전송은 비동기 이벤트일 수 있습니다. 교착 상태를 방지하려면 클라이언트와 서버 모두 동시에 요청을 보내고 받을 수 있어야 합니다. RTSP 응답은 피어 RTSP 에이전트 자체 요청 뒤에 전송, 수신 또는 처리를 위해 대기열에 추가될 수 있으므로 모든 RTSP 에이전트는 처리되지 않은 메시지를 처리하는 특정 기능을 보유해야 합니다. 잠재적인 문제는 피어가 처리했음에도 불구하고 처리되지 않은 요청이 시간 초과될 수 있다는 것입니다. 이는 RTSP 에이전트가 처리 중이지만 완료하는 데 시간이 걸리는 여러 요청 뒤의 대기열에 응답이 있기 때문일 수 있습니다. 이 문제를 방지하려면 RTSP 에이전트는 모든 응답 메시지가 수신 즉시 처리될 수 있도록 들어오는 메시지를 로컬로 버퍼링해야 합니다. 응답이 요청과 분리되어 처리를 위해 직접 전달되는 경우 결과를 즉시 사용할 수 있을 뿐만 아니라 해당 미해결 요청과 관련된 상태도 해제될 수 있습니다. 그러나 수신 RTSP 에이전트에서 여러 요청을 버퍼링하면 리소스가 소비되고 에이전트에 대한 리소스 고갈 공격이 가능해집니다. 따라서 이 버퍼는 불합리한 요청 수나 전체 메시지 크기가 수신 에이전트의 자원을 소비하는 것을 허용하지 않도록 제한되어야 합니다. 대부분의 API에서 수신 에이전트가 TCP 소켓 읽기를 중지하면 TCP 창이 고정되어 부하가 예상보다 클 때 송신 에이전트에 버퍼링이 강제로 적용됩니다. 그러나 RTSP 메시지 크기와 빈도는 향후 프로토콜 확장에 따라 변경될 수 있으므로 에이전트는 잠재적인 공격에 대해 더 엄격한 측정을 수행하는 데 주의해야 합니다. 공격을 받으면 RTSP 에이전트는 TCP 연결을 닫고 해당 TCP 연결과 관련된 상태를 해제할 수 있습니다.
