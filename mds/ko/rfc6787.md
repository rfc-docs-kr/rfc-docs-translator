

```text
Internet Engineering Task Force (IETF)                        D. Burnett
Request for Comments: 6787                                         Voxeo
Category: Standards Track                                  S. Shanmugham
ISSN: 2070-1721                                      Cisco Systems, Inc.
                                                           November 2012

           Media Resource Control Protocol Version 2 (MRCPv2)
```

---
# **Abstract**

미디어 리소스 제어 프로토콜 버전 2\(MRCPv2\)를 사용하면 클라이언트 호스트가 네트워크의 서버에 있는 음성 합성기, 인식기, 검증기 및 식별자와 같은 미디어 서비스 리소스를 제어할 수 있습니다. MRCPv2는 "독립형" 프로토콜이 아닙니다. SIP\(Session Initiation Protocol\)와 같은 다른 프로토콜을 사용하여 MRCPv2 클라이언트와 서버를 조정하고 이들 간의 세션을 관리하고 SDP\(Session Description Protocol\)를 사용하여 기능을 설명, 검색 및 교환합니다. 또한 SIP 및 SDP를 사용하여 미디어 소스 또는 싱크와 미디어 서버 간의 미디어 세션 및 관련 매개변수를 설정합니다. 이 작업이 완료되면 MRCPv2 교환이 위에서 설정한 제어 세션을 통해 작동하여 클라이언트가 음성 리소스 서버에서 미디어 처리 리소스를 제어할 수 있습니다.

---
# **Status of This Memo**

이것은 인터넷 표준 추적 문서입니다.

이 문서는 IETF\(Internet Engineering Task Force\)의 산물입니다. 이는 IETF 커뮤니티의 합의를 나타냅니다. 공개 검토를 받았으며 IESG\(Internet Engineering Steering Group\)의 게시 승인을 받았습니다. 인터넷 표준에 대한 추가 정보는 RFC 5741의 섹션 2에서 확인할 수 있습니다.

이 문서의 현재 상태, 오류 사항, 이 문서에 대한 피드백을 제공하는 방법에 대한 정보는 http://www.rfc-editor.org/info/rfc6787에서 확인할 수 있습니다.

---
# **Copyright Notice**

Copyright \(c\) 2012 IETF Trust 및 문서 작성자로 식별된 사람. 판권 소유.

이 문서는 BCP 78 및 IETF Trust의 IETF 문서와 관련된 법적 조항\(http://trustee.ietf.org/license-info\)의 적용을 받으며, 이 문서가 발행된 날짜에 효력이 발생합니다. 이 문서를 검토하세요.

주의해서, 이 문서와 관련된 귀하의 권리와 제한 사항을 설명합니다. 이 문서에서 추출한 코드 구성 요소에는 신탁 법률 조항의 섹션 4.e에 설명된 대로 단순화된 BSD 라이선스 텍스트가 포함되어야 하며 단순화된 BSD 라이선스에 설명된 대로 보증 없이 제공됩니다.

이 문서에는 2008년 11월 10일 이전에 공개되거나 공개된 IETF 문서 또는 IETF 기여의 자료가 포함될 수 있습니다. 이 자료 중 일부의 저작권을 관리하는 사람은 IETF Trust에 해당 자료의 수정을 허용할 권한을 부여하지 않았을 수 있습니다. IETF 표준 프로세스 외부. 해당 자료의 저작권을 관리하는 사람으로부터 적절한 라이센스를 얻지 않은 경우 이 문서는 IETF 표준 프로세스 외부에서 수정될 수 없으며 해당 문서의 파생물은 형식을 지정하는 경우를 제외하고 IETF 표준 프로세스 외부에서 생성될 수 없습니다. RFC로 출판하거나 영어 이외의 언어로 번역합니다.

---
# **Table of Contents**

```text
   1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . .   8
   2.  Document Conventions  . . . . . . . . . . . . . . . . . . . .   9
     2.1.   Definitions  . . . . . . . . . . . . . . . . . . . . . .  10
     2.2.   State-Machine Diagrams . . . . . . . . . . . . . . . . .  10
     2.3.   URI Schemes  . . . . . . . . . . . . . . . . . . . . . .  11
   3.  Architecture  . . . . . . . . . . . . . . . . . . . . . . . .  11
     3.1.   MRCPv2 Media Resource Types  . . . . . . . . . . . . . .  12
     3.2.   Server and Resource Addressing . . . . . . . . . . . . .  14
   4.  MRCPv2 Basics . . . . . . . . . . . . . . . . . . . . . . . .  14
     4.1.   Connecting to the Server . . . . . . . . . . . . . . . .  14
     4.2.   Managing Resource Control Channels . . . . . . . . . . .  14
     4.3.   SIP Session Example  . . . . . . . . . . . . . . . . . .  17
     4.4.   Media Streams and RTP Ports  . . . . . . . . . . . . . .  22
     4.5.   MRCPv2 Message Transport . . . . . . . . . . . . . . . .  24
     4.6.   MRCPv2 Session Termination . . . . . . . . . . . . . . .  24
   5.  MRCPv2 Specification  . . . . . . . . . . . . . . . . . . . .  24
     5.1.   Common Protocol Elements . . . . . . . . . . . . . . . .  25
     5.2.   Request  . . . . . . . . . . . . . . . . . . . . . . . .  28
     5.3.   Response . . . . . . . . . . . . . . . . . . . . . . . .  29
     5.4.   Status Codes . . . . . . . . . . . . . . . . . . . . . .  30
     5.5.   Events . . . . . . . . . . . . . . . . . . . . . . . . .  31
   6.  MRCPv2 Generic Methods, Headers, and Result Structure . . . .  32
     6.1.   Generic Methods  . . . . . . . . . . . . . . . . . . . .  32
       6.1.1.   SET-PARAMS . . . . . . . . . . . . . . . . . . . . .  32
       6.1.2.   GET-PARAMS . . . . . . . . . . . . . . . . . . . . .  33
     6.2.   Generic Message Headers  . . . . . . . . . . . . . . . .  34
       6.2.1.   Channel-Identifier . . . . . . . . . . . . . . . . .  35
       6.2.2.   Accept . . . . . . . . . . . . . . . . . . . . . . .  36
       6.2.3.   Active-Request-Id-List . . . . . . . . . . . . . . .  36
       6.2.4.   Proxy-Sync-Id  . . . . . . . . . . . . . . . . . . .  36
       6.2.5.   Accept-Charset . . . . . . . . . . . . . . . . . . .  37
       6.2.6.   Content-Type . . . . . . . . . . . . . . . . . . . .  37
       6.2.7.   Content-ID . . . . . . . . . . . . . . . . . . . . .  38
       6.2.8.   Content-Base . . . . . . . . . . . . . . . . . . . .  38
       6.2.9.   Content-Encoding . . . . . . . . . . . . . . . . . .  38
       6.2.10.  Content-Location . . . . . . . . . . . . . . . . . .  39
       6.2.11.  Content-Length . . . . . . . . . . . . . . . . . . .  39
       6.2.12.  Fetch Timeout  . . . . . . . . . . . . . . . . . . .  39
       6.2.13.  Cache-Control  . . . . . . . . . . . . . . . . . . .  40
       6.2.14.  Logging-Tag  . . . . . . . . . . . . . . . . . . . .  41
       6.2.15.  Set-Cookie . . . . . . . . . . . . . . . . . . . . .  42
       6.2.16.  Vendor-Specific Parameters . . . . . . . . . . . . .  44
     6.3.   Generic Result Structure . . . . . . . . . . . . . . . .  44
       6.3.1.   Natural Language Semantics Markup Language . . . . .  45
   7.  Resource Discovery  . . . . . . . . . . . . . . . . . . . . .  46
   8.  Speech Synthesizer Resource . . . . . . . . . . . . . . . . .  47
     8.1.   Synthesizer State Machine  . . . . . . . . . . . . . . .  48
     8.2.   Synthesizer Methods  . . . . . . . . . . . . . . . . . .  48
     8.3.   Synthesizer Events . . . . . . . . . . . . . . . . . . .  49
     8.4.   Synthesizer Header Fields  . . . . . . . . . . . . . . .  49
       8.4.1.   Jump-Size  . . . . . . . . . . . . . . . . . . . . .  49
       8.4.2.   Kill-On-Barge-In . . . . . . . . . . . . . . . . . .  50
       8.4.3.   Speaker-Profile  . . . . . . . . . . . . . . . . . .  51
       8.4.4.   Completion-Cause . . . . . . . . . . . . . . . . . .  51
       8.4.5.   Completion-Reason  . . . . . . . . . . . . . . . . .  52
       8.4.6.   Voice-Parameter  . . . . . . . . . . . . . . . . . .  52
       8.4.7.   Prosody-Parameters . . . . . . . . . . . . . . . . .  53
       8.4.8.   Speech-Marker  . . . . . . . . . . . . . . . . . . .  53
       8.4.9.   Speech-Language  . . . . . . . . . . . . . . . . . .  54
       8.4.10.  Fetch-Hint . . . . . . . . . . . . . . . . . . . . .  54
       8.4.11.  Audio-Fetch-Hint . . . . . . . . . . . . . . . . . .  55
       8.4.12.  Failed-URI . . . . . . . . . . . . . . . . . . . . .  55
       8.4.13.  Failed-URI-Cause . . . . . . . . . . . . . . . . . .  55
       8.4.14.  Speak-Restart  . . . . . . . . . . . . . . . . . . .  56
       8.4.15.  Speak-Length . . . . . . . . . . . . . . . . . . . .  56
       8.4.16.  Load-Lexicon . . . . . . . . . . . . . . . . . . . .  57
       8.4.17.  Lexicon-Search-Order . . . . . . . . . . . . . . . .  57
     8.5.   Synthesizer Message Body . . . . . . . . . . . . . . . .  57
       8.5.1.   Synthesizer Speech Data  . . . . . . . . . . . . . .  57
       8.5.2.   Lexicon Data . . . . . . . . . . . . . . . . . . . .  59
     8.6.   SPEAK Method . . . . . . . . . . . . . . . . . . . . . .  60
     8.7.   STOP . . . . . . . . . . . . . . . . . . . . . . . . . .  62
     8.8.   BARGE-IN-OCCURRED  . . . . . . . . . . . . . . . . . . .  63
     8.9.   PAUSE  . . . . . . . . . . . . . . . . . . . . . . . . .  65
     8.10.  RESUME . . . . . . . . . . . . . . . . . . . . . . . . .  66
     8.11.  CONTROL  . . . . . . . . . . . . . . . . . . . . . . . .  67
     8.12.  SPEAK-COMPLETE . . . . . . . . . . . . . . . . . . . . .  69
     8.13.  SPEECH-MARKER  . . . . . . . . . . . . . . . . . . . . .  70
     8.14.  DEFINE-LEXICON . . . . . . . . . . . . . . . . . . . . .  71
   9.  Speech Recognizer Resource  . . . . . . . . . . . . . . . . .  72
     9.1.   Recognizer State Machine . . . . . . . . . . . . . . . .  74
     9.2.   Recognizer Methods . . . . . . . . . . . . . . . . . . .  74
     9.3.   Recognizer Events  . . . . . . . . . . . . . . . . . . .  75
     9.4.   Recognizer Header Fields . . . . . . . . . . . . . . . .  75
       9.4.1.   Confidence-Threshold . . . . . . . . . . . . . . . .  77
       9.4.2.   Sensitivity-Level  . . . . . . . . . . . . . . . . .  77
       9.4.3.   Speed-Vs-Accuracy  . . . . . . . . . . . . . . . . .  77
       9.4.4.   N-Best-List-Length . . . . . . . . . . . . . . . . .  78
       9.4.5.   Input-Type . . . . . . . . . . . . . . . . . . . . .  78
       9.4.6.   No-Input-Timeout . . . . . . . . . . . . . . . . . .  78
       9.4.7.   Recognition-Timeout  . . . . . . . . . . . . . . . .  79
       9.4.8.   Waveform-URI . . . . . . . . . . . . . . . . . . . .  79
       9.4.9.   Media-Type . . . . . . . . . . . . . . . . . . . . .  80
       9.4.10.  Input-Waveform-URI . . . . . . . . . . . . . . . . .  80
       9.4.11.  Completion-Cause . . . . . . . . . . . . . . . . . .  80
       9.4.12.  Completion-Reason  . . . . . . . . . . . . . . . . .  83
       9.4.13.  Recognizer-Context-Block . . . . . . . . . . . . . .  83
       9.4.14.  Start-Input-Timers . . . . . . . . . . . . . . . . .  83
       9.4.15.  Speech-Complete-Timeout  . . . . . . . . . . . . . .  84
       9.4.16.  Speech-Incomplete-Timeout  . . . . . . . . . . . . .  84
       9.4.17.  DTMF-Interdigit-Timeout  . . . . . . . . . . . . . .  85
       9.4.18.  DTMF-Term-Timeout  . . . . . . . . . . . . . . . . .  85
       9.4.19.  DTMF-Term-Char . . . . . . . . . . . . . . . . . . .  85
       9.4.20.  Failed-URI . . . . . . . . . . . . . . . . . . . . .  86
       9.4.21.  Failed-URI-Cause . . . . . . . . . . . . . . . . . .  86
       9.4.22.  Save-Waveform  . . . . . . . . . . . . . . . . . . .  86
       9.4.23.  New-Audio-Channel  . . . . . . . . . . . . . . . . .  86
       9.4.24.  Speech-Language  . . . . . . . . . . . . . . . . . .  87
       9.4.25.  Ver-Buffer-Utterance . . . . . . . . . . . . . . . .  87
       9.4.26.  Recognition-Mode . . . . . . . . . . . . . . . . . .  87
       9.4.27.  Cancel-If-Queue  . . . . . . . . . . . . . . . . . .  88
       9.4.28.  Hotword-Max-Duration . . . . . . . . . . . . . . . .  88
       9.4.29.  Hotword-Min-Duration . . . . . . . . . . . . . . . .  88
       9.4.30.  Interpret-Text . . . . . . . . . . . . . . . . . . .  89
       9.4.31.  DTMF-Buffer-Time . . . . . . . . . . . . . . . . . .  89
       9.4.32.  Clear-DTMF-Buffer  . . . . . . . . . . . . . . . . .  89
       9.4.33.  Early-No-Match . . . . . . . . . . . . . . . . . . .  90
       9.4.34.  Num-Min-Consistent-Pronunciations  . . . . . . . . .  90
       9.4.35.  Consistency-Threshold  . . . . . . . . . . . . . . .  90
       9.4.36.  Clash-Threshold  . . . . . . . . . . . . . . . . . .  90
       9.4.37.  Personal-Grammar-URI . . . . . . . . . . . . . . . .  91
       9.4.38.  Enroll-Utterance . . . . . . . . . . . . . . . . . .  91
       9.4.39.  Phrase-Id  . . . . . . . . . . . . . . . . . . . . .  91
       9.4.40.  Phrase-NL  . . . . . . . . . . . . . . . . . . . . .  92
       9.4.41.  Weight . . . . . . . . . . . . . . . . . . . . . . .  92
       9.4.42.  Save-Best-Waveform . . . . . . . . . . . . . . . . .  92
       9.4.43.  New-Phrase-Id  . . . . . . . . . . . . . . . . . . .  93
       9.4.44.  Confusable-Phrases-URI . . . . . . . . . . . . . . .  93
       9.4.45.  Abort-Phrase-Enrollment  . . . . . . . . . . . . . .  93
     9.5.   Recognizer Message Body  . . . . . . . . . . . . . . . .  93
       9.5.1.   Recognizer Grammar Data  . . . . . . . . . . . . . .  93
       9.5.2.   Recognizer Result Data . . . . . . . . . . . . . . .  97
       9.5.3.   Enrollment Result Data . . . . . . . . . . . . . . .  98
       9.5.4.   Recognizer Context Block . . . . . . . . . . . . . .  98
     9.6.   Recognizer Results . . . . . . . . . . . . . . . . . . .  99
       9.6.1.   Markup Functions . . . . . . . . . . . . . . . . . .  99
       9.6.2.   Overview of Recognizer Result Elements and Their
                Relationships  . . . . . . . . . . . . . . . . . . . 100
       9.6.3.   Elements and Attributes  . . . . . . . . . . . . . . 101
     9.7.   Enrollment Results . . . . . . . . . . . . . . . . . . . 106
       9.7.1.   <num-clashes> Element  . . . . . . . . . . . . . . . 106
       9.7.2.   <num-good-repetitions> Element . . . . . . . . . . . 106
       9.7.3.   <num-repetitions-still-needed> Element . . . . . . . 107
       9.7.4.   <consistency-status> Element . . . . . . . . . . . . 107
       9.7.5.   <clash-phrase-ids> Element . . . . . . . . . . . . . 107
       9.7.6.   <transcriptions> Element . . . . . . . . . . . . . . 107
       9.7.7.   <confusable-phrases> Element . . . . . . . . . . . . 107
     9.8.   DEFINE-GRAMMAR . . . . . . . . . . . . . . . . . . . . . 107
     9.9.   RECOGNIZE  . . . . . . . . . . . . . . . . . . . . . . . 111
     9.10.  STOP . . . . . . . . . . . . . . . . . . . . . . . . . . 118
     9.11.  GET-RESULT . . . . . . . . . . . . . . . . . . . . . . . 119
     9.12.  START-OF-INPUT . . . . . . . . . . . . . . . . . . . . . 120
     9.13.  START-INPUT-TIMERS . . . . . . . . . . . . . . . . . . . 120
     9.14.  RECOGNITION-COMPLETE . . . . . . . . . . . . . . . . . . 120
     9.15.  START-PHRASE-ENROLLMENT  . . . . . . . . . . . . . . . . 123
     9.16.  ENROLLMENT-ROLLBACK  . . . . . . . . . . . . . . . . . . 124
     9.17.  END-PHRASE-ENROLLMENT  . . . . . . . . . . . . . . . . . 124
     9.18.  MODIFY-PHRASE  . . . . . . . . . . . . . . . . . . . . . 125
     9.19.  DELETE-PHRASE  . . . . . . . . . . . . . . . . . . . . . 125
     9.20.  INTERPRET  . . . . . . . . . . . . . . . . . . . . . . . 125
     9.21.  INTERPRETATION-COMPLETE  . . . . . . . . . . . . . . . . 127
     9.22.  DTMF Detection . . . . . . . . . . . . . . . . . . . . . 128
   10. Recorder Resource . . . . . . . . . . . . . . . . . . . . . . 129
     10.1.  Recorder State Machine . . . . . . . . . . . . . . . . . 129
     10.2.  Recorder Methods . . . . . . . . . . . . . . . . . . . . 130
     10.3.  Recorder Events  . . . . . . . . . . . . . . . . . . . . 130
     10.4.  Recorder Header Fields . . . . . . . . . . . . . . . . . 130
       10.4.1.  Sensitivity-Level  . . . . . . . . . . . . . . . . . 130
       10.4.2.  No-Input-Timeout . . . . . . . . . . . . . . . . . . 131
       10.4.3.  Completion-Cause . . . . . . . . . . . . . . . . . . 131
       10.4.4.  Completion-Reason  . . . . . . . . . . . . . . . . . 132
       10.4.5.  Failed-URI . . . . . . . . . . . . . . . . . . . . . 132
       10.4.6.  Failed-URI-Cause . . . . . . . . . . . . . . . . . . 132
       10.4.7.  Record-URI . . . . . . . . . . . . . . . . . . . . . 132
       10.4.8.  Media-Type . . . . . . . . . . . . . . . . . . . . . 133
       10.4.9.  Max-Time . . . . . . . . . . . . . . . . . . . . . . 133
       10.4.10. Trim-Length  . . . . . . . . . . . . . . . . . . . . 134
       10.4.11. Final-Silence  . . . . . . . . . . . . . . . . . . . 134
       10.4.12. Capture-On-Speech  . . . . . . . . . . . . . . . . . 134
       10.4.13. Ver-Buffer-Utterance . . . . . . . . . . . . . . . . 134
       10.4.14. Start-Input-Timers . . . . . . . . . . . . . . . . . 135
       10.4.15. New-Audio-Channel  . . . . . . . . . . . . . . . . . 135
     10.5.  Recorder Message Body  . . . . . . . . . . . . . . . . . 135
     10.6.  RECORD . . . . . . . . . . . . . . . . . . . . . . . . . 135
     10.7.  STOP . . . . . . . . . . . . . . . . . . . . . . . . . . 136
     10.8.  RECORD-COMPLETE  . . . . . . . . . . . . . . . . . . . . 137
     10.9.  START-INPUT-TIMERS . . . . . . . . . . . . . . . . . . . 138
     10.10. START-OF-INPUT . . . . . . . . . . . . . . . . . . . . . 138
   11. Speaker Verification and Identification . . . . . . . . . . . 139
     11.1.  Speaker Verification State Machine . . . . . . . . . . . 140
     11.2.  Speaker Verification Methods . . . . . . . . . . . . . . 142
     11.3.  Verification Events  . . . . . . . . . . . . . . . . . . 144
     11.4.  Verification Header Fields . . . . . . . . . . . . . . . 144
       11.4.1.  Repository-URI . . . . . . . . . . . . . . . . . . . 144
       11.4.2.  Voiceprint-Identifier  . . . . . . . . . . . . . . . 145
       11.4.3.  Verification-Mode  . . . . . . . . . . . . . . . . . 145
       11.4.4.  Adapt-Model  . . . . . . . . . . . . . . . . . . . . 146
       11.4.5.  Abort-Model  . . . . . . . . . . . . . . . . . . . . 146
       11.4.6.  Min-Verification-Score . . . . . . . . . . . . . . . 147
       11.4.7.  Num-Min-Verification-Phrases . . . . . . . . . . . . 147
       11.4.8.  Num-Max-Verification-Phrases . . . . . . . . . . . . 147
       11.4.9.  No-Input-Timeout . . . . . . . . . . . . . . . . . . 148
       11.4.10. Save-Waveform  . . . . . . . . . . . . . . . . . . . 148
       11.4.11. Media-Type . . . . . . . . . . . . . . . . . . . . . 148
       11.4.12. Waveform-URI . . . . . . . . . . . . . . . . . . . . 148
       11.4.13. Voiceprint-Exists  . . . . . . . . . . . . . . . . . 149
       11.4.14. Ver-Buffer-Utterance . . . . . . . . . . . . . . . . 149
       11.4.15. Input-Waveform-URI . . . . . . . . . . . . . . . . . 149
       11.4.16. Completion-Cause . . . . . . . . . . . . . . . . . . 150
       11.4.17. Completion-Reason  . . . . . . . . . . . . . . . . . 151
       11.4.18. Speech-Complete-Timeout  . . . . . . . . . . . . . . 151
       11.4.19. New-Audio-Channel  . . . . . . . . . . . . . . . . . 152
       11.4.20. Abort-Verification . . . . . . . . . . . . . . . . . 152
       11.4.21. Start-Input-Timers . . . . . . . . . . . . . . . . . 152
     11.5.  Verification Message Body  . . . . . . . . . . . . . . . 152
       11.5.1.  Verification Result Data . . . . . . . . . . . . . . 152
       11.5.2.  Verification Result Elements . . . . . . . . . . . . 153
     11.6.  START-SESSION  . . . . . . . . . . . . . . . . . . . . . 157
     11.7.  END-SESSION  . . . . . . . . . . . . . . . . . . . . . . 158
     11.8.  QUERY-VOICEPRINT . . . . . . . . . . . . . . . . . . . . 159
     11.9.  DELETE-VOICEPRINT  . . . . . . . . . . . . . . . . . . . 160
     11.10. VERIFY . . . . . . . . . . . . . . . . . . . . . . . . . 160
     11.11. VERIFY-FROM-BUFFER . . . . . . . . . . . . . . . . . . . 160
     11.12. VERIFY-ROLLBACK  . . . . . . . . . . . . . . . . . . . . 164
     11.13. STOP . . . . . . . . . . . . . . . . . . . . . . . . . . 164
     11.14. START-INPUT-TIMERS . . . . . . . . . . . . . . . . . . . 165
     11.15. VERIFICATION-COMPLETE  . . . . . . . . . . . . . . . . . 165
     11.16. START-OF-INPUT . . . . . . . . . . . . . . . . . . . . . 166
     11.17. CLEAR-BUFFER . . . . . . . . . . . . . . . . . . . . . . 166
     11.18. GET-INTERMEDIATE-RESULT  . . . . . . . . . . . . . . . . 167
   12. Security Considerations . . . . . . . . . . . . . . . . . . . 168
     12.1.  Rendezvous and Session Establishment . . . . . . . . . . 168
     12.2.  Control Channel Protection . . . . . . . . . . . . . . . 168
     12.3.  Media Session Protection . . . . . . . . . . . . . . . . 169
     12.4.  Indirect Content Access  . . . . . . . . . . . . . . . . 169
     12.5.  Protection of Stored Media . . . . . . . . . . . . . . . 170
     12.6.  DTMF and Recognition Buffers . . . . . . . . . . . . . . 171
     12.7.  Client-Set Server Parameters . . . . . . . . . . . . . . 171
     12.8.  DELETE-VOICEPRINT and Authorization  . . . . . . . . . . 171
   13. IANA Considerations . . . . . . . . . . . . . . . . . . . . . 171
     13.1.  New Registries . . . . . . . . . . . . . . . . . . . . . 171
       13.1.1.  MRCPv2 Resource Types  . . . . . . . . . . . . . . . 171
       13.1.2.  MRCPv2 Methods and Events  . . . . . . . . . . . . . 172
       13.1.3.  MRCPv2 Header Fields . . . . . . . . . . . . . . . . 173
       13.1.4.  MRCPv2 Status Codes  . . . . . . . . . . . . . . . . 176
       13.1.5.  Grammar Reference List Parameters  . . . . . . . . . 176
       13.1.6.  MRCPv2 Vendor-Specific Parameters  . . . . . . . . . 176
     13.2.  NLSML-Related Registrations  . . . . . . . . . . . . . . 177
       13.2.1.  'application/nlsml+xml' Media Type Registration  . . 177
     13.3.  NLSML XML Schema Registration  . . . . . . . . . . . . . 178
     13.4.  MRCPv2 XML Namespace Registration  . . . . . . . . . . . 178
     13.5.  Text Media Type Registrations  . . . . . . . . . . . . . 178
       13.5.1.  text/grammar-ref-list  . . . . . . . . . . . . . . . 178
     13.6.  'session' URI Scheme Registration  . . . . . . . . . . . 180
     13.7.  SDP Parameter Registrations  . . . . . . . . . . . . . . 181
       13.7.1.  Sub-Registry "proto" . . . . . . . . . . . . . . . . 181
       13.7.2.  Sub-Registry "att-field (media-level)" . . . . . . . 182
   14. Examples  . . . . . . . . . . . . . . . . . . . . . . . . . . 183
     14.1.  Message Flow . . . . . . . . . . . . . . . . . . . . . . 183
     14.2.  Recognition Result Examples  . . . . . . . . . . . . . . 192
       14.2.1.  Simple ASR Ambiguity . . . . . . . . . . . . . . . . 192
       14.2.2.  Mixed Initiative . . . . . . . . . . . . . . . . . . 192
       14.2.3.  DTMF Input . . . . . . . . . . . . . . . . . . . . . 193
       14.2.4.  Interpreting Meta-Dialog and Meta-Task Utterances  . 194
       14.2.5.  Anaphora and Deixis  . . . . . . . . . . . . . . . . 195
       14.2.6.  Distinguishing Individual Items from Sets with
                One Member . . . . . . . . . . . . . . . . . . . . . 195
       14.2.7.  Extensibility  . . . . . . . . . . . . . . . . . . . 196
   15. ABNF Normative Definition . . . . . . . . . . . . . . . . . . 196
   16. XML Schemas . . . . . . . . . . . . . . . . . . . . . . . . . 211
     16.1.  NLSML Schema Definition  . . . . . . . . . . . . . . . . 211
     16.2.  Enrollment Results Schema Definition . . . . . . . . . . 213
     16.3.  Verification Results Schema Definition . . . . . . . . . 214
   17. References  . . . . . . . . . . . . . . . . . . . . . . . . . 218
     17.1.  Normative References . . . . . . . . . . . . . . . . . . 218
     17.2.  Informative References . . . . . . . . . . . . . . . . . 220
   Appendix A.  Contributors . . . . . . . . . . . . . . . . . . . . 223
   Appendix B.  Acknowledgements . . . . . . . . . . . . . . . . . . 223
```

---
## **1.  Introduction**

MRCPv2는 클라이언트 장치가 네트워크의 미디어 처리 리소스를 제어할 수 있도록 설계되었습니다. 이러한 미디어 처리 리소스에는 음성 인식 엔진, 음성 합성 엔진, 화자 확인 및 화자 식별 엔진이 포함됩니다. MRCPv2는 전문화된 음성 처리 서버에서 별도의 백엔드 음성 처리 기능을 유지하면서 VoiceXML \[W3C.REC-voicexml20-20040316\] 브라우저 또는 기타 클라이언트 애플리케이션을 사용하여 분산된 대화형 음성 응답 플랫폼을 구현할 수 있도록 합니다. MRCPv2는 Cisco Systems, Inc., Nuance Communications 및 Speechworks, Inc.가 공동으로 개발한 이전 Media Resource Control Protocol\(MRCP\) \[RFC4463\]을 기반으로 합니다. 일부 메서드 이름은 비슷하지만 이러한 메서드가 전달되는 방식은 다릅니다. 또한 각 리소스에 대해 더 많은 리소스와 더 많은 메서드가 있습니다. MRCP의 첫 번째 버전은 본질적으로 이 프로토콜의 개발에 대한 입력으로만 사용되었습니다. MRCPv2 클라이언트가 MRCPv1 서버와 함께 작동하거나 그 반대의 경우도 마찬가지일 것이라는 기대는 없습니다. 두 프로토콜 간에는 마이그레이션 계획이나 게이트웨이 정의가 없습니다.

Speech Services Control\(SPEECHSC\) \[RFC4313\]의 프로토콜 요구 사항에는 솔루션이 미디어 처리 서버에 도달하고, 미디어 리소스에 대한 통신 채널을 설정하고, 서버와 제어 메시지 및 미디어 스트림을 주고받을 수 있어야 한다는 것이 포함됩니다. 세션 개시 프로토콜\(SIP\) \[RFC3261\]은 이러한 요구 사항을 충족합니다.

MRCP의 독점 버전은 RTSP\(Real Time Streaming Protocol\) \[RFC2326\]에서 실행되었습니다. MRCPv2 작업이 시작될 당시, 이러한 RTSP 사용은 RTSP 프로토콜을 손상시키거나 이전 버전과의 호환성 문제를 일으킬 것이라는 의견이 일치했습니다. 이는 \[RFC4313\]의 섹션 3.2에서 금지되어 있습니다. 이것이 MRCPv2가 RTSP에서 실행되지 않는 이유입니다.

MRCPv2는 SIP 및 세션 설명 프로토콜\(SDP\) \[RFC4566\]을 기반으로 이러한 기능을 활용합니다. MRCPv2는 SIP를 사용하여 서버와의 미디어 및 제어 세션을 설정 및 해제합니다. 또한 클라이언트는 SIP re-INVITE 메서드\(기존 SIP 세션 내에서 전송된 INVITE 대화\)를 사용하여 클라이언트와 서버 간의 SIP 대화를 유지하면서 이러한 미디어 및 제어 세션의 특성을 변경할 수 있습니다. SDP는 해당 대화와 관련된 미디어 세션의 매개변수를 설명하는 데 사용됩니다. 상호 운용성을 보장하기 위해 세션 설정 프로토콜로 SIP를 지원하는 것이 필수적입니다. 사전 합의에 따라 다른 프로토콜을 세션 설정에 사용할 수 있습니다. 이 문서에서는 SIP 및 SDP의 사용에 대해서만 설명합니다.

MRCPv2는 SIP와 SDP를 사용하여 음성 클라이언트/서버 대화를 만들고 서버에 미디어 채널을 설정합니다. 또한 SIP와 SDP를 사용하여 해당 대화에 필요한 각 미디어 처리 리소스에 대해 클라이언트와 서버 간에 MRCPv2 제어 세션을 설정합니다. 클라이언트와 미디어 리소스 간의 MRCPv2 프로토콜 교환은 해당 제어 세션에서 수행됩니다. MRCPv2 교환은 SIP 대화, 미디어 세션 또는 SIP를 통해 시작된 대화의 다른 매개변수의 상태를 변경하지 않습니다. MRCPv2 세션과 연결된 미디어 처리 리소스의 상태를 제어하고 영향을 미칩니다.

MRCPv2는 다양한 미디어 처리 리소스와 해당 작업을 안내하는 데 필요한 상태 머신을 제어하는 메시지를 정의합니다. 또한 이러한 메시지가 전송 제어 프로토콜\(TCP\) \[RFC0793\] 또는 전송 계층 보안\(TLS\) 프로토콜 \[RFC5246\]과 같은 전송 계층 프로토콜을 통해 어떻게 전송되는지 설명합니다. \(참고: 스트림 제어 전송 프로토콜\(SCTP\) \[RFC4960\]도 MRCPv2에 대한 실행 가능한 전송이지만 SCTP에 대한 매핑은 이 사양에 설명되어 있지 않습니다.\)

---
## **2.  Document Conventions**

이 문서의 핵심 단어 "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY" 및 "OPTIONAL"은 다음과 같습니다. RFC 2119 \[RFC2119\]에 설명된 대로 해석됩니다.

많은 정의와 구문이 Hypertext Transfer Protocol -- HTTP/1.1 \[RFC2616\]의 정의와 구문과 동일하기 때문에 이 사양은 복사하는 대신 정의된 섹션을 참조합니다. 간결하게 하기 위해 \[HX.Y\]는 RFC 2616의 섹션 X.Y를 참조하는 것으로 간주해야 합니다.

이 문서에 명시된 모든 메커니즘은 산문과 확장된 Backus-Naur 형식\(ABNF\[RFC5234\]\)으로 설명됩니다.

ABNF 형식의 완전한 메시지 형식은 섹션 15에 제공되며 규범적 형식 정의입니다. 읽기 편의를 위해 문서 본문에 프로덕션을 중복할 수 있습니다. 본문의 프로덕션이 규범적 정의의 프로덕션과 충돌하는 경우 후자가 규칙입니다.

---
### **2.1.  Definitions**

```text
   Media Resource
                  An entity on the speech processing server that can be
                  controlled through MRCPv2.

   MRCP Server
                  Aggregate of one or more "Media Resource" entities on
                  a server, exposed through MRCPv2.  Often, 'server' in
                  this document refers to an MRCP server.

   MRCP Client
                  An entity controlling one or more Media Resources
                  through MRCPv2 ("Client" for short).

   DTMF
                  Dual-Tone Multi-Frequency; a method of transmitting
                  key presses in-band, either as actual tones (Q.23
                  [Q.23]) or as named tone events (RFC 4733 [RFC4733]).

   Endpointing
                  The process of automatically detecting the beginning
                  and end of speech in an audio stream.  This is
                  critical both for speech recognition and for automated
                  recording as one would find in voice mail systems.

   Hotword Mode
                  A mode of speech recognition where a stream of
                  utterances is evaluated for match against a small set
                  of command words.  This is generally employed either
                  to trigger some action or to control the subsequent
                  grammar to be used for further recognition.
```

---
### **2.2.  State-Machine Diagrams**

이 문서의 상태 머신 다이어그램은 가능한 모든 메서드 호출을 보여주지 않습니다. 오히려 IN-PROGRESS 또는 COMPLETE 상태로 이동한 메서드에 따라 리소스의 상태를 반영합니다\(섹션 5.3 참조\). PENDING 요청은 본질적으로 아직 리소스에 영향을 미치지 않았고 처리될 대기열에 있으므로 상태 머신 다이어그램에 반영되지 않습니다.

---
### **2.3.  URI Schemes**

이 문서는 URI\(Uniform Resource Identifiers \[RFC3986\]\) 또는 미디어 참조를 위한 URI 목록을 포함하는 많은 프로토콜 헤더를 정의합니다. 보안 고려 사항 섹션\(섹션 12\)을 포함한 전체 문서는 달리 명시되지 않는 한 HTTP 또는 HTTP over TLS\(HTTPS\) \[RFC2818\]가 URI 주소 지정 체계로 사용된다고 가정합니다. 그러나 구현은 이 문서에 설명된 모든 보안 고려 사항과 특정 체계에 고유한 다른 사항을 해결한 경우 다른 체계\(예: '파일'\)를 지원할 수 있습니다. 예를 들어, 클라이언트와 서버가 모두 동일한 물리적 하드웨어에 상주하고 파일 시스템이 기존 사용자 수준 파일 액세스 제어로 보호되는 구현은 '파일' 체계를 지원하기에 적합한 후보가 될 수 있습니다.

---
## **3.  Architecture**

MRCPv2를 사용하는 시스템은 미디어 스트림의 생성 및/또는 소비를 필요로 하는 클라이언트와 이러한 스트림을 입력으로 처리하거나 출력으로 생성하는 리소스 또는 "엔진"을 가진 미디어 리소스 서버로 구성됩니다. 클라이언트는 SIP 및 SDP를 사용하여 서버와 MRCPv2 제어 채널을 설정하여 미디어 처리 리소스를 사용합니다. MRCPv2 서버는 SIP URI를 사용하여 주소가 지정됩니다.

SIP는 RFC 3264 \[RFC3264\]에 설명된 제공/응답 모델과 함께 SDP를 사용하여 MRCPv2 제어 채널을 설정하고 해당 특성을 설명합니다. 클라이언트와 서버 간의 SIP 대화와 관련된 각 미디어 처리 리소스를 제어하려면 별도의 MRCPv2 세션이 필요합니다. SIP 대화 내에서 다양한 리소스에 대한 개별 리소스 제어 채널은 SIP re-INVITE 트랜잭션에서 전달되는 SDP 제공/응답을 통해 추가되거나 제거됩니다.

서버는 SDP 교환을 통해 클라이언트에게 추측하기 어려운 모호하지 않은 채널 식별자와 TCP 포트 번호를 제공합니다\(4.2절 참조\). 그런 다음 클라이언트는 이 포트 번호에서 서버와 새 TCP 연결을 열 수 있습니다. 여러 MRCPv2 채널은 클라이언트와 서버 간에 TCP 연결을 공유할 수 있습니다. 클라이언트와 서버 간에 교환되는 모든 MRCPv2 메시지는 서버가 해당 서버에서 활성화된 모든 MRCPv2 제어 채널 간에 모호하지 않도록 해야 하는 지정된 채널 식별자를 전달합니다. 클라이언트는 이 채널 식별자를 사용하여 해당 채널과 연결된 미디어 처리 리소스를 나타냅니다. 메시지 프레이밍에 대한 정보는 5절을 참조하십시오.

SIP는 또한 SDP "m=" 줄을 사용하여 클라이언트\(또는 다른 미디어 소스/싱크\)와 MRCPv2 서버 간의 미디어 세션을 설정합니다.

하나 이상의 미디어 처리 리소스가 SIP 세션에 따라 미디어 세션을 공유할 수 있으며, 각 미디어 처리 리소스는 고유한 미디어 세션을 가질 수 있습니다.

다음 다이어그램은 MRCPv2를 사용하는 시스템의 일반 아키텍처를 보여줍니다. 다이어그램을 단순화하기 위해 몇 가지 리소스만 표시됩니다.

```text
     MRCPv2 client                   MRCPv2 Media Resource Server
|--------------------|            |------------------------------------|
||------------------||            ||----------------------------------||
|| Application Layer||            ||Synthesis|Recognition|Verification||
||------------------||            || Engine  |  Engine   |   Engine   ||
||Media Resource API||            ||    ||   |    ||     |    ||      ||
||------------------||            ||Synthesis|Recognizer |  Verifier  ||
|| SIP  |  MRCPv2   ||            ||Resource | Resource  |  Resource  ||
||Stack |           ||            ||     Media Resource Management    ||
||      |           ||            ||----------------------------------||
||------------------||            ||   SIP  |        MRCPv2           ||
||   TCP/IP Stack   ||---MRCPv2---||  Stack |                         ||
||                  ||            ||----------------------------------||
||------------------||----SIP-----||           TCP/IP Stack           ||
|--------------------|            ||                                  ||
         |                        ||----------------------------------||
        SIP                       |------------------------------------|
         |                          /
|-------------------|             RTP
|                   |             /
| Media Source/Sink |------------/
|                   |
|-------------------|

                      Figure 1: Architectural Diagram
```

---
### **3.1.  MRCPv2 Media Resource Types**

MRCPv2 서버는 클라이언트에게 다음 미디어 처리 리소스 중 하나 이상을 제공할 수 있습니다.

```text
   Basic Synthesizer
                  A speech synthesizer resource that has very limited
                  capabilities and can generate its media stream
                  exclusively from concatenated audio clips.  The speech
                  data is described using a limited subset of the Speech
                  Synthesis Markup Language (SSML)
                  [W3C.REC-speech-synthesis-20040907] elements.  A basic
                  synthesizer MUST support the SSML tags <speak>,
                  <audio>, <say-as>, and <mark>.

   Speech Synthesizer
                  A full-capability speech synthesis resource that can
                  render speech from text.  Such a synthesizer MUST have
                  full SSML [W3C.REC-speech-synthesis-20040907] support.

   Recorder
                  A resource capable of recording audio and providing a
                  URI pointer to the recording.  A recorder MUST provide
                  endpointing capabilities for suppressing silence at
                  the beginning and end of a recording, and MAY also
                  suppress silence in the middle of a recording.  If
                  such suppression is done, the recorder MUST maintain
                  timing metadata to indicate the actual timestamps of
                  the recorded media.

   DTMF Recognizer
                  A recognizer resource capable of extracting and
                  interpreting Dual-Tone Multi-Frequency (DTMF) [Q.23]
                  digits in a media stream and matching them against a
                  supplied digit grammar.  It could also do a semantic
                  interpretation based on semantic tags in the grammar.

   Speech Recognizer
                  A full speech recognition resource that is capable of
                  receiving a media stream containing audio and
                  interpreting it to recognition results.  It also has a
                  natural language semantic interpreter to post-process
                  the recognized data according to the semantic data in
                  the grammar and provide semantic results along with
                  the recognized input.  The recognizer MAY also support
                  enrolled grammars, where the client can enroll and
                  create new personal grammars for use in future
                  recognition operations.

   Speaker Verifier
                  A resource capable of verifying the authenticity of a
                  claimed identity by matching a media stream containing
                  spoken input to a pre-existing voiceprint.  This may
                  also involve matching the caller's voice against more
                  than one voiceprint, also called multi-verification or
                  speaker identification.
```

---
### **3.2.  Server and Resource Addressing**

MRCPv2 서버는 일반 SIP 서버이므로 SIP URI\(RFC 3261 \[RFC3261\]\)로 주소가 지정됩니다.

예를 들어:

```text
        sip:mrcpv2@example.net   or
        sips:mrcpv2@example.net
```

---
## **4.  MRCPv2 Basics**

MRCPv2는 클라이언트와 서버 간의 MRCPv2 제어 메시지의 안정적인 시퀀싱 및 전달을 보장하기 위해 TCP와 같은 연결 지향 전송 계층 프로토콜이 필요합니다. SPEECHSC 요구 사항\[RFC4313\]에 열거된 보안 요구 사항을 충족하기 위해 클라이언트와 서버는 TLS도 구현해야 합니다. 클라이언트와 서버 간의 하나 이상의 연결은 서버에 대한 여러 MRCPv2 채널에서 공유될 수 있습니다. 개별 메시지는 다른 채널의 메시지를 구별하기 위해 채널 식별자를 전달합니다. MRCPv2 인코딩은 내장된 바이너리 데이터를 전달하는 메커니즘이 있는 텍스트 기반입니다. 이를 통해 인식 문법, 인식 결과, 합성기 음성 마크업 등과 같은 임의의 데이터를 MRCPv2 메시지로 전달할 수 있습니다. 메시지 프레이밍에 대한 정보는 섹션 5를 참조하십시오.

---
### **4.1.  Connecting to the Server**

MRCPv2는 SIP를 SDP와 함께 세션 설정 및 관리 프로토콜로 사용합니다. 클라이언트는 기존 INVITE 및 기타 SIP 요청을 사용하여 MRCPv2 서버에 도달하여 SIP 대화를 설정, 유지 및 종료합니다. SIP를 통한 SDP 제공/응답 교환 모델은 각 리소스에 대한 리소스 제어 채널을 설정하는 데 사용됩니다. SDP 제공/응답 교환은 또한 서버와 오디오의 소스 또는 싱크 간에 미디어 세션을 설정하는 데 사용됩니다.

---
### **4.2.  Managing Resource Control Channels**

클라이언트는 SIP 대화 상자 아래의 각 미디어 처리 리소스를 제어하기 위해 별도의 MRCPv2 리소스 제어 채널이 필요합니다. 고유한 채널 식별자 문자열은 이러한 리소스 제어 채널을 식별합니다. 채널 식별자는 추측하기 어려운 명확한 문자열이며, 그 뒤에 "@"가 오고, 그 다음에 리소스 유형을 지정하는 문자열 토큰이 옵니다. 서버는 채널 식별자를 생성하고 현재 해당 서버에서 할당한 다른 MRCP 채널의 식별자와 충돌하지 않도록 해야 합니다. MRCPv2는 다음과 같은 IANA 등록 미디어 처리 유형을 정의합니다.

리소스. 추가 리소스 유형과 관련 메서드/이벤트 및 상태 머신은 아래 섹션 13에 설명된 대로 추가될 수 있습니다.

```text
          +---------------+----------------------+--------------+
          | Resource Type | Resource Description | Described in |
          +---------------+----------------------+--------------+
          | speechrecog   | Speech Recognizer    | Section 9    |
          | dtmfrecog     | DTMF Recognizer      | Section 9    |
          | speechsynth   | Speech Synthesizer   | Section 8    |
          | basicsynth    | Basic Synthesizer    | Section 8    |
          | speakverify   | Speaker Verification | Section 11   |
          | recorder      | Speech Recorder      | Section 10   |
          +---------------+----------------------+--------------+

                          Table 1: Resource Types
```

SIP INVITE 또는 re-INVITE 트랜잭션과 이것이 전달하는 SDP 제공/응답 교환에는 할당할 리소스 제어 채널을 설명하는 "m=" 줄이 포함됩니다. 세션에서 사용할 각 MRCPv2 리소스에 대해 하나의 SDP "m=" 줄이 있어야 합니다. 이 "m=" 줄에는 "application"이라는 미디어 유형 필드와 "TCP/MRCPv2" 또는 "TCP/TLS/MRCPv2"라는 전송 유형 필드가 있어야 합니다. "m=" 줄의 포트 번호 필드에는 클라이언트의 SDP 제공에서 전송 프로토콜의 "discard" 포트\(TCP의 경우 포트 9\)가 포함되어야 하고 SDP 응답에서 서버의 TCP 수신 포트가 포함되어야 합니다. 그런 다음 클라이언트는 해당 서버 포트에 TCP 또는 TLS 연결을 설정하거나 해당 포트에 이미 설정된 연결을 공유할 수 있습니다. MRCPv2에서는 여러 세션이 동일한 TCP 연결을 공유할 수 있으므로 단일 SDP 문서의 여러 "m=" 줄이 동일한 포트 필드 값을 공유할 수 있습니다. MRCPv2 서버는 통신 채널 공유 외에는 동일한 포트를 사용하는 리소스 간에 어떠한 관계도 가정해서는 안 됩니다.

MRCPv2 리소스는 동일한 채널을 사용하는 다른 리소스와 구별하기 위해 "m=" 줄의 포트 또는 형식 필드를 사용하지 않습니다. 클라이언트는 SDP 제공의 제어 "m=" 줄과 연결된 리소스 속성에서 리소스 유형 식별자를 지정해야 합니다. 서버는 SDP 답변의 제어 "m=" 줄과 연결된 "채널" 속성에서 전체 채널 식별자\(리소스 유형 식별자와 추측하기 어려운 모호하지 않은 문자열 포함\)로 응답해야 합니다. 기존 SDP 사용과 역호환성을 유지하려면 "m=" 줄의 형식 필드에 임의로 선택된 "1" 값이 있어야 합니다.

클라이언트가 세션에 미디어 처리 리소스를 추가하려고 할 때 SIP re-INVITE 요청에서 RFC 3264 \[RFC3264\] 절차에 따라 새로운 SDP 제안을 발행합니다. SDP 제안/답변

이 SIP 트랜잭션에서 수행되는 교환에는 세션에 할당할 새 리소스에 대한 하나 이상의 추가 제어 "m=" 라인이 포함됩니다. 서버는 새 "m=" 라인을 보고 리소스를 할당하고\(사용 가능한 경우\) SIP 응답에 포함된 SDP 답변에서 해당 제어 "m=" 라인으로 응답합니다. 새 리소스를 사용할 수 없는 경우 re-INVITE는 오류 메시지를 수신하고 re-INVITE 전에 진행 중인 기존 미디어 처리가 이전과 동일하게 계속됩니다. 각 유형의 리소스를 두 개 이상 할당하는 것은 불가능합니다. 클라이언트가 모든 유형의 리소스를 두 개 이상 요청하는 경우 서버는 해당 유형의 리소스\(첫 번째 리소스 외\)를 사용할 수 없는 것처럼 동작해야 합니다.

TCP를 전송 프로토콜로 사용하는 MRCPv2 클라이언트와 서버는 여기에 설명된 고려 사항과 함께 TCP 연결을 설정하기 위해 RFC 4145 \[RFC4145\]에 지정된 절차를 사용해야 합니다. 마찬가지로 TCP/TLS를 전송 프로토콜로 사용하는 MRCPv2 클라이언트와 서버는 여기에 설명된 고려 사항과 함께 TLS 연결을 설정하기 위해 RFC 4572 \[RFC4572\]에 지정된 절차를 사용해야 합니다. RFC 4145 \[RFC4145\]에 설명된 대로 a=setup 속성은 클라이언트의 제안에 대해 "활성"이어야 하고 MRCPv2 서버의 답변에 대해 "수동"이어야 합니다. a=connection 속성은 클라이언트에서 MRCPv2 서버로의 첫 번째 제어 "m=" 줄 제안에서 "new" 값을 가져야 합니다. 클라이언트에서 MRCP 서버로 보내는 후속 제어 "m=" 라인은 클라이언트가 새 연결을 설정하거나 기존 연결을 공유할지 여부에 따라 "new" 또는 "existing"을 포함할 수 있습니다. 클라이언트가 "new" 값을 지정하는 경우 서버는 "new" 값으로 응답해야 합니다. 클라이언트가 "existing" 값을 지정하는 경우 서버는 응답해야 합니다. 응답의 합법적인 값은 서버가 기존 연결을 공유하는 것을 선호하는 경우 "existing"이고 그렇지 않은 경우 "new"입니다. 후자의 경우 클라이언트는 새 전송 연결을 시작해야 합니다.

클라이언트가 이 세션에서 리소스를 할당 해제하려고 할 때 RFC 3264 \[RFC3264\]에 따라 새로운 SDP 오퍼를 발행합니다. 여기서 제어 "m=" 라인 포트는 0으로 설정해야 합니다. 이 SDP 오퍼는 SIP re-INVITE 요청에서 전송됩니다. 이렇게 하면 연관된 MRCPv2 식별자와 리소스가 할당 해제됩니다. 서버는 현재 여러 MRCP 채널에서 공유되고 있는 TCP 또는 TLS 연결을 닫아서는 안 됩니다. 연결을 공유할 수 있는 모든 MRCP 채널이 해제되거나 연관된 SIP 대화가 종료되면 클라이언트 또는 서버가 연결을 종료합니다.

클라이언트가 전체 세션과 모든 리소스를 해체하고자 할 때, SIP 세션을 닫기 위해 SIP BYE 요청을 발행해야 합니다. 이렇게 하면 세션에서 할당된 모든 제어 채널과 리소스가 할당 해제됩니다.

모든 서버는 TLS를 지원해야 합니다. 서버는 제어된 환경\(예: 공개 인터넷이 아닌\)에서 TLS 없이 TCP를 사용할 수 있습니다. 이 환경에서는 두 노드가 모두 보호된 경계 내에 있어 제어된 경계 외부의 원격 노드에서 MRCP 서버에 액세스할 수 없습니다. 클라이언트는 SDP 제공을 통해 MRCPv2 세션에 사용할 전송을 선택해야 합니다. 위에 나와 있는 예외 외에도 TCP를 사용할 때 "m=" 줄은 연결 지향 전송을 위한 SDP 사용을 설명하는 RFC4145 \[RFC4145\]를 준수해야 합니다. TLS를 사용할 때 제어 스트림의 SDP "m=" 줄은 TLS를 통한 연결 지향 미디어\(COMEDIA\) \[RFC4572\]를 준수해야 합니다. 이 줄은 TLS를 통한 보안 연결 지향 전송을 설정하기 위한 SDP 사용을 지정합니다.

---
### **4.3.  SIP Session Example**

이 첫 번째 예는 SIP를 사용하여 적절한 리소스로 라우팅하는 힘을 보여줍니다. 이 예에서 INVITE에서 mresources@example.com으로 도메인의 음성 서버 서비스에 대한 요청을 사용하는 것을 주목하세요. 도메인의 SIP 라우팅 기계는 200 OK에서 반환되는 실제 서버 mresources@server.example.com을 찾습니다. "cmid"는 섹션 4.4에 정의되어 있습니다.

이 예시 교환은 신디사이저에 대한 리소스 제어 채널을 추가합니다. 신디사이저도 오디오 스트림을 생성하므로 이 상호 작용은 서버에서 오디오를 보낼 수신 전용 실시간 프로토콜\(RTP\) \[RFC3550\] 미디어 세션도 생성합니다. 미디어 소스/싱크와의 SIP 대화는 MRCP와 독립적이며 표시되지 않습니다.

```text
   C->S:  INVITE sip:mresources@example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf1
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314161 INVITE
          Contact:<sip:sarvi@client.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=sarvi 2890844526 2890844526 IN IP4 192.0.2.12
          s=-
          c=IN IP4 192.0.2.12
          t=0 0
          m=application 9 TCP/MRCPv2 1
          a=setup:active

          a=connection:new
          a=resource:speechsynth
          a=cmid:1
          m=audio 49170 RTP/AVP 0
          a=rtpmap:0 pcmu/8000
          a=recvonly
          a=mid:1

   S->C:  SIP/2.0 200 OK
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf1;received=192.0.32.10
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314161 INVITE
          Contact:<sip:mresources@server.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=- 2890842808 2890842808 IN IP4 192.0.2.11
          s=-
          c=IN IP4 192.0.2.11
          t=0 0
          m=application 32416 TCP/MRCPv2 1
          a=setup:passive
          a=connection:new
          a=channel:32AECB234338@speechsynth
          a=cmid:1
          m=audio 48260 RTP/AVP 0
          a=rtpmap:0 pcmu/8000
          a=sendonly
          a=mid:1

   C->S:  ACK sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf2
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:Sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314161 ACK
          Content-Length:0

                 Example: Add Synthesizer Control Channel
```

이 예시 교환은 이전 그림에서 계속되고 인식기에 대한 추가 리소스 제어 채널을 할당합니다. 인식기는 인식을 위해 오디오 스트림을 수신해야 하므로 이 상호 작용은 오디오 스트림을 sendrecv로 업데이트하여 양방향 RTP 미디어 세션을 만듭니다.

```text
   C->S:  INVITE sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf3
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314162 INVITE
          Contact:<sip:sarvi@client.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=sarvi 2890844526 2890844527 IN IP4 192.0.2.12
          s=-
          c=IN IP4 192.0.2.12
          t=0 0
          m=application 9 TCP/MRCPv2 1
          a=setup:active
          a=connection:existing
          a=resource:speechsynth
          a=cmid:1
          m=audio 49170 RTP/AVP 0 96
          a=rtpmap:0 pcmu/8000
          a=rtpmap:96 telephone-event/8000
          a=fmtp:96 0-15
          a=sendrecv
          a=mid:1
          m=application 9 TCP/MRCPv2 1
          a=setup:active
          a=connection:existing
          a=resource:speechrecog
          a=cmid:1

   S->C:  SIP/2.0 200 OK
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf3;received=192.0.32.10
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314162 INVITE

          Contact:<sip:mresources@server.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=- 2890842808 2890842809 IN IP4 192.0.2.11
          s=-
          c=IN IP4 192.0.2.11
          t=0 0
          m=application 32416 TCP/MRCPv2 1
          a=setup:passive
          a=connection:existing
          a=channel:32AECB234338@speechsynth
          a=cmid:1
          m=audio 48260 RTP/AVP 0 96
          a=rtpmap:0 pcmu/8000
          a=rtpmap:96 telephone-event/8000
          a=fmtp:96 0-15
          a=sendrecv
          a=mid:1
          m=application 32416 TCP/MRCPv2 1
          a=setup:passive
          a=connection:existing
          a=channel:32AECB234338@speechrecog
          a=cmid:1

   C->S:  ACK sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf4
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:Sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314162 ACK
          Content-Length:0

                          Example: Add Recognizer
```

이 예시 교환은 이전 그림에서 계속되고 인식기 채널을 할당 해제합니다. 인식기가 더 이상 오디오 스트림을 수신할 필요가 없으므로 이 상호 작용은 RTP 미디어 세션을 recvonly로 업데이트합니다.

```text
   C->S:  INVITE sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf5
          Max-Forwards:6

          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314163 INVITE
          Contact:<sip:sarvi@client.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=sarvi 2890844526 2890844528 IN IP4 192.0.2.12
          s=-
          c=IN IP4 192.0.2.12
          t=0 0
          m=application 9 TCP/MRCPv2 1
          a=resource:speechsynth
          a=cmid:1
          m=audio 49170 RTP/AVP 0
          a=rtpmap:0 pcmu/8000
          a=recvonly
          a=mid:1
          m=application 0 TCP/MRCPv2 1
          a=resource:speechrecog
          a=cmid:1

   S->C:  SIP/2.0 200 OK
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf5;received=192.0.32.10
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314163 INVITE
          Contact:<sip:mresources@server.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=- 2890842808 2890842810 IN IP4 192.0.2.11
          s=-
          c=IN IP4 192.0.2.11
          t=0 0
          m=application 32416 TCP/MRCPv2 1
          a=channel:32AECB234338@speechsynth
          a=cmid:1
          m=audio 48260 RTP/AVP 0
          a=rtpmap:0 pcmu/8000
          a=sendonly
          a=mid:1

          m=application 0 TCP/MRCPv2 1
          a=channel:32AECB234338@speechrecog
          a=cmid:1

   C->S:  ACK sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bf6
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:Sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:314163 ACK
          Content-Length:0

                      Example: Deallocate Recognizer
```

---
### **4.4.  Media Streams and RTP Ports**

MRCPv2 리소스는 미디어 스트림을 생성하거나 소비하므로 클라이언트나 서버는 미디어 세션을 해당 리소스 또는 리소스와 연결해야 합니다. 여러 리소스를 하나의 미디어 세션과 연결하거나 각 리소스에 별도의 미디어 세션을 할당할 수 있습니다. 또한 필요한 경우 여러 미디어 세션을 하나의 리소스와 연결할 수 있지만 이 시나리오는 현재 리소스 세트에는 유용하지 않습니다. 예를 들어, 신디사이저와 인식기를 "sendrecv" 모드로 열면 동일한 미디어 세션\(m=오디오 라인\)에 연결할 수 있습니다. 또는 인식기는 자체 "sendonly" 오디오 세션을 가질 수 있고 신디사이저는 자체 "recvonly" 오디오 세션을 가질 수 있습니다.

제어 채널과 해당 미디어 세션 간의 연결은 새로운 "리소스 채널 미디어 식별자" 미디어 수준 속성\("cmid"\)을 사용하여 설정됩니다. 이 속성의 유효한 값은 RFC 5888 \[RFC5888\]에 정의된 "mid" 속성의 값입니다. 오디오 "m=" 라인이 두 개 이상 있는 경우 각 오디오 "m=" 라인에는 "mid" 속성이 있어야 합니다. 각 제어 "m=" 라인에는 리소스 제어 채널과 연결된 오디오 "m=" 라인의 "mid" 속성이 일치하는 하나 이상의 "cmid" 속성이 있을 수 있습니다. 제어 "m=" 라인에 "cmid" 속성이 없으면 어떤 미디어와도 연결되지 않습니다. 따라서 이러한 리소스에 대한 작업은 제한됩니다. 예를 들어, 인식기 리소스인 경우 RECOGNIZE 메서드는 처리하기 위해 연결된 미디어가 필요하지만 INTERPRET 메서드는 필요하지 않습니다. "cmid" 속성의 포맷은 다음 ABNF로 설명됩니다.

```text
   cmid-attribute     = "a=cmid:" identification-tag
   identification-tag = token
```

미디어 세션을 MRCPv2 제어 채널에 유연하게 매핑하려면 단일 오디오 "m=" 라인을 여러 리소스와 연관시키거나 각 리소스에 자체 오디오 "m=" 라인을 가질 수 있습니다. 예를 들어, 클라이언트가 인식기와 신시사이저를 할당하여 단일 양방향 오디오 스트림과 연관시키려는 경우 SDP 오퍼에는 두 개의 제어 "m=" 라인과 "sendrecv" 속성이 있는 단일 오디오 "m=" 라인이 포함됩니다. 각 제어 "m=" 라인에는 오디오 "m=" 라인의 "mid"와 값이 일치하는 "cmid" 속성이 있습니다. 반면 클라이언트가 인식기와 신시사이저를 각각 자체 별도 오디오 스트림과 함께 할당하려는 경우 SDP 오퍼에는 두 개의 제어 "m=" 라인\(하나는 인식기용이고 다른 하나는 신시사이저용\)과 두 개의 오디오 "m=" 라인\(하나는 속성 "sendonly"이고 다른 하나는 속성 "recvonly"임\)이 포함됩니다. 인식기 컨트롤 "m=" 줄의 "cmid" 속성은 "sendonly" 오디오 "m=" 줄의 "mid" 값과 일치하고, 신디사이저 컨트롤 "m=" 줄의 "cmid" 속성은 "recvonly" "m=" 줄의 "mid" 속성과 일치합니다.

서버가 두 개 이상의 미디어 처리 리소스와 연관된 미디어 세션에서 미디어\(예: 오디오\)를 수신하는 경우, 해당 미디어를 소비해야 하는 리소스로 미디어를 수신하여 포크하는 것은 서버의 책임입니다. MRCPv2 세션의 여러 리소스가 단일 연관된 미디어 세션에서 전송될 오디오\(또는 다른 미디어\)를 생성하는 경우, 서버는 여러 스트림을 단일 RTP 세션으로 멀티플렉싱하거나 여러 스트림을 하나로 결합하기 위한 임베디드 RTP 믹서\(RFC 3550 \[RFC3550\] 참조\)를 포함하는 것이 책임입니다. 전자의 경우, 미디어 스트림은 다양한 소스에서 생성된 RTP 패킷을 포함하므로 패킷에는 서로 다른 동기화 소스 식별자\(SSRC\)가 있습니다. 후자의 경우, RTP 패킷에는 믹서에서 결합되기 전의 원래 스트림에 해당하는 여러 기여 소스 식별자\(CSRC\)가 포함됩니다. MRCPv2 서버 구현이 멀티플렉싱이나 믹싱을 하지 않는 경우, 클라이언트가 SIP 488 "허용 불가" 오류로 SDP 제공을 거부하여 단일 오디오 스트림에 여러 리소스를 연결하는 것을 허용하지 않아야 합니다. 이 경우 SIP 501 "구현되지 않음" 오류를 반환하는 대규모 설치 기반이 있다는 점에 유의하세요. 이 설치 기반과의 상호 운용성을 용이하게 하기 위해 새로운 구현은 이 컨텍스트에서 501을 레거시 구현으로 알려진 요소에서 수신될 때 488로 처리해야 합니다.

---
### **4.5.  MRCPv2 Message Transport**

이 문서에서 정의한 MRCPv2 메시지는 클라이언트와 서버 간의 TCP 또는 TLS 연결을 통해 전송됩니다. 이 전송 연결과 리소스 제어 채널을 설정하는 방법은 섹션 4.1 및 4.2에서 설명합니다. 다른 SIP 대화에 속하는 클라이언트와 서버 간의 여러 리소스 제어 채널은 하나 이상의 TLS 또는 TCP 연결을 공유할 수 있습니다. 서버와 클라이언트는 이 작동 모드를 지원해야 합니다. 클라이언트와 서버는 개별 MRCPv2 메시지의 Channel-Identifier 헤더 필드에 포함된 MRCPv2 채널 식별자를 사용하여 MRCPv2 메시지를 다른 리소스 채널과 구별해야 합니다\(자세한 내용은 섹션 6.2.1 참조\). 모든 MRCPv2 서버는 TLS를 지원해야 합니다. 서버는 제어된 환경\(예: 공개 인터넷이 아닌\)에서 TLS 없이 TCP를 사용할 수 있습니다. 이 환경에서는 두 노드가 모두 보호된 경계 내에 있으므로 제어된 경계 외부의 원격 노드에서 MRCP 서버에 액세스할 수 없습니다. MRCPv2 세션에 어떤 전송 모드를 사용할지는 클라이언트가 선택해야 합니다.

이후의 대부분의 예에서는 MRCPv2 메시지만 보여주고 MRCPv2 제어 채널을 설정하는 데 사용되었을 수 있는 SIP 메시지는 보여주지 않습니다.

---
### **4.6.  MRCPv2 Session Termination**

MRCP 클라이언트가 MRCP 채널 중 하나에 대한 기본 연결이 닫혔음을 알아차리고 이전에 해당 채널을 닫는 re-INVITE를 시작하지 않은 경우, SIP 대화 상자와 다른 모든 MRCP 채널을 닫기 위해 BYE를 보내야 합니다. MRCP 서버가 MRCP 채널 중 하나에 대한 기본 연결이 닫혔음을 알아차리고 이전에 해당 채널을 닫는 re-INVITE를 수신하여 수락하지 않은 경우, SIP 대화 상자와 다른 모든 MRCP 채널을 닫기 위해 BYE를 보내야 합니다.

---
## **5.  MRCPv2 Specification**

달리 명시되지 않는 한, MRCPv2 메시지는 다양한 언어를 표현할 수 있도록 UTF-8\(RFC 3629 \[RFC3629\]\)로 유니코드 인코딩됩니다. 예를 들어, DEFINE-GRAMMAR\(섹션 9.8\)는 본문에 임의의\(그러나 XML을 통해 지정된\) 인코딩으로 임의의 XML을 포함할 수 있기 때문에 그러한 예외 중 하나입니다. MRCPv2는 또한 일부 로케일에서 다른 문자 세트가 이미 널리 사용되고 있기 때문에 메시지 본문을 다른 문자 세트\(예: ISO 8859-1 \[ISO.8859-1.1987\]\)로 표현할 수 있도록 허용합니다. MRCPv2 헤더\(MRCP 메시지의 첫 번째 줄\)와 헤더 필드 이름은 UTF-8의 US-ASCII 하위 세트만 사용합니다.

줄은 CRLF\(캐리지 리턴, 그 다음 줄 바꿈\)로 종료됩니다. 또한 메시지의 일부 매개변수에는 이진 데이터 또는 여러 줄에 걸친 레코드가 포함될 수 있습니다. 이러한 필드에는 매개변수와 연결된 길이 값이 있으며, 이는 매개변수 바로 뒤에 오는 옥텟 수를 나타냅니다.

---
### **5.1.  Common Protocol Elements**

MRCPv2 메시지 세트는 클라이언트에서 서버로의 요청, 서버에서 클라이언트로의 응답, 서버에서 클라이언트로의 비동기 이벤트로 구성됩니다. 이러한 모든 메시지는 시작 줄, 하나 이상의 헤더 필드, 헤더 필드의 끝을 나타내는 빈 줄\(즉, CRLF 앞에 아무것도 없는 줄\) 및 선택적 메시지 본문으로 구성됩니다.

```text
generic-message  =    start-line
                      message-header
                      CRLF
                      [ message-body ]
```

---
# **message-body     =    *OCTET**
---
# **start-line       =    request-line / response-line / event-line**
---
# **message-header   =  1*(generic-header / resource-header / generic-field)**

```text
resource-header  =    synthesizer-header
                 /    recognizer-header
                 /    recorder-header
                 /    verifier-header
```

메시지 본문에는 리소스별 및 메시지별 데이터가 포함됩니다. 데이터를 전달하는 데 사용되는 실제 미디어 유형은 개별 메시지를 정의하는 섹션에 지정됩니다. 일반 헤더 필드는 섹션 6.2에 설명되어 있습니다.

메시지에 메시지 본문이 포함되어 있는 경우, 메시지에는 메시지 본문의 미디어 유형과 데이터 인코딩을 나타내는 콘텐츠 헤더가 반드시 포함되어야 합니다.

요청, 응답 및 이벤트 메시지\(다음 섹션에 설명됨\)에는 메시지가 준수하는 MRCP 버전이 포함됩니다. 버전 순서, 규정 준수 요구 사항 및 버전 번호 업그레이드와 관련하여 버전 호환성 규칙은 \[H3.1\]을 따릅니다. 버전 정보는 "MRCP"\(\[H3.1\]의 "HTTP"와 대조적으로\) 또는 "MRCP/2.0"\(\[H3.1\]의 "HTTP/1.1"과 대조적으로\)으로 표시됩니다. 이 사양을 준수하기 위해 MRCPv2를 보내는 클라이언트 및 서버

메시지는 반드시 "MRCP/2.0"의 mrcp 버전을 나타내야 합니다. mrcp 버전을 사용하는 ABNF 프로덕션은 섹션 5.2, 5.3 및 5.5에서 찾을 수 있습니다.

```text
   mrcp-version   =    "MRCP" "/" 1*2DIGIT "." 1*2DIGIT
```

메시지 길이 필드는 시작 줄을 포함한 옥텟 단위의 메시지 길이를 지정하며, 메시지 시작 부분에서 두 번째 토큰이어야 합니다.이는 메시지의 프레이밍 및 구문 분석을 보다 간단하게 하기 위한 것입니다.이 필드는 메시지 본문에 인코딩될 수 있는 데이터를 포함한 메시지의 길이를 지정합니다.이 값은 메시지 길이 토큰 자체의 길이로 인해 메시지 길이 값이 변경되는 경우 비효율성을 제거하거나 줄이기 위해 앞에 0이 있는 고정 길이 정수로 지정될 수 있습니다.MRCP의 모든 길이와 마찬가지로 이 값은 10진수 숫자로 해석해야 합니다.특히 앞에 0이 있다고 해서 값이 8진수 숫자로 해석되어야 한다는 것을 나타내지 않습니다.

```text
   message-length =    1*19DIGIT
```

다음 샘플 MRCP 교환은 적절한 메시지 길이 값을 보여줍니다. 메시지 길이 값은 사양의 다른 모든 예에서 제거되었으며, 해당 예에서 사소한 메시지 길이 계산 오류가 발생하는 경우 혼란을 줄이기 위해 '...'로 대체되었습니다.

```text
   C->S:   MRCP/2.0 877 INTERPRET 543266
           Channel-Identifier:32AECB23433801@speechrecog
           Interpret-Text:may I speak to Andre Roy
           Content-Type:application/srgs+xml
           Content-ID:<request1@form-level.store>
           Content-Length:661

           <?xml version="1.0"?>
           <!-- the default grammar language is US English -->
           <grammar xmlns="http://www.w3.org/2001/06/grammar"
                    xml:lang="en-US" version="1.0" root="request">
           <!-- single language attachment to tokens -->
               <rule id="yes">
                   <one-of>
                       <item xml:lang="fr-CA">oui</item>
                       <item xml:lang="en-US">yes</item>
                   </one-of>
               </rule>

           <!-- single language attachment to a rule expansion -->
               <rule id="request">
                   may I speak to
                   <one-of xml:lang="fr-CA">
                       <item>Michel Tremblay</item>
                       <item>Andre Roy</item>
                   </one-of>
               </rule>
           </grammar>

   S->C:   MRCP/2.0 82 543266 200 IN-PROGRESS
           Channel-Identifier:32AECB23433801@speechrecog

   S->C:   MRCP/2.0 634 INTERPRETATION-COMPLETE 543266 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success
           Content-Type:application/nlsml+xml
           Content-Length:441

           <?xml version="1.0"?>
           <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                   xmlns:ex="http://www.example.com/example"
                   grammar="session:request1@form-level.store">
               <interpretation>
                   <instance name="Person">
                       <ex:Person>
                           <ex:Name> Andre Roy </ex:Name>
                       </ex:Person>
                   </instance>
                   <input>   may I speak to Andre Roy </input>
               </interpretation>
           </result>
```

모든 MRCPv2 메시지, 응답 및 이벤트는 반드시 채널 식별자 헤더 필드를 포함해야 하므로 서버나 클라이언트가 동일한 전송 연결을 공유하는 다양한 제어 채널의 메시지를 구별할 수 있습니다.

섹션 8-11의 리소스별 헤더 필드 설명에서, 헤더 필드는 허용된 것으로 명시적으로 나열되지 않는 한 해당 리소스의 메서드\(요청, 응답 또는 이벤트\)에서 허용되지 않습니다. 또한, "이 헤더 필드는 메서드 X에서 발생할 수 있습니다"라는 문구는 헤더 필드가 해당 메서드에서 허용되지만 해당 메서드의 모든 인스턴스에서 사용할 필요는 없음을 나타냅니다.

---
### **5.2.  Request**

MRCPv2 요청은 요청 줄, 메시지 헤더 섹션, 요청 메시지에 대한 특정 데이터가 포함된 선택적 메시지 본문으로 구성됩니다.

클라이언트가 서버로 보내는 요청 메시지의 첫 번째 줄에는 적용할 메서드, 해당 요청에 대한 메서드 태그, 사용 중인 프로토콜 버전이 포함됩니다.

```text
   request-line   =    mrcp-version SP message-length SP method-name
                       SP request-id CRLF
```

mrcp-version 필드는 클라이언트에서 사용되는 MRCP 프로토콜 버전입니다.

메시지 길이 필드는 시작 줄을 포함한 메시지의 길이를 지정합니다.

mrcp-version 및 message-length 필드에 대한 자세한 내용은 섹션 5.1에 나와 있습니다.

method-name 필드는 클라이언트가 서버에 요청하는 특정 요청을 식별합니다. 각 리소스는 MRCPv2 메서드의 하위 집합을 지원합니다. 각 리소스의 하위 집합은 해당 리소스에 대한 사양의 섹션에 정의되어 있습니다.

```text
   method-name    =    generic-method
                  /    synthesizer-method
                  /    recognizer-method
                  /    recorder-method
                  /    verifier-method
```

요청 ID 필드는 클라이언트가 생성하여 서버로 전송하는 부호 없는 32비트 정수로 표현할 수 있는 고유 식별자입니다. 클라이언트는 MRCP 세션 내에서 연속적인 요청에 대해 단조롭게 증가하는 요청 ID를 사용해야 합니다. 요청 ID 공간은 선형적\(즉, mod\(32\)가 아님\)이므로 공간이 래핑되지 않으며 유효성은 간단한 부호 없는 비교 연산으로 확인할 수 있습니다. 클라이언트는 첫 번째 요청에 대해 초기 값을 선택할 수 있지만 긴 세션에서 공간이 고갈되는 것을 방지하기 위해 작은 정수를 사용하는 것이 좋습니다. 서버가 중복 또는 순서가 잘못된 요청을 수신하는 경우 서버는 응답 코드 410으로 요청을 거부해야 합니다. 요청 ID는 MRCP 세션으로 범위가 지정되므로 세션의 모든 TCP 연결과 모든 리소스 채널에서 고유합니다.

서버 리소스는 요청에 대한 응답에서 클라이언트가 지정한 식별자를 사용해야 합니다. 요청이 완료되지 않으면

동기적으로, 이 요청과 관련된 미래의 비동기 이벤트는 반드시 클라이언트가 할당한 요청 ID를 가져야 합니다.

```text
   request-id     =    1*10DIGIT
```

---
### **5.3.  Response**

메서드에 대한 요청 메시지를 수신하고 해석한 후, 서버 리소스는 MRCPv2 응답 메시지로 응답합니다. 응답은 응답 줄과 메시지 헤더 섹션, 그리고 메서드에 대한 특정 데이터를 포함하는 선택적 메시지 본문으로 구성됩니다.

```text
   response-line  =    mrcp-version SP message-length SP request-id
                       SP status-code SP request-state CRLF
```

mrcp-version 필드는 지원되는 경우 요청 버전을 포함해야 합니다. 그렇지 않은 경우 서버에서 지원하는 가장 높은 MRCP 버전을 포함해야 합니다.

메시지 길이 필드는 시작 줄을 포함한 메시지의 길이를 지정합니다.

mrcp-version 및 message-length 필드에 대한 자세한 내용은 섹션 5.1에 나와 있습니다.

응답에 사용된 요청 ID는 해당 요청 메시지에서 전송된 요청 ID와 일치해야 합니다.

상태 코드 필드는 요청의 성공, 실패 또는 기타 상태를 나타내는 3자리 코드입니다.

```text
   status-code     =    3DIGIT
```

요청 상태 필드는 요청에서 시작된 작업이 PENDING, IN-PROGRESS 또는 COMPLETE인지 여부를 나타냅니다. COMPLETE 상태는 요청이 완료될 때까지 처리되었으며 해당 리소스에서 해당 요청 ID를 가진 클라이언트로 더 이상 이벤트나 다른 메시지가 전송되지 않음을 의미합니다. PENDING 상태는 요청이 대기열에 배치되었으며 선입선출 순서로 처리됨을 의미합니다. IN-PROGRESS 상태는 요청이 처리 중이며 아직 완료되지 않았음을 의미합니다. PENDING 또는 IN-PROGRESS 상태는 해당 요청 ID를 가진 추가 이벤트 메시지가 전달될 수 있음을 나타냅니다.

```text
   request-state    =  "COMPLETE"
                    /  "IN-PROGRESS"
                    /  "PENDING"
```

---
### **5.4.  Status Codes**

상태 코드는 성공\(2xx\), 클라이언트 실패\(4xx\), 서버 실패\(5xx\) 코드로 분류됩니다.

```text
     +------------+--------------------------------------------------+
     | Code       | Meaning                                          |
     +------------+--------------------------------------------------+
     | 200        | Success                                          |
     | 201        | Success with some optional header fields ignored |
     +------------+--------------------------------------------------+

                               Success (2xx)

   +--------+----------------------------------------------------------+
   | Code   | Meaning                                                  |
   +--------+----------------------------------------------------------+
   | 401    | Method not allowed                                       |
   | 402    | Method not valid in this state                           |
   | 403    | Unsupported header field                                 |
   | 404    | Illegal value for header field. This is the error for a  |
   |        | syntax violation.                                        |
   | 405    | Resource not allocated for this session or does not      |
   |        | exist                                                    |
   | 406    | Mandatory Header Field Missing                           |
   | 407    | Method or Operation Failed (e.g., Grammar compilation    |
   |        | failed in the recognizer. Detailed cause codes might be  |
   |        | available through a resource-specific header.)           |
   | 408    | Unrecognized or unsupported message entity               |
   | 409    | Unsupported Header Field Value. This is a value that is  |
   |        | syntactically legal but exceeds the implementation's     |
   |        | capabilities or expectations.                            |
   | 410    | Non-Monotonic or Out-of-order sequence number in request.|
   | 411-420| Reserved for future assignment                           |
   +--------+----------------------------------------------------------+

                           Client Failure (4xx)

              +------------+--------------------------------+
              | Code       | Meaning                        |
              +------------+--------------------------------+
              | 501        | Server Internal Error          |
              | 502        | Protocol Version not supported |
              | 503        | Reserved for future assignment |
              | 504        | Message too large              |
              +------------+--------------------------------+

                           Server Failure (5xx)
```

---
### **5.5.  Events**

서버 리소스는 상태 변경이나 특정 이벤트 발생을 클라이언트에 전달해야 할 수 있습니다. 이러한 메시지는 요청이 즉시 완료되지 않고 응답이 PENDING 또는 IN-PROGRESS 상태를 반환할 때 사용됩니다. 요청의 중간 결과 및 이벤트는 서버의 이벤트 메시지를 통해 클라이언트에 표시됩니다. 이벤트 메시지는 이벤트 헤더 줄과 메시지 헤더 섹션, 이벤트 메시지에 대한 특정 데이터가 포함된 선택적 메시지 본문으로 구성됩니다. 헤더 줄에는 해당 요청의 request-id와 상태 값이 있습니다. 요청이 완료되고 이것이 마지막 이벤트인 경우 요청 상태 값은 COMPLETE이고 그렇지 않으면 IN-PROGRESS입니다.

```text
   event-line       =  mrcp-version SP message-length SP event-name
                       SP request-id SP request-state CRLF
```

여기에 사용된 mrcp-version은 요청/응답 줄에서 사용된 것과 동일하며 서버에서 실행 중인 MRCP의 가장 높은 버전을 나타냅니다.

메시지 길이 필드는 시작 줄을 포함한 메시지의 길이를 지정합니다.

mrcp-version 및 message-length 필드에 대한 자세한 내용은 섹션 5.1에 나와 있습니다.

이벤트 이름은 미디어 리소스에서 생성된 이벤트의 특성을 식별합니다. 유효한 이벤트 이름 세트는 이벤트를 생성하는 리소스에 따라 달라집니다. 문서의 해당 리소스별 섹션을 참조하세요.

```text
   event-name       =  synthesizer-event
                    /  recognizer-event
                    /  recorder-event
                    /  verifier-event
```

이벤트에 사용된 요청 ID는 이 이벤트를 발생시킨 요청에서 전송된 요청 ID와 반드시 일치해야 합니다.

요청 상태는 이 이벤트를 발생시킨 요청/명령이 완료되었는지 또는 아직 진행 중인지, 그리고 섹션 5.3에서 언급한 것과 동일한지 여부를 나타냅니다. 요청에 대한 최종 이벤트는 요청 완료를 나타내는 COMPLETE 상태를 갖습니다.

---
## **6.  MRCPv2 Generic Methods, Headers, and Result Structure**

MRCPv2는 모든 리소스에 공통적인 메서드와 헤더 필드 세트를 지원합니다. 이는 여기에서 논의되며, 리소스별 메서드와 헤더 필드는 문서의 해당 리소스별 섹션에서 논의됩니다.

---
### **6.1.  Generic Methods**

MRCPv2는 리소스와 관련된 상태를 읽고 쓰는 두 가지 일반적인 방법을 지원합니다.

```text
   generic-method      =    "SET-PARAMS"
                       /    "GET-PARAMS"
```

이에 대한 설명은 다음 하위 섹션에서 설명합니다.

---
#### **6.1.1.  SET-PARAMS**

클라이언트에서 서버로의 SET-PARAMS 메서드는 MRCPv2 리소스에 세션에 대한 매개변수를 정의하도록 지시합니다. 여기에는 신디사이저의 음성 특성 및 음조, 인식기의 인식 타이머 등이 포함됩니다. 서버가 모든 매개변수를 수락하고 설정하는 경우 응답 상태 코드 200을 반환해야 합니다. 서버 작동에 영향을 미치지 않고 안전하게 무시할 수 있는 일부 선택적 헤더 필드를 무시하도록 선택하는 경우 201을 반환해야 합니다.

전송되는 헤더 필드 중 하나 이상이 올바르지 않은 경우, 다음과 같이 오류 403, 404 또는 409가 반환되어야 합니다.

- 설정되는 헤더 필드 중 하나 이상에 불법적인 값이 있는 경우, 서버는 404 헤더 필드에 대한 불법적인 값으로 요청을 거부해야 합니다.

- 설정된 헤더 필드 중 하나 이상이 리소스에서 지원되지 않는 경우, 서버는 다음 문단에 설명된 경우를 제외하고 403 지원되지 않는 헤더 필드를 통해 요청을 거부해야 합니다.

- 설정되는 헤더 필드 중 하나 이상에 지원되지 않는 값이 있는 경우, 서버는 다음 문단에 설명된 경우를 제외하고 409 지원되지 않는 헤더 필드 값으로 요청을 거부해야 합니다.

오류 404와 다른 오류가 모두 발생한 경우 오류 404만 반환해야 합니다. 오류 403과 409가 모두 발생했지만 오류 404는 발생하지 않은 경우 오류 403만 반환해야 합니다.

오류 403, 404 또는 409가 반환되면 응답에는 클라이언트에서 보낸 그대로 잘못된 또는 지원되지 않는 헤더 필드와 해당 값이 포함되어야 합니다. SET-PARAMS를 사용하여 수정된 세션 매개변수는 개별 요청이나 진행 중인 요청에 명시적으로 지정된 매개변수를 재정의하지 않습니다.

```text
   C->S:  MRCP/2.0 ... SET-PARAMS 543256
          Channel-Identifier:32AECB23433802@speechsynth
          Voice-gender:female
          Voice-variant:3

   S->C:  MRCP/2.0 ... 543256 200 COMPLETE
          Channel-Identifier:32AECB23433802@speechsynth
```

---
#### **6.1.2.  GET-PARAMS**

클라이언트에서 서버로 전송되는 GET-PARAMS 메서드는 MRCPv2 리소스에 현재 세션 매개변수\(예: 신시사이저의 음성 특성 및 음조, 인식기의 인식 타이머 등\)를 요청합니다. 클라이언트가 값 없이 요청에서 보내는 모든 헤더 필드에 대해 서버는 헤더 필드와 해당 값을 응답에 포함해야 합니다. 클라이언트가 매개변수 헤더 필드를 지정하지 않은 경우 서버는 공급업체별 매개변수를 포함하여 응답의 해당 헤더 섹션에 모든 설정 가능한 매개변수와 해당 값을 반환해야 합니다. 이러한 와일드카드 매개변수 요청은 구현에 따라 설정 가능한 매개변수의 수가 많을 수 있으므로 처리 집약적일 수 있습니다. 따라서 클라이언트가 와일드카드 GET-PARAMS 작업을 자주 사용하지 않는 것이 좋습니다. GET-PARAMS는 요청 수준 범위가 있는 값이 아닌 전체 세션에 적용되는 헤더 필드 값을 반환합니다. 예를 들어, Input-Waveform-URI는 요청 수준 헤더 필드이므로 GET-PARAMS에서 반환되지 않습니다.

요청된 모든 헤더 필드가 지원되는 경우 서버는 반드시 응답 상태 코드 200을 반환해야 합니다. 검색되는 헤더 필드 중 일부가 리소스에 지원되지 않는 경우 서버는 반드시 403 지원되지 않는 헤더 필드로 요청을 거부해야 합니다. 이러한 응답에는 클라이언트에서 보낸 그대로 값이 없는 지원되지 않는 헤더 필드가 포함되어야 합니다.

```text
   C->S:   MRCP/2.0 ... GET-PARAMS 543256
           Channel-Identifier:32AECB23433802@speechsynth
           Voice-gender:
           Voice-variant:
           Vendor-Specific-Parameters:com.example.param1;
                         com.example.param2

   S->C:   MRCP/2.0 ... 543256 200 COMPLETE
           Channel-Identifier:32AECB23433802@speechsynth
           Voice-gender:female
           Voice-variant:3
           Vendor-Specific-Parameters:com.example.param1="Company Name";
                         com.example.param2="124324234@example.com"
```

---
### **6.2.  Generic Message Headers**

다음 하위 섹션에 정의된 일반 헤더와 나중에 정의된 리소스별 헤더 필드를 모두 포함하는 모든 MRCPv2 헤더 필드는 RFC 5322 \[RFC5322\]의 섹션 3.1에 제공된 것과 동일한 일반 형식을 따릅니다. 각 헤더 필드는 이름 뒤에 콜론\(":"\)과 값으로 구성됩니다. 헤더 필드 이름은 대소문자를 구분하지 않습니다. 값 앞에는 LWS\(선형 공백\)가 아무리 많아도 올 수 있지만 단일 SP\(공백\)가 선호됩니다. 헤더 필드는 각 추가 줄 앞에 최소한 하나의 SP 또는 HT\(수평 탭\)를 추가하여 여러 줄로 확장할 수 있습니다.

```text
   generic-field  = field-name ":" [ field-value ]
   field-name     = token
   field-value    = *LWS field-content *( CRLF 1*LWS field-content)
   field-content  = <the OCTETs making up the field-value
                    and consisting of either *TEXT or combinations
                    of token, separators, and quoted-string>
```

필드-컨텐츠에는 선행 또는 후행 LWS\(즉, 필드-값의 첫 번째 비공백 문자 앞이나 필드-값의 마지막 비공백 문자 뒤에 발생하는 선형 공백\)가 포함되지 않습니다. 이러한 선행 또는 후행 LWS는 필드 값의 의미를 변경하지 않고 제거할 수 있습니다. 필드-컨텐츠 사이에 발생하는 모든 LWS는 필드 값을 해석하거나 메시지를 다운스트림으로 전달하기 전에 단일 SP로 대체할 수 있습니다.

MRCPv2 서버와 클라이언트는 헤더 필드 순서에 의존해서는 안 됩니다. 일반 헤더 필드를 먼저 보내고, 그 다음에 요청 헤더 또는 응답 헤더 필드를 보내고, 마지막으로 엔티티 헤더 필드로 보내는 것이 좋습니다. 그러나 MRCPv2 서버와 클라이언트는 헤더 필드를 어떤 순서로든 처리할 준비가 되어 있어야 합니다. 이 규칙의 유일한 예외는 메시지에 같은 이름의 헤더 필드가 여러 개 있는 경우입니다.

동일한 이름을 가진 여러 헤더 필드가 메시지에 존재할 수 있는 경우는 해당 헤더 필드의 전체 값이 쉼표로 구분된 목록\[즉, #\(값\)\]으로 정의된 경우에만 가능합니다.

공급업체별 매개변수는 순서에 따라 달라질 수 있으므로, 메시지의 의미를 변경하지 않고 동일한 이름의 여러 헤더 필드를 하나의 "이름:값" 쌍으로 결합할 수 있어야 합니다. 각 후속 값을 첫 번째 값에 추가하여 각각을 쉼표로 구분합니다. 따라서 동일한 이름의 헤더 필드가 수신되는 순서는 결합된 헤더 필드 값의 해석에 중요하며, 따라서 중개자는 메시지를 전달할 때 이러한 값의 순서를 변경해서는 안 됩니다.

```text
   generic-header      =    channel-identifier
                       /    accept
                       /    active-request-id-list
                       /    proxy-sync-id
                       /    accept-charset
                       /    content-type
                       /    content-id
                       /    content-base
                       /    content-encoding
                       /    content-location
                       /    content-length
                       /    fetch-timeout
                       /    cache-control
                       /    logging-tag
                       /    set-cookie
                       /    vendor-specific
```

---
#### **6.2.1.  Channel-Identifier**

모든 MRCPv2 요청, 응답 및 이벤트에는 Channel-Identifier 헤더 필드가 포함되어야 합니다. 이 값은 제어 채널이 세션에 추가되고 서버의 SDP 답변에 있는 "a=channel" 속성을 통해 클라이언트에 전달될 때 서버에서 할당합니다. 헤더 필드 값은 '@' 기호로 구분된 두 부분으로 구성됩니다. 첫 번째 부분은 MRCPv2 세션을 식별하는 명확한 문자열입니다. 두 번째 부분은 섹션 3.1에 나열된 미디어 처리 리소스 유형 중 하나를 지정하는 문자열 토큰입니다. 명확한 문자열\(첫 번째 부분\)은 추측하기 어렵고, 서버에서 관리하는 리소스 인스턴스 중에서 고유해야 하며, 단일 SIP 대화를 통해 해당 서버가 설정된 모든 리소스 채널에 공통적이어야 합니다.

```text
   channel-identifier  = "Channel-Identifier" ":" channel-id CRLF
   channel-id          = 1*alphanum "@" 1*alphanum
```

---
#### **6.2.2.  Accept**

Accept 헤더 필드는 \[H14.1\]에 정의된 구문을 따릅니다. 의미도 동일하지만 Accept 헤더 필드가 없는 경우 서버는 제어되는 리소스 유형에 특정한 기본값을 가정해야 합니다. 이 기본값은 SET-PARAMS 메서드에서 이 헤더 필드를 보내 세션의 리소스에 대해 변경할 수 있습니다. 세션의 리소스에 대한 이 헤더 필드의 현재 기본값은 GET-PARAMS 메서드를 통해 찾을 수 있습니다. 이 헤더 필드는 모든 요청에서 발생할 수 있습니다.

---
#### **6.2.3.  Active-Request-Id-List**

요청에서 이 헤더 필드는 요청이 적용되는 요청 ID 목록을 나타냅니다. 이는 PENDING 또는 IN-PROGRESS인 여러 요청이 있고 클라이언트가 이 요청을 특별히 이들 중 하나 이상에 적용하기를 원할 때 유용합니다.

응답에서 이 헤더 필드는 메서드가 수정하거나 영향을 준 요청 ID 목록을 반환합니다. PENDING 또는 IN-PROGRESS의 요청 상태에 있는 요청이 하나 이상 있을 수 있습니다. PENDING 또는 IN-PROGRESS 요청 중 하나 이상에 영향을 미치는 메서드가 클라이언트에서 서버로 전송되는 경우 응답은 헤더 섹션에 이 명령에 의해 영향을 받거나 수정된 요청 ID 목록을 포함해야 합니다.

Active-Request-Id-List는 이벤트가 아닌 요청과 응답에만 사용됩니다.

예를 들어, Active-Request-Id-List가 없는 STOP 요청이 PENDING 또는 IN-PROGRESS 상태의 SPEAK 요청이 하나 이상 있는 신디사이저 리소스로 전송되는 경우, IN-PROGRESS를 포함한 모든 SPEAK 요청은 반드시 취소되어야 합니다. STOP 요청에 대한 응답에는 종료된 모든 SPEAK 요청의 요청 ID가 Active-Request-Id-List 값에 포함됩니다. STOP 응답을 보낸 후, 서버는 종료된 요청에 대해 SPEAK-COMPLETE 또는 RECOGNITION-COMPLETE 이벤트를 보내서는 안 됩니다.

```text
   active-request-id-list  =  "Active-Request-Id-List" ":"
                              request-id *("," request-id) CRLF
```

---
#### **6.2.4.  Proxy-Sync-Id**

모든 서버 리소스가 "barge-in-able" 이벤트를 생성하면 고유한 태그도 생성됩니다. 태그는 이벤트에서 이 헤더 필드의 값으로 클라이언트로 전송됩니다. 그런 다음 클라이언트는 서버 리소스 간의 중개자 역할을 하며 수신한 Proxy-Sync-Id와 함께 BARGE-IN-OCCURRED 메서드를 신디사이저 서버 리소스로 전송합니다.

서버 리소스에서. 인식기 및 합성기 리소스가 동일한 세션의 일부인 경우 더 빠른 상호 작용 및 응답을 달성하기 위해 함께 작업하도록 선택할 수 있습니다. 여기서 Proxy-Sync-Id는 클라이언트가 중재한 이벤트를 수신하는 리소스가 이 이벤트가 리소스의 직접적인 상호 작용을 통해 처리되었는지 여부를 결정하는 데 도움이 됩니다. 이 헤더 필드는 이벤트 및 BARGE-IN-OCCURRED 메서드에서만 발생할 수 있습니다. 이 헤더 필드의 이름에는 역사적 이유로 '프록시'라는 단어만 포함되며 프록시 서버가 관련되어 있음을 의미하지 않습니다.

```text
   proxy-sync-id    =  "Proxy-Sync-Id" ":" 1*VCHAR CRLF
```

---
#### **6.2.5.  Accept-Charset**

\[H14.2\]를 참조하세요. 이것은 이 요청과 관련된 응답 또는 이벤트에서 반환된 엔터티에 대해 허용되는 문자 집합을 지정합니다. 이것은 RECOGNITION-COMPLETE 이벤트의 NLSML\(자연어 의미 마크업 언어\) 결과에서 사용할 문자 집합을 지정하는 데 유용합니다. 이 헤더 필드는 요청에서만 사용됩니다.

---
#### **6.2.6.  Content-Type**

\[H14.17\]을 참조하세요. MRCPv2는 음성 마크업, 문법 및 인식 결과를 포함하여 콘텐츠에 대해 제한된 등록된 미디어 유형 집합을 지원합니다. 각 MRCPv2 리소스 유형에 적용 가능한 콘텐츠 유형은 문서의 해당 섹션에 지정되어 있으며 IANA에서 유지 관리하는 MIME 미디어 유형 레지스트리에 등록되어 있습니다. 다중 파트 콘텐츠 유형 "multipart/mixed"는 위에 언급된 여러 콘텐츠를 통신하는 데 지원되며, 이 경우 본문 부분에는 MRCPv2 특정 헤더 필드가 포함되어서는 안 됩니다. 이 헤더 필드는 모든 메시지에 나타날 수 있습니다.

```text
   content-type     =    "Content-Type" ":" media-type-value CRLF

   media-type-value =    type "/" subtype *( ";" parameter )

   type             =    token

   subtype          =    token

   parameter        =    attribute "=" value

   attribute        =    token

   value            =    token / quoted-string
```

---
#### **6.2.7.  Content-ID**

이 헤더 필드에는 참조할 수 있는 콘텐츠의 ID 또는 이름이 포함되어 있습니다. 이 헤더 필드는 RFC 2392 \[RFC2392\]의 사양에 따라 작동하며 다중 파트 메시지에서 콘텐츠 모호성 해소에 필요합니다. MRCPv2에서 연관된 콘텐츠가 클라이언트나 서버에 의해 저장될 때마다 이 ID를 사용하여 검색할 수 있어야 합니다. 이러한 콘텐츠는 섹션 13.6에 설명된 '세션' URI 체계로 주소를 지정하여 나중에 세션에서 참조할 수 있습니다. 이 헤더 필드는 모든 메시지에 발생할 수 있습니다.

---
#### **6.2.8.  Content-Base**

Content-Base 엔티티 헤더는 엔티티 내의 상대 URI를 확인하기 위한 기본 URI를 지정하는 데 사용될 수 있습니다.

```text
   content-base      = "Content-Base" ":" absoluteURI CRLF
```

그러나 엔티티 본문 내의 콘텐츠의 기본 URI는 해당 엔티티 본문 내에서 재정의될 수 있습니다. 이에 대한 예로는 다중 부분 미디어가 있으며, 이는 여러 엔티티를 포함할 수 있습니다. 이 헤더 필드는 모든 메시지에 나타날 수 있습니다.

---
#### **6.2.9.  Content-Encoding**

Content-Encoding 엔티티 헤더는 Content-Type에 대한 수정자로 사용됩니다. 존재하는 경우, 해당 값은 엔티티 본문에 적용된 추가 콘텐츠 인코딩을 나타내며, 따라서 Content-Type 헤더 필드에서 참조하는 미디어 유형을 얻기 위해 적용해야 하는 디코딩 메커니즘을 나타냅니다. Content-Encoding은 주로 기본 미디어 유형의 정체성을 잃지 않고 문서를 압축할 수 있도록 하는 데 사용됩니다. SIP 세션을 사용하여 허용된 인코딩을 결정할 수 있습니다\(섹션 7 참조\). 이 헤더 필드는 모든 메시지에 발생할 수 있습니다.

```text
   content-encoding  = "Content-Encoding" ":"
                       *WSP content-coding
                       *(*WSP "," *WSP content-coding *WSP )
                       CRLF
```

콘텐츠 코딩은 \[H3.5\]에 정의되어 있습니다. 사용 예는 Content-Encoding:gzip입니다.

엔터티에 여러 인코딩이 적용된 경우 콘텐츠 인코딩은 적용된 순서대로 나열되어야 합니다.

---
#### **6.2.10.  Content-Location**

Content-Location 엔티티 헤더는 요청된 리소스의 URI와 별도의 위치에서 해당 엔티티에 액세스할 수 있는 경우 메시지에 포함된 엔티티의 리소스 위치를 제공하는 데 사용될 수 있습니다. \[H14.14\]를 참조하십시오.

```text
   content-location  =  "Content-Location" ":"
                        ( absoluteURI / relativeURI ) CRLF
```

Content-Location 값은 요청 시점에 이 특정 엔터티에 해당하는 리소스의 위치를 나타내는 설명입니다. 이 헤더 필드는 최적화 목적으로만 제공됩니다. 이 헤더 필드의 수신자는 전송되는 엔터티가 Content-Location URI에서 검색되었거나 이미 검색되었을 수 있는 것과 동일하다고 가정할 수 있습니다.

예를 들어, 클라이언트가 문법 마크업을 인라인으로 제공하고 이전에 특정 URI에서 검색한 경우 해당 URI는 Content-Location 헤더 필드를 사용하여 엔터티의 일부로 제공될 수 있습니다. 이를 통해 인식기와 같은 리소스가 캐시를 살펴보고 이 문법이 이전에 검색, 컴파일 및 캐시되었는지 확인할 수 있습니다. 이 경우 이전에 컴파일된 문법 객체를 사용하여 최적화할 수 있습니다.

Content-Location이 상대 URI인 경우 상대 URI는 Content-Base URI에 상대적으로 해석됩니다. 이 헤더 필드는 모든 메시지에 나타날 수 있습니다.

---
#### **6.2.11.  Content-Length**

이 헤더 필드에는 메시지 본문 내용의 길이\(즉, 마지막 헤더 필드 뒤에 오는 이중 CRLF 뒤\)가 포함됩니다. HTTP와 달리 헤더 섹션을 넘어 내용을 전달하는 모든 메시지에 포함되어야 합니다. 누락된 경우 기본값인 0이 가정됩니다. 그렇지 않으면 \[H14.13\]에 따라 해석됩니다. 메시지 본문이 필요 없는 메시지에 본문이 포함되어 있는 경우\(즉, Content-Length가 0이 아닌 경우\) 수신자는 메시지 본문의 내용을 무시해야 합니다. 이 헤더 필드는 모든 메시지에 발생할 수 있습니다.

```text
   content-length  =  "Content-Length" ":" 1*19DIGIT CRLF
```

---
#### **6.2.12.  Fetch Timeout**

인식기 또는 합성기가 문서나 다른 리소스를 가져와야 할 때 이 헤더 필드는 해당 URI 액세스 속성을 제어합니다. 이는 서버가 가져올 수 있는 콘텐츠에 대한 시간 초과를 정의합니다.

네트워크를 통해 페치해야 합니다. 값은 밀리초로 해석되며 0에서 구현별 최대값까지입니다. 서버는 긴 시간 초과 값을 허용하는 데 신중해야 합니다. 이 헤더 필드의 기본값은 구현에 따라 다릅니다. 이 헤더 필드는 DEFINE-GRAMMAR, RECOGNIZE, SPEAK, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다.

```text
   fetch-timeout       =   "Fetch-Timeout" ":" 1*19DIGIT CRLF
```

---
#### **6.2.13.  Cache-Control**

서버가 콘텐츠 캐싱을 구현하는 경우 저장된 콘텐츠에 액세스하고 캐싱할 때 HTTP 1.1 \[RFC2616\]의 캐시 정확성 규칙을 준수해야 합니다. 특히 캐시된 URI 또는 문서의 "expires" 및 "cache-control" 헤더 필드는 반드시 준수되어야 하며 이 헤더 필드에서 설정한 Cache-Control 기본값보다 우선합니다. Cache-Control 지시문은 세션 또는 요청에 대한 서버의 기본 캐싱 알고리즘을 정의하는 데 사용됩니다. 지시문의 범위는 지시문이 전송되는 방법에 따라 달라집니다. 지시문이 SET-PARAMS 메서드에서 전송되는 경우 개별 요청의 Cache-Control 헤더 필드로 재정의되지 않는 한 해당 세션 중에 서버가 수행하는 모든 외부 문서 요청에 적용됩니다. 지시문이 다른 요청에서 전송되는 경우 서버가 해당 요청에 대해 수행하는 외부 문서 요청에만 적용됩니다. GET-PARAMS 메서드의 빈 Cache-Control 헤더 필드는 서버에서 서버의 현재 Cache-Control 지시문 설정을 반환하라는 요청입니다. 이 헤더 필드는 요청에서만 발생할 수 있습니다.

```text
   cache-control    =    "Cache-Control" ":"
                         [*WSP cache-directive
                         *( *WSP "," *WSP cache-directive *WSP )]
                         CRLF

   cache-directive     = "max-age" "=" delta-seconds
                       / "max-stale" [ "=" delta-seconds ]
                       / "min-fresh" "=" delta-seconds

   delta-seconds       = 1*19DIGIT
```

여기서, 델타 초는 서버가 메시지 응답이나 데이터를 수신한 순간부터 경과한 초 수를 지정하는 소수 시간 값입니다.

다양한 캐시 지시어 옵션을 사용하면 클라이언트가 서버에 기본 캐시 만료 메커니즘을 재정의하도록 요청할 수 있습니다.

```text
   max-age        Indicates that the client can tolerate the server
                  using content whose age is no greater than the
                  specified time in seconds.  Unless a "max-stale"
                  directive is also included, the client is not willing
                  to accept a response based on stale data.

   min-fresh      Indicates that the client is willing to accept a
                  server response with cached data whose expiration is
                  no less than its current age plus the specified time
                  in seconds.  If the server's cache time-to-live
                  exceeds the client-supplied min-fresh value, the
                  server MUST NOT utilize cached content.

   max-stale      Indicates that the client is willing to allow a server
                  to utilize cached data that has exceeded its
                  expiration time.  If "max-stale" is assigned a value,
                  then the client is willing to allow the server to use
                  cached data that has exceeded its expiration time by
                  no more than the specified number of seconds.  If no
                  value is assigned to "max-stale", then the client is
                  willing to allow the server to use stale data of any
                  age.
```

서버 캐시가 검증 없이 오래된 응답/데이터를 사용하도록 요청받은 경우, 캐시 검증과 관련된 "MUST" 수준 요구 사항\(예: 해당 URI에 관한 HTTP 1.1 사양의 "must-revalidate" Cache-Control 지시어\)과 충돌하지 않는 경우에만 이를 수행할 수 있습니다.

MRCPv2 Cache-Control 지시문과 서버의 캐시된 항목에 모두 "max-age" 지시문이 포함되어 있는 경우, 두 값 중 작은 값이 해당 요청에 대한 캐시된 항목의 신선도를 결정하는 데 사용됩니다.

---
#### **6.2.14.  Logging-Tag**

이 헤더 필드는 서버에서 생성된 로그에 대한 로깅 태그를 설정하거나 검색하기 위한 SET-PARAMS/GET-PARAMS 메서드의 일부로 전송될 수 있습니다. 일단 설정되면 값은 새 값이 설정되거나 세션이 종료될 때까지 유지됩니다. MRCPv2 서버는 시스템 관리자가 로깅 태그가 특정 값으로 설정된 로그 파일 부분만 검사하거나 추출할 수 있도록 출력 로그의 하위 집합을 만드는 메커니즘을 제공할 수 있습니다.

클라이언트가 로깅 태그에 MRCPv2 클라이언트 사용자 에이전트를 식별하는 정보를 포함하는 것이 좋습니다. 그러면 서버에서 주어진 로그 메시지를 생성한 MRCPv2 클라이언트 요청을 판별할 수 있습니다. 또한 MRCPv2 클라이언트가 로깅하지 않는 것이 좋습니다.

신용카드 번호, 국민식별번호 등 개인 식별 정보.

```text
   logging-tag    = "Logging-Tag" ":" 1*UTFCHAR CRLF
```

---
#### **6.2.15.  Set-Cookie**

MRCPv2 서버의 연관된 HTTP 클라이언트가 MRCPv2 클라이언트를 대신하여 처리할 문서를 가져오기 때문에 MRCPv2 서버의 HTTP 클라이언트에 있는 쿠키 저장소는 MRCPv2 클라이언트의 HTTP 클라이언트에 있는 쿠키 저장소의 확장으로 처리됩니다. 이를 위해서는 MRCPv2 클라이언트와 서버가 필요에 따라 공통 쿠키 저장소를 동기화할 수 있어야 합니다. MRCPv2 클라이언트가 저장된 쿠키를 MRCPv2 서버로 푸시하고 MRCPv2 서버에서 MRCPv2 클라이언트로 다시 저장된 새 쿠키를 가져올 수 있도록 하려면 Set-Cookie 엔티티 헤더 필드를 MRCPv2 요청에 포함하여 서버의 쿠키 저장소를 업데이트하고 최종 MRCPv2 응답 또는 이벤트에서 반환하여 나중에 클라이언트의 자체 쿠키 저장소를 업데이트할 수 있습니다. 서버에 저장된 쿠키는 MRCPv2 세션 동안 지속되며 세션이 끝나면 반드시 파기해야 합니다. 쿠키에 대한 지원을 보장하려면 MRCPv2 클라이언트와 서버는 Set-Cookie 엔티티 헤더 필드를 지원해야 합니다.

MRCPv2 클라이언트가 서버로 전송되는 쿠키\(있는 경우\)를 결정합니다. 모든 쿠키를 공유해야 한다는 요구 사항은 없습니다. 오히려 MRCPv2 클라이언트는 MRCPv2 서버가 요청을 처리하는 데 필요한 쿠키만 통신하는 것이 좋습니다.

```text
 set-cookie      =       "Set-Cookie:" cookies CRLF
 cookies         =       cookie *("," *LWS cookie)
 cookie          =       attribute "=" value *(";" cookie-av)
 cookie-av       =       "Comment" "=" value
                 /       "Domain" "=" value
                 /       "Max-Age" "=" value
                 /       "Path" "=" value
                 /       "Secure"
                 /       "Version" "=" 1*19DIGIT
                 /       "Age" "=" delta-seconds

 set-cookie        = "Set-Cookie:" SP set-cookie-string
 set-cookie-string = cookie-pair *( ";" SP cookie-av )
 cookie-pair       = cookie-name "=" cookie-value
 cookie-name       = token
 cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )
 cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E
 token             = <token, defined in [RFC2616], Section 2.2>

 cookie-av         = expires-av / max-age-av / domain-av /
                      path-av / secure-av / httponly-av /
                      extension-av / age-av
 expires-av        = "Expires=" sane-cookie-date
 sane-cookie-date  = <rfc1123-date, defined in [RFC2616], Section 3.3.1>
 max-age-av        = "Max-Age=" non-zero-digit *DIGIT
 non-zero-digit    = %x31-39
 domain-av         = "Domain=" domain-value
 domain-value      = <subdomain>
 path-av           = "Path=" path-value
 path-value        = <any CHAR except CTLs or ";">
 secure-av         = "Secure"
 httponly-av       = "HttpOnly"
 extension-av      = <any CHAR except CTLs or ";">
 age-av            = "Age=" delta-seconds
```

Set-Cookie 헤더 필드는 RFC 6265 \[RFC6265\]에 지정되어 있습니다. "Age" 속성은 쿠키의 수명을 나타내기 위해 이 사양에 도입되었으며 선택 사항입니다. MRCPv2 클라이언트 또는 서버는 HTTP/1.1 사양 \[RFC2616\]의 수명 계산 규칙에 따라 쿠키의 수명을 계산하고 그에 따라 "Age" 속성을 추가해야 합니다. 이 속성은 클라이언트가 HTTP 서버로부터 쿠키를 수신한 후 시간이 지났을 수 있기 때문에 제공됩니다. 클라이언트가 실제 수명만큼 Max-Age를 줄이는 대신 Max-Age를 그대로 전달하고 "Age" 속성을 추가하여 시간이 지났다는 사실을 고려하면서도 수신된 쿠키를 유지합니다.

MRCPv2 클라이언트 또는 서버는 HTTP 원본 서버에서 생략된 경우 RFC 6265에 지정된 대로 "도메인" 및 "경로" 속성에 대한 기본값을 제공해야 합니다. 이 경우 "도메인" 속성 값에 선행 점이 없다는 점에 유의하세요. HTTP 프로토콜을 통해 수신된 명시적으로 지정된 "도메인" 값은 선행 점을 포함하도록 수정될 수 있지만 MRCPv2 클라이언트 또는 서버는 MRCPv2 프로토콜을 통해 수신될 때 "도메인" 값을 수정해서는 안 됩니다.

MRCPv2 클라이언트나 서버는 섹션 6.2에 설명된 대로 동일한 유형의 여러 쿠키 헤더 필드를 단일 "필드-이름:필드-값" 쌍으로 결합할 수 있습니다.

Set-Cookie 헤더 필드는 이후 서버가 HTTP 액세스를 수행하게 되는 모든 요청에서 지정할 수 있습니다. 서버가 HTTP 원본 서버로부터 새 쿠키 정보를 수신하고 쿠키 저장소가 RFC 6265에 따라 수정되었다고 가정하면 서버는 클라이언트가 자체 쿠키 저장소를 업데이트할 수 있도록 적절한 경우 MRCPv2 COMPLETE 응답 또는 이벤트에서 새 쿠키 정보를 반환해야 합니다.

SET-PARAMS 요청은 서버의 쿠키 저장소를 업데이트하기 위해 Set-Cookie 헤더 필드를 지정할 수 있습니다. GET-PARAMS 요청은 "Set-Cookie" 유형 쿠키의 전체 쿠키 저장소를 클라이언트에 반환하는 데 사용될 수 있습니다.

---
#### **6.2.16.  Vendor-Specific Parameters**

이 헤더 필드 세트를 통해 클라이언트는 공급업체별 매개변수를 설정하거나 검색할 수 있습니다.

```text
   vendor-specific          =    "Vendor-Specific-Parameters" ":"
                                 [vendor-specific-av-pair
                                 *(";" vendor-specific-av-pair)] CRLF

   vendor-specific-av-pair  = vendor-av-pair-name "="
                              value

   vendor-av-pair-name     = 1*UTFCHAR
```

이 양식의 헤더 필드는 모든 메서드\(요청\)에서 보낼 수 있으며 서버 측에서 구현별 매개변수를 관리하는 데 사용됩니다. vendor-av-pair-name은 역방향 인터넷 도메인 이름 규칙을 따릅니다\(구문 및 등록 정보는 섹션 13.1.6 참조\). vendor 속성의 값은 "=" 기호 뒤에 지정되며 따옴표로 묶을 수 있습니다. 예:

```text
   com.example.companyA.paramxyz=256
   com.example.companyA.paramabc=High
   com.example.companyB.paramxyz=Low
```

GET-PARAMS에서 사용하여 서버에서 이러한 매개변수의 현재 값을 가져오는 경우, 이 헤더 필드 값은 구현에 맞는 속성 이름의 세미콜론으로 구분된 목록을 포함할 수 있습니다.

---
### **6.3.  Generic Result Structure**

Recognizer 및 Verifier 리소스에 대한 서버의 결과 데이터는 다양한 이벤트의 MRCPv2 메시지 본문에서 형식화된 미디어 엔터티로 전달됩니다. W3C의 초기 초안을 기반으로 하는 XML 마크업인 Natural Language Semantics Markup Language\(NLSML\)는 결과를 클라이언트로 반환하기 위한 기본 표준입니다. 따라서 이러한 리소스 유형을 구현하는 모든 서버는 미디어 유형 'application/nlsml+xml'을 지원해야 합니다. Extensible MultiModal Annotation\(EMMA\) \[W3C.REC-emma-20090210\] 형식도 결과를 반환하는 데 사용할 수 있습니다. 이는 세션 설정 시간에 SDP\(a=resultformat:application/emma+xml\) 또는 SIP\(Allow/Accept\)를 사용하여 형식을 협상하여 수행할 수 있습니다. 예를 들어 SIP를 사용하는 경우 클라이언트가

결과가 EMMA인 경우, MRCPv2 서버는 SDP를 검사하지 않고도 SIP 헤더 필드를 검사하여 EMMA를 지원하는 다른 서버로 요청을 라우팅할 수 있습니다.

MRCPv2는 이 표현을 사용하여 마크업을 생성하고 사용하는 클라이언트와 서버 간에 콘텐츠를 전달합니다. MRCPv2는 NSLML을 특별히 사용하여 MRCPv2 서버의 해당 리소스와 MRCPv2 클라이언트 간에 인식, 등록 및 검증 결과를 전달합니다. 이 결과 형식의 세부 정보는 섹션 6.3.1에 자세히 설명되어 있습니다.

```text
   Content-Type:application/nlsml+xml
   Content-Length:...

   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           xmlns:ex="http://www.example.com/example"
           grammar="http://theYesNoGrammar">
       <interpretation>
           <instance>
                   <ex:response>yes</ex:response>
           </instance>
           <input>OK</input>
       </interpretation>
   </result>

                              Result Example
```

---
#### **6.3.1.  Natural Language Semantics Markup Language**

자연어 의미 마크업 언어\(NLSML\)는 인식기\(등록 포함\) 및 검증기 리소스에서 결과 정보를 전달하도록 설계된 요소와 속성이 있는 XML 데이터 구조입니다. NLSML의 규범적 정의는 섹션 16.1의 RelaxNG 스키마입니다. 이 형식의 요소와 속성은 MRCPv2 네임스페이스에서 정의됩니다. 결과 구조에서 이러한 요소는 결과 내에서 선언된 네임스페이스 접두사로 접두사가 붙거나 해당 네임스페이스에 속하는 것으로 식별된 요소의 자식이어야 합니다. XML 네임스페이스를 사용하는 방법에 대한 자세한 내용은 \[W3C.REC-xml-names11-20040204\]를 참조하십시오. \[W3C.REC-xml-names11-20040204\]의 섹션 2는 네임스페이스와 네임스페이스 접두사를 선언하는 방법에 대한 자세한 내용을 제공합니다.

NLSML의 루트 요소는 <result\>입니다. 선택적인 자식 요소는 <interpretation\>, <enrollment-result\>, <verification-result\>이며, 이 중 적어도 하나는 있어야 합니다. 단일 <result\>는 선택적인 자식 요소 중 하나 또는 전부를 포함할 수 있습니다. <result\> 및 <interpretation\> 요소와 하위 요소 및 속성에 대한 세부 정보

섹션 9.6에서 찾을 수 있습니다. <enrollment-result\> 요소와 하위 요소의 세부 사항은 섹션 9.7에서 찾을 수 있습니다. <verification-result\> 요소와 하위 요소의 세부 사항은 섹션 11.5.2에서 찾을 수 있습니다.

---
## **7.  Resource Discovery**

서버 리소스는 클라이언트가 표준 SIP 메커니즘을 통해 발견하고 해당 기능을 학습할 수 있습니다. 클라이언트는 서버에 SIP OPTIONS 트랜잭션을 발행할 수 있으며, 이는 서버의 기능을 요청하는 효과가 있습니다. 서버는 RFC 3264 \[RFC3264\]에 따라 해당 기능에 대한 SDP 인코딩 설명으로 이러한 요청에 응답해야 합니다. MRCPv2 기능은 미디어 유형 "application"과 전송 유형 "TCP/TLS/MRCPv2" 또는 "TCP/MRCPv2"를 포함하는 단일 "m=" 줄로 설명됩니다. 서버가 지원하는 각 미디어 리소스에 대해 하나의 "리소스" 속성이 있어야 하며, 해당 값으로 리소스 유형 식별자가 있어야 합니다.

SDP 설명에는 오디오 기능과 서버가 지원하는 코더를 설명하는 "m=" 줄도 포함되어야 합니다.

이 예에서 클라이언트는 SIP OPTIONS 방법을 사용하여 MRCPv2 서버의 기능을 쿼리합니다.

```text
   C->S:
        OPTIONS sip:mrcp@server.example.com SIP/2.0
        Via:SIP/2.0/TCP client.atlanta.example.com:5060;
         branch=z9hG4bK74bf7
        Max-Forwards:6
        To:<sip:mrcp@example.com>
        From:Sarvi <sip:sarvi@example.com>;tag=1928301774
        Call-ID:a84b4c76e66710
        CSeq:63104 OPTIONS
        Contact:<sip:sarvi@client.example.com>
        Accept:application/sdp
        Content-Length:0

   S->C:
        SIP/2.0 200 OK
        Via:SIP/2.0/TCP client.atlanta.example.com:5060;
         branch=z9hG4bK74bf7;received=192.0.32.10
        To:<sip:mrcp@example.com>;tag=62784
        From:Sarvi <sip:sarvi@example.com>;tag=1928301774
        Call-ID:a84b4c76e66710
        CSeq:63104 OPTIONS
        Contact:<sip:mrcp@server.example.com>
        Allow:INVITE, ACK, CANCEL, OPTIONS, BYE

        Accept:application/sdp
        Accept-Encoding:gzip
        Accept-Language:en
        Supported:foo
        Content-Type:application/sdp
        Content-Length:...

        v=0
        o=sarvi 2890844536 2890842811 IN IP4 192.0.2.12
        s=-
        i=MRCPv2 server capabilities
        c=IN IP4 192.0.2.12/127
        t=0 0
        m=application 0 TCP/TLS/MRCPv2 1
        a=resource:speechsynth
        a=resource:speechrecog
        a=resource:speakverify
        m=audio 0 RTP/AVP 0 3
        a=rtpmap:0 PCMU/8000
        a=rtpmap:3 GSM/8000
```

- MRCPv2 서버 기능 검색을 위한 SIP OPTIONS 사용

---
## **8.  Speech Synthesizer Resource**

이 리소스는 클라이언트가 제공한 텍스트 마크업을 처리하고 실시간으로 합성 음성 스트림을 생성합니다. 이 리소스의 서버 구현 및 기능에 따라 클라이언트는 음성 특성, 스피커 속도 등과 같은 합성 음성의 매개변수를 지시할 수도 있습니다.

합성기 리소스는 클라이언트의 MRCPv2 요청에 의해 제어됩니다. 마찬가지로 리소스는 이러한 요청에 응답하거나 클라이언트에 비동기 이벤트를 생성하여 합성된 음성 스트림 생성 중에 클라이언트에게 관심 있는 조건을 나타낼 수 있습니다.

이 섹션은 다음 리소스 유형에 적용됩니다.

```text
   o  speechsynth

   o  basicsynth
```

이러한 리소스의 기능은 섹션 3.1에 정의되어 있습니다.

---
### **8.1.  Synthesizer State Machine**

신디사이저는 클라이언트의 MRCPv2 요청을 처리하기 위한 상태 머신을 유지합니다. 아래에 표시된 상태 전환은 신디사이저의 상태를 설명하고 신디사이저 리소스 큐의 헤드에 있는 요청의 상태를 반영합니다. PENDING 상태의 SPEAK 요청은 리소스의 상태에 영향을 미치지 않고 STOP 요청으로 삭제되거나 중지될 수 있습니다.

```text
   Idle                    Speaking                  Paused
   State                   State                     State
     |                        |                          |
     |----------SPEAK-------->|                 |--------|
     |<------STOP-------------|             CONTROL      |
     |<----SPEAK-COMPLETE-----|                 |------->|
     |<----BARGE-IN-OCCURRED--|                          |
     |              |---------|                          |
     |          CONTROL       |-----------PAUSE--------->|
     |              |-------->|<----------RESUME---------|
     |                        |               |----------|
     |----------|             |              PAUSE       |
     |    BARGE-IN-OCCURRED   |               |--------->|
     |<---------|             |----------|               |
     |                        |      SPEECH-MARKER       |
     |                        |<---------|               |
     |----------|             |----------|               |
     |         STOP           |       RESUME             |
     |          |             |<---------|               |
     |<---------|             |                          |
     |<---------------------STOP-------------------------|
     |----------|             |                          |
     |     DEFINE-LEXICON     |                          |
     |          |             |                          |
     |<---------|             |                          |
     |<---------------BARGE-IN-OCCURRED------------------|

                         Synthesizer State Machine
```

---
### **8.2.  Synthesizer Methods**

신디사이저는 다음과 같은 방법을 지원합니다.

```text
   synthesizer-method   =  "SPEAK"
                        /  "STOP"
                        /  "PAUSE"
                        /  "RESUME"
                        /  "BARGE-IN-OCCURRED"
                        /  "CONTROL"
                        /  "DEFINE-LEXICON"
```

---
### **8.3.  Synthesizer Events**

합성기는 다음과 같은 이벤트를 생성할 수 있습니다.

```text
   synthesizer-event    =  "SPEECH-MARKER"
                        /  "SPEAK-COMPLETE"
```

---
### **8.4.  Synthesizer Header Fields**

합성기 방법은 요청 옵션과 연관된 요청, 응답 또는 이벤트를 보강하기 위한 정보를 포함하는 헤더 필드를 포함할 수 있습니다.

```text
   synthesizer-header  =  jump-size
                       /  kill-on-barge-in
                       /  speaker-profile
                       /  completion-cause
                       /  completion-reason
                       /  voice-parameter
                       /  prosody-parameter
                       /  speech-marker
                       /  speech-language
                       /  fetch-hint
                       /  audio-fetch-hint
                       /  failed-uri
                       /  failed-uri-cause
                       /  speak-restart
                       /  speak-length
                       /  load-lexicon
                       /  lexicon-search-order
```

---
#### **8.4.1.  Jump-Size**

이 헤더 필드는 CONTROL 메서드에서 지정할 수 있으며 활성 SPEAK 요청에서 앞으로 또는 뒤로 점프할 양을 제어합니다. '+' 또는 '-'는 현재 재생 중인 내용에 대한 상대 값을 나타냅니다. 이 헤더 필드는 합성된 음성으로 원하는 오프셋으로 SPEAK 요청에서 지정할 수도 있습니다. 이 경우 합성기는 이 시간 동안 음성 마크업으로 말하기 시작해야 합니다. 끝을 넘어 확장되는 오프셋은

생성된 음성은 길이가 0인 오디오를 생성합니다. 지원되는 다양한 음성 길이 단위는 합성기 구현에 따라 달라집니다. 합성기 리소스가 작업에 대한 단위를 지원하지 않는 경우 리소스는 409 "지원되지 않는 헤더 필드 값" 상태 코드로 응답해야 합니다.

```text
   jump-size             =   "Jump-Size" ":" speech-length-value CRLF

   speech-length-value   =   numeric-speech-length
                         /   text-speech-length

   text-speech-length    =   1*UTFCHAR SP "Tag"

   numeric-speech-length =    ("+" / "-") positive-speech-length

   positive-speech-length =   1*19DIGIT SP numeric-speech-unit

   numeric-speech-unit   =   "Second"
                         /   "Word"
                         /   "Sentence"
                         /   "Paragraph"
```

---
#### **8.4.2.  Kill-On-Barge-In**

이 헤더 필드는 "kill-on-barge-in" 지원을 활성화하기 위해 SPEAK 메서드의 일부로 전송될 수 있습니다. 활성화된 경우 SPEAK 메서드는 신호 감지기 리소스에서 감지한 DTMF 입력이나 음성 인식기 리소스에서 감지 또는 인식한 음성 시작에 의해 중단됩니다.

```text
   kill-on-barge-in      =   "Kill-On-Barge-In" ":" BOOLEAN CRLF
```

클라이언트는 모든 소스에서 barge-in-able 이벤트를 수신할 때 BARGE-IN-OCCURRED 메서드를 신디사이저 리소스로 보내야 합니다. 이 소스는 신디사이저 리소스 또는 신호 감지기 리소스일 수 있으며 로컬 또는 분산일 수 있습니다. 이 헤더 필드가 SPEAK 요청에서 지정되지 않았거나 SET-PARAMS에서 명시적으로 설정되지 않은 경우 이 헤더 필드의 기본값은 "true"입니다.

인식기 또는 신호 감지기 리소스가 합성기와 동일한 서버에 있고 둘 다 동일한 세션의 일부인 경우, 서버는 둘 다와 협력하여 합성기에 내부 알림을 제공하여 클라이언트의 BARGE-IN-OCCURRED 이벤트를 기다리지 않고도 오디오를 중지할 수 있습니다.

Kill-On-Barge-In을 사용하여 사용자에게 프롬프트를 재생하고 입력을 요청할 때 최적의 성능을 위해 클라이언트가 SPEAK 요청보다 먼저 RECOGNIZE 요청을 실행하는 것이 일반적으로 권장됩니다.

그리고 사용자 경험. 이런 식으로, 프롬프트가 재생되기 전에 인식기가 온라인 상태이고 사용자의 음성이 처음에 잘리지 않는 것이 보장됩니다\(특히 파워 유저의 경우\).

---
#### **8.4.3.  Speaker-Profile**

이 헤더 필드는 클라이언트에서 서버로의 SET-PARAMS/GET-PARAMS 또는 SPEAK 요청의 일부일 수 있으며 스피커 프로필을 참조하는 URI를 지정합니다. 스피커 프로필은 성별, 악센트 등과 같은 음성 매개변수의 컬렉션입니다.

```text
   speaker-profile       =   "Speaker-Profile" ":" uri CRLF
```

---
#### **8.4.4.  Completion-Cause**

이 헤더 필드는 합성기 리소스에서 클라이언트로 오는 SPEAK-COMPLETE 이벤트에서 지정되어야 합니다. 이는 SPEAK 요청이 완료된 이유를 나타냅니다.

```text
   completion-cause      =   "Completion-Cause" ":" 3DIGIT SP
                             1*VCHAR CRLF

   +------------+-----------------------+------------------------------+
   | Cause-Code | Cause-Name            | Description                  |
   +------------+-----------------------+------------------------------+
   | 000        | normal                | SPEAK completed normally.    |
   | 001        | barge-in              | SPEAK request was terminated |
   |            |                       | because of barge-in.         |
   | 002        | parse-failure         | SPEAK request terminated     |
   |            |                       | because of a failure to      |
   |            |                       | parse the speech markup      |
   |            |                       | text.                        |
   | 003        | uri-failure           | SPEAK request terminated     |
   |            |                       | because access to one of the |
   |            |                       | URIs failed.                 |
   | 004        | error                 | SPEAK request terminated     |
   |            |                       | prematurely due to           |
   |            |                       | synthesizer error.           |
   | 005        | language-unsupported  | Language not supported.      |
   | 006        | lexicon-load-failure  | Lexicon loading failed.      |
   | 007        | cancelled             | A prior SPEAK request failed |
   |            |                       | while this one was still in  |
   |            |                       | the queue.                   |
   +------------+-----------------------+------------------------------+

                Synthesizer Resource Completion Cause Codes
```

---
#### **8.4.5.  Completion-Reason**

이 헤더 필드는 합성기 리소스에서 클라이언트로 오는 SPEAK-COMPLETE 이벤트에서 지정할 수 있습니다. 여기에는 SPEAK 요청 완료의 이유 텍스트가 포함됩니다. 이 헤더 필드는 음성 마크업 텍스트 구문 분석 오류와 같이 실패 이유를 설명하는 텍스트를 전달합니다.

```text
   completion-reason   =   "Completion-Reason" ":"
                           quoted-string CRLF
```

완료 이유 텍스트는 클라이언트가 로그에서 사용하고 디버깅 및 계측 목적으로 제공됩니다. 클라이언트는 완료 이유 텍스트를 해석해서는 안 됩니다.

---
#### **8.4.6.  Voice-Parameter**

이 헤더 필드 세트는 말하는 사람의 음성을 정의합니다.

```text
   voice-parameter    =   voice-gender
                       /   voice-age
                       /   voice-variant
                       /   voice-name

   voice-gender        =   "Voice-Gender:" voice-gender-value CRLF
   voice-gender-value  =   "male"
                       /   "female"
                       /   "neutral"
   voice-age           =   "Voice-Age:" 1*3DIGIT CRLF
   voice-variant       =   "Voice-Variant:" 1*19DIGIT CRLF
   voice-name          =   "Voice-Name:"
                           1*UTFCHAR *(1*WSP 1*UTFCHAR) CRLF
```

"Voice-" 매개변수는 W3C의 음성 합성 마크업 언어 사양\(SSML\) \[W3C.REC-speech-synthesis-20040907\]에 지정된 음성 요소의 유사한 이름의 속성에서 파생됩니다. 이러한 매개변수의 합법적 값은 해당 사양에 정의된 대로입니다.

이러한 헤더 필드는 전체 세션에 대한 기본값을 정의하거나 가져오기 위해 SET-PARAMS 또는 GET-PARAMS 요청으로 전송될 수 있으며, 해당 SPEAK 요청에 대한 기본값을 정의하기 위해 SPEAK 요청으로 전송될 수 있습니다. 물론 SSML 콘텐츠 자체가 SSML 문서 내부에서 이러한 값을 설정할 수 있습니다.

음성 매개변수 헤더 필드는 진행 중인 SPEAK 요청에 영향을 미치고 즉시 동작을 변경하기 위해 CONTROL 메서드로 보낼 수도 있습니다. 신시사이저 리소스가 이 작업을 지원하지 않는 경우 상태 코드 403 "지원되지 않는 헤더 필드"로 요청을 거부해야 합니다.

---
#### **8.4.7.  Prosody-Parameters**

이 헤더 필드 세트는 음성의 음조를 정의합니다.

```text
   prosody-parameter   =   "Prosody-" prosody-param-name ":"
                           prosody-param-value CRLF

   prosody-param-name    =    1*VCHAR

   prosody-param-value   =    1*VCHAR
```

prosody-param-name은 W3C의 음성 합성 마크업 언어 사양 \[W3C.REC-speech-synthesis-20040907\]에 명시된 prosody 요소 아래의 속성 이름 중 하나입니다. prosody-param-value는 해당 사양의 해당 prosody 요소 속성의 값 선택 중 하나입니다.

이러한 헤더 필드는 전체 세션에 대한 기본값을 정의하거나 가져오기 위해 SET-PARAMS 또는 GET-PARAMS 요청에서 전송될 수 있으며, 해당 SPEAK 요청에 대한 기본값을 정의하기 위해 SPEAK 요청에서 전송될 수 있습니다. 또한 이러한 속성은 SSML로 표시된 음성 텍스트의 일부가 될 수 있습니다.

SET-PARAMS 또는 SPEAK 요청의 음성 매개변수 헤더 필드는 음성 데이터가 'text/plain' 유형이고 음성 마크업 형식을 사용하지 않는 경우에만 적용됩니다.

이러한 프로소디 매개변수 헤더 필드는 진행 중인 SPEAK 요청에 영향을 미치고 즉시 동작을 변경하기 위해 CONTROL 메서드에서 전송할 수도 있습니다. 신시사이저 리소스가 이 작업을 지원하지 않는 경우 클라이언트에 403 "지원되지 않는 헤더 필드" 상태 코드로 응답해야 합니다.

---
#### **8.4.8.  Speech-Marker**

이 헤더 필드에는 "타임스탬프" 필드에 타임스탬프 정보가 들어 있습니다. 이것은 네트워크 시간 프로토콜\(NTP\) \[RFC5905\] 타임스탬프, 10진수 형태의 64비트 숫자입니다. 실시간 제어 프로토콜\(RTCP\) \[RFC3550\]을 통해 미디어 스트림의 실시간 프로토콜\(RTP\) \[RFC3550\] 타임스탬프와 동기화되어야 합니다.

마커는 마크업 내에 정의된 북마크입니다. 대부분의 음성 마크업 형식은 음성 텍스트 내에 마커 필드를 임베드하는 메커니즘을 제공합니다. 합성기는 이러한 마커 필드에 도달하면 SPEECH-MARKER 이벤트를 생성합니다. 이 헤더 필드는 SPEECH-MARKER 이벤트의 일부여야 하며 타임스탬프 뒤에 세미콜론으로 구분된 마커 태그 값을 포함해야 합니다. 이러한 이벤트에서 타임스탬프는 합성기가 마커에 해당하는 텍스트를 음성으로 내보낸 시간을 표시합니다.

이 헤더 필드는 STOP, CONTROL 및 BARGE-IN-OCCURRED 메서드에 대한 응답, SPEAK-COMPLETE 이벤트 및 IN-PROGRESS SPEAK 응답에서도 반환되어야 합니다. 이러한 메시지에서 현재 SPEAK에 대한 마커가 발견된 경우 마커 태그 값은 발견된 마지막 임베디드 마커여야 합니다. 현재 SPEAK에 대한 마커가 아직 발견되지 않은 경우 타임스탬프만 필요합니다. 이러한 이벤트에서 이 헤더 필드의 목적은 요청 수명 주기 내의 중요한 이벤트\(SPEAK 처리 시작, SPEAK 처리 종료, CONTROL/STOP/BARGE-IN-OCCURRED 수신\)와 관련된 타임스탬프 정보를 제공하는 것입니다.

```text
   timestamp           =   "timestamp" "=" time-stamp-value

   time-stamp-value    =   1*20DIGIT

   speech-marker       =   "Speech-Marker" ":"
                           timestamp
                           [";" 1*(UTFCHAR / %x20)] CRLF
```

---
#### **8.4.9.  Speech-Language**

이 헤더 필드는 마크업에 언어가 지정되지 않은 경우 음성 데이터의 기본 언어를 지정합니다. 이 헤더 필드의 값은 값에 대해 RFC 5646 \[RFC5646\]을 따라야 합니다. 헤더 필드는 SPEAK, SET-PARAMS 또는 GET-PARAMS 요청에서 발생할 수 있습니다.

```text
   speech-language     =   "Speech-Language" ":" 1*VCHAR CRLF
```

---
#### **8.4.10.  Fetch-Hint**

합성기가 문서나 음성 마크업 또는 오디오 파일과 같은 다른 리소스를 페치해야 할 때 이 헤더 필드는 해당 URI 액세스 속성을 제어합니다. 이는 합성기가 서버에서 콘텐츠를 검색해야 하는 시기에 대한 클라이언트 정책을 제공합니다. "prefetch" 값은 요청을 수신할 때 콘텐츠를 다운로드할 수 있음을 나타내는 반면 "safe"는 콘텐츠를 다운로드해서는 안 됨을 나타냅니다.

실제로 참조될 때까지 다운로드됩니다. 기본값은 "prefetch"입니다. 이 헤더 필드는 SPEAK, SET-PARAMS 또는 GET-PARAMS 요청에서 발생할 수 있습니다.

```text
   fetch-hint          =   "Fetch-Hint" ":" ("prefetch" / "safe") CRLF
```

---
#### **8.4.11.  Audio-Fetch-Hint**

합성기가 문서나 음성 오디오 파일과 같은 다른 리소스를 페치해야 할 때 이 헤더 필드는 해당 URI 액세스 속성을 제어합니다. 이는 합성기가 오디오를 미리 페치하여 음성을 최적화할 수 있는지 여부에 대한 클라이언트 정책을 제공합니다. 값은 "safe"로 지정하여 오디오가 참조될 때만 페치되고, 그 전에는 페치되지 않음을 나타냅니다. "prefetch"로 지정하여 구현에서 오디오를 미리 페치하도록 허용하지만 요구하지는 않음을 나타냅니다. "stream"으로 지정하여 오디오 페치를 스트리밍할 수 있습니다. 기본값은 "prefetch"입니다. 이 헤더 필드는 SPEAK, SET-PARAMS 또는 GET-PARAMS 요청에서 발생할 수 있습니다.

```text
   audio-fetch-hint    =   "Audio-Fetch-Hint" ":"
                           ("prefetch" / "safe" / "stream") CRLF
```

---
#### **8.4.12.  Failed-URI**

합성기 메서드가 합성기가 URI를 가져오거나 액세스해야 하고 액세스가 실패하는 경우, 서버는 메서드 응답의 이 헤더 필드에 실패한 URI를 제공해야 합니다. 단, URI 실패가 여러 개 있는 경우, 서버는 메서드 응답의 이 헤더 필드에 실패한 URI 중 하나를 제공해야 합니다.

```text
   failed-uri          =   "Failed-URI" ":" absoluteURI CRLF
```

---
#### **8.4.13.  Failed-URI-Cause**

합성기 메서드가 합성기가 URI를 가져오거나 액세스해야 하고 액세스가 실패하면 서버는 이 헤더 필드를 통해 메서드 응답의 Failed-URI 헤더 필드에 URI에 대한 URI 특정 또는 프로토콜 특정 응답 코드를 제공해야 합니다. 값 인코딩은 모든 액세스 프로토콜을 수용하기 위해 UTF-8\(RFC 3629 \[RFC3629\]\)입니다. 일부 액세스 프로토콜은 숫자 응답 코드 대신 응답 문자열을 가질 수 있습니다.

```text
   failed-uri-cause    =   "Failed-URI-Cause" ":" 1*UTFCHAR CRLF
```

---
#### **8.4.14.  Speak-Restart**

클라이언트가 현재 말하고 있는 합성기 리소스에 뒤로 점프하라는 CONTROL 요청을 보내고 대상 점프 지점이 현재 SPEAK 요청의 시작 부분보다 앞선 경우, 현재 SPEAK 요청은 음성 데이터의 시작 부분부터 다시 시작해야 하며, CONTROL 요청에 대한 서버의 응답에는 다시 시작을 나타내는 "true" 값을 갖는 이 헤더 필드가 포함되어야 합니다.

```text
   speak-restart       =   "Speak-Restart" ":" BOOLEAN CRLF
```

---
#### **8.4.15.  Speak-Length**

이 헤더 필드는 현재 활성화된 SPEAK 요청의 현재 말하기 지점을 기준으로 말할 수 있는 최대 음성 길이를 제어하기 위해 CONTROL 메서드에서 지정할 수 있습니다. 숫자인 경우 값은 양의 정수여야 합니다. 태그 단위가 있는 헤더 필드가 지정된 경우 태그에 도달하거나 SPEAK 요청이 완료될 때까지 음성 출력이 계속됩니다. 이 헤더 필드는 음성 데이터에서 말할 길이를 나타내기 위해 SPEAK 요청에서 지정할 수 있으며 SPEAK 요청이 시작되는 음성 지점을 기준으로 합니다. 지원되는 다양한 음성 길이 단위는 신시사이저 구현에 따라 다릅니다. 서버가 지정된 단위를 지원하지 않는 경우 서버는 409 "지원되지 않는 헤더 필드 값" 상태 코드로 응답해야 합니다.

```text
   speak-length          =   "Speak-Length" ":" positive-length-value
                             CRLF

   positive-length-value =   positive-speech-length
                         /   text-speech-length

   text-speech-length    =   1*UTFCHAR SP "Tag"

   positive-speech-length =  1*19DIGIT SP numeric-speech-unit

   numeric-speech-unit   =   "Second"
                         /   "Word"
                         /   "Sentence"
                         /   "Paragraph"
```

---
#### **8.4.16.  Load-Lexicon**

이 헤더 필드는 사전을 로드해야 하는지 언로드해야 하는지를 나타내는 데 사용됩니다. 값 "true"는 사전을 로드하지 않은 경우 로드하는 것을 의미하고 값 "false"는 사전이 로드된 경우 언로드하는 것을 의미합니다. 이 헤더 필드의 기본값은 "true"입니다. 이 헤더 필드는 DEFINE-LEXICON 메서드에서 지정할 수 있습니다.

```text
   load-lexicon       =   "Load-Lexicon" ":" BOOLEAN CRLF
```

---
#### **8.4.17.  Lexicon-Search-Order**

이 헤더 필드는 활성 발음 사전 URI 목록과 활성 사전 간의 검색 순서를 지정하는 데 사용됩니다. SSML 문서 내에 지정된 사전은 이 헤더 필드에 지정된 사전보다 우선합니다. 이 헤더 필드는 SPEAK, SET-PARAMS 및 GET-PARAMS 메서드에서 지정할 수 있습니다.

```text
   lexicon-search-order =   "Lexicon-Search-Order" ":"
             "<" absoluteURI ">" *(" " "<" absoluteURI ">") CRLF
```

---
### **8.5.  Synthesizer Message Body**

합성 메시지는 요청, 응답 또는 이벤트와 관련된 추가 정보를 메시지 본문에 포함할 수 있습니다.

---
#### **8.5.1.  Synthesizer Speech Data**

합성기가 말할 마크업된 텍스트는 메시지 본문에 입력된 미디어 엔터티로 지정됩니다. 합성기가 말할 음성 데이터는 메시지 본문에 데이터를 임베드하거나 데이터에 액세스하기 위한 URI를 제공하여 참조로 지정할 수 있습니다. 어느 경우든 음성을 마크업하는 데 사용된 데이터와 형식은 서버에서 지원하는 콘텐츠 유형이어야 합니다.

합성기 리소스를 포함하는 모든 MRCPv2 서버는 일반 텍스트 음성 데이터와 W3C의 음성 합성 마크업 언어\[W3C.REC-speech-synthesis-20040907\]를 모두 지원해야 하며 따라서 미디어 유형 'text/plain' 및 'application/ssml+xml'을 지원해야 합니다. 다른 형식도 지원될 수 있습니다.

URI 참조로 음성 데이터를 가져오는 경우 미디어 유형 'text/uri-list'\(RFC 2483 \[RFC2483\] 참조\)를 사용하여 역참조 시 말할 내용을 포함하는 하나 이상의 URI를 나타냅니다. 음성 URI 목록이 지정된 경우 리소스는 URI가 콘텐츠에 지정된 순서대로 각 URI에서 제공하는 음성 데이터를 말해야 합니다.

MRCPv2 클라이언트와 서버는 'multipart/mixed' 미디어 유형을 지원해야 합니다. 이는 URI와 인라인 음성 데이터를 혼합하여 제공할 때 사용하기에 적합한 미디어 유형입니다. multipart 콘텐츠 블록에 포함된 'text/uri-list', 'application/ssml+xml' 및/또는 'text/plain' 미디어 유형에 대한 콘텐츠가 있을 수 있습니다. 음성 데이터에 사용된 문자 집합 및 인코딩은 표준 미디어 유형 정의에 따라 지정됩니다. multipart 콘텐츠에는 실제 오디오 데이터도 포함될 수 있습니다. 클라이언트는 메모리나 로컬 장치에 저장된 오디오 클립을 녹음하여 SPEAK 요청의 일부로 재생하려고 할 수 있습니다. 오디오 부분은 클라이언트가 multipart 콘텐츠 블록의 일부로 보낼 수 있습니다. 이 오디오는 'multipart/mixed' 미디어 유형 사양에 따라 multipart 콘텐츠 블록의 다른 부분인 음성 마크업 데이터에서 참조됩니다.

```text
   Content-Type:text/uri-list
   Content-Length:...

   http://www.example.com/ASR-Introduction.ssml
   http://www.example.com/ASR-Document-Part1.ssml
   http://www.example.com/ASR-Document-Part2.ssml
   http://www.example.com/ASR-Conclusion.ssml

                             URI List Example

   Content-Type:application/ssml+xml
   Content-Length:...

   <?xml version="1.0"?>
        <speak version="1.0"
               xmlns="http://www.w3.org/2001/10/synthesis"
               xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
               xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
               xml:lang="en-US">
          <p>
            <s>You have 4 new messages.</s>
            <s>The first is from Aldine Turnbet
            and arrived at <break/>
            <say-as interpret-as="vxml:time">0345p</say-as>.</s>

            <s>The subject is <prosody
            rate="-20%">ski trip</prosody></s>
         </p>
        </speak>

                               SSML Example

   Content-Type:multipart/mixed; boundary="break"

   --break
   Content-Type:text/uri-list
   Content-Length:...

   http://www.example.com/ASR-Introduction.ssml
   http://www.example.com/ASR-Document-Part1.ssml
   http://www.example.com/ASR-Document-Part2.ssml
   http://www.example.com/ASR-Conclusion.ssml

   --break
   Content-Type:application/ssml+xml
   Content-Length:...

   <?xml version="1.0"?>
       <speak version="1.0"
              xmlns="http://www.w3.org/2001/10/synthesis"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
              xml:lang="en-US">
          <p>
            <s>You have 4 new messages.</s>
            <s>The first is from Stephanie Williams
            and arrived at <break/>
            <say-as interpret-as="vxml:time">0342p</say-as>.</s>

            <s>The subject is <prosody
            rate="-20%">ski trip</prosody></s>
          </p>
       </speak>
   --break--

                             Multipart Example
```

---
#### **8.5.2.  Lexicon Data**

클라이언트에서 서버로의 신시사이저 사전 데이터는 인라인 또는 참조로 제공될 수 있습니다. 어느 쪽이든 MRCPv2 요청 메시지의 메시지 본문에 입력된 미디어로 전달됩니다\(섹션 8.14 참조\).

메시지에 사전이 인라인으로 지정되면 클라이언트는 콘텐츠 헤더 필드의 일부로 해당 사전의 콘텐츠 ID를 제공해야 합니다. 서버는 세션 기간 동안 해당 콘텐츠 ID와 연관된 사전을 저장해야 합니다. 저장된 사전은 동일한 콘텐츠 ID로 새 사전을 정의하여 덮어쓸 수 있습니다.

Content-ID와 연관된 사전은 '세션' URI 체계를 통해 참조될 수 있습니다\(섹션 13.6 참조\).

사전 데이터가 외부 URI 참조로 지정된 경우 미디어 유형 'text/uri-list'\(RFC 2483 \[RFC2483\] 참조\)는 사전 데이터를 얻기 위해 역참조될 수 있는 하나 이상의 URI를 나열하는 데 사용됩니다. 모든 MRCPv2 서버는 "http" 및 "https" URI 액세스 메커니즘을 지원해야 하며 다른 메커니즘을 지원할 수 있습니다.

메시지 본문의 데이터가 URI와 인라인 사전 데이터의 혼합으로 구성된 경우 'multipart/mixed' 미디어 유형이 사용됩니다. 사전 데이터에서 사용되는 문자 집합과 인코딩은 표준 미디어 유형 정의에 따라 지정할 수 있습니다.

---
### **8.6.  SPEAK Method**

SPEAK 요청은 합성기 리소스에 음성 텍스트를 제공하고 음성 합성 및 스트리밍을 시작합니다. SPEAK 메서드는 합성되는 음성의 동작을 변경하는 음성 및 프로소디 헤더 필드와 말할 실제 마크업된 텍스트를 포함하는 입력된 미디어 메시지 본문을 포함할 수 있습니다.

SPEAK 메서드 구현은 해당 작업의 일부인 모든 외부 URI를 페치해야 합니다. 캐싱이 구현된 경우 이 URI 페치는 캐시에서 페치할지 외부 서버에서 페치할지 결정할 때 메서드와 관련된 캐시 제어 힌트 및 매개변수 헤더 필드를 따라야 합니다. 메서드에 이러한 힌트/매개변수가 지정되지 않은 경우 SET-PARAMS/GET-PARAMS를 사용하여 세션에 설정된 값이 적용됩니다. 세션에 설정되지 않은 경우 기본값이 적용됩니다.

음성 매개변수를 적용할 때 세 가지 수준의 우선순위가 있습니다. 가장 높은 우선순위는 음성 마크업 텍스트 내에 지정된 우선순위이고, 그 다음은 SPEAK 요청의 헤더 필드에 지정된 우선순위이며, 따라서 해당 SPEAK 요청에만 적용되고, 그 다음은 SET-PARAMS 요청을 사용하여 설정할 수 있는 세션 기본값이며, 세션 중에 호출되는 후속 메서드에 적용됩니다.

SPEAK 요청이 서버에 도착했을 때 리소스가 유휴 상태였고 SPEAK 메서드가 활발하게 처리 중이었다면 리소스는 성공 상태 코드와 요청 상태 IN-PROGRESS로 즉시 응답합니다.

SPEAK 메서드가 서버에 도착했을 때 리소스가 말하기 또는 일시 중지 상태인 경우, 즉 이전 SPEAK 요청을 처리하는 중이면 상태는 PENDING 요청 상태와 함께 성공을 반환합니다. 서버는 SPEAK 요청을 신디사이저 리소스 요청 대기열에 넣습니다. 요청 대기열은 다음과 같이 작동합니다.

엄격히 FIFO: 요청은 수신 순서대로 직렬로 처리됩니다. 현재 SPEAK가 실패하면 보류 큐의 모든 SPEAK 메서드가 취소되고 각각 "취소됨"의 Completion-Cause를 갖는 SPEAK-COMPLETE 이벤트를 생성합니다.

합성기 리소스의 경우, SPEAK는 IN-PROGRESS 또는 PENDING의 요청 상태를 반환할 수 있는 유일한 메서드입니다. 텍스트가 합성되어 미디어 스트림으로 재생되면 리소스는 SPEAK 요청의 요청 ID와 COMPLETE의 요청 상태를 사용하여 SPEAK-COMPLETE 이벤트를 발행합니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543257
         Channel-Identifier:32AECB23433802@speechsynth
         Voice-gender:neutral
         Voice-Age:25
         Prosody-volume:medium
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
            <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams and arrived at
                <break/>
                <say-as interpret-as="vxml:time">0342p</say-as>.
                </s>
             <s>The subject is
                    <prosody rate="-20%">ski trip</prosody>
             </s>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543257 200 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857206027059

   S->C: MRCP/2.0 ... SPEAK-COMPLETE 543257 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Completion-Cause:000 normal
         Speech-Marker:timestamp=857206027059

                               SPEAK Example
```

---
### **8.7.  STOP**

클라이언트에서 서버로 전송되는 STOP 메서드는 합성기 리소스에 무언가를 말하고 있는 경우 말하기를 중지하라고 알려줍니다.

STOP 요청은 Active-Request-Id-List 헤더 필드와 함께 보내어 대기열에 있을 수 있는 0개 이상의 특정 SPEAK 요청을 중지하고 응답 상태 코드 200 "Success"를 반환할 수 있습니다. STOP 요청에서 Active-Request-Id-List 헤더 필드가 전송되지 않으면 서버는 모든 미처리 SPEAK 요청을 종료합니다.

STOP 요청이 하나 이상의 PENDING 또는 IN-PROGRESS SPEAK 요청을 성공적으로 종료한 경우 응답에는 종료된 SPEAK 요청 ID를 열거하는 Active-Request-Id-List 헤더 필드가 포함되어야 합니다. 그렇지 않은 경우 응답에 Active-Request-Id-List 헤더 필드가 없습니다. 이러한 종료된 요청에 대해 SPEAK-COMPLETE 이벤트가 전송되지 않습니다.

진행 중이던 SPEAK 요청이 말하기를 중단한 경우, 다음에 보류 중인 SPEAK 요청\(있는 경우\)은 리소스에서 진행 중 상태가 되고 말하기 상태로 전환됩니다.

진행 중이고 일시 중지된 SPEAK 요청이 중지되면, 다음에 보류 중인 SPEAK 요청\(있는 경우\)은 진행 중이 되고 일시 중지 상태가 됩니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543258
         Channel-Identifier:32AECB23433802@speechsynth
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
           <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams and arrived at
                <break/>
                <say-as interpret-as="vxml:time">0342p</say-as>.</s>
             <s>The subject is
                 <prosody rate="-20%">ski trip</prosody></s>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543258 200 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857206027059

   C->S: MRCP/2.0 ... STOP 543259
         Channel-Identifier:32AECB23433802@speechsynth

   S->C: MRCP/2.0 ... 543259 200 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Active-Request-Id-List:543258
         Speech-Marker:timestamp=857206039059

                               STOP Example
```

---
### **8.8.  BARGE-IN-OCCURRED**

BARGE-IN-OCCURRED 방법은 합성기 리소스와 함께 사용될 경우, 바지인 가능 이벤트를 감지한 클라이언트에게 합성기 리소스에 이벤트 발생을 통신할 수 있는 수단을 제공합니다.

이 방법은 두 가지 시나리오에서 유용합니다.

1. 클라이언트가 입력 미디어에서 DTMF 숫자나 기타 통화 가능 이벤트를 감지했으며 이를 합성기 리소스에 전달하려고 합니다.

1. 인식기 리소스와 합성기 리소스는 다른 서버에 있습니다. 이 경우 클라이언트는 두 서버의 중개자 역할을 합니다. 클라이언트는 인식 리소스에서 이벤트를 수신하고 합성기에 BARGE-IN-OCCURRED 요청을 보냅니다. 이러한 경우 BARGE-IN-OCCURRED 메서드는 원래 이벤트를 생성하는 리소스에서 수신한 Proxy-Sync-Id 헤더 필드도 갖습니다.

SPEAK 요청이 kill-on-barge-in이 활성화된 상태에서 활성화되고\(8.4.2절 참조\) BARGE-IN-OCCURRED 이벤트가 수신되면 신디사이저는 즉시 오디오 스트리밍을 중지해야 합니다. 또한 현재 활성화된 요청 뒤에 대기 중인 모든 음성 요청을 종료해야 합니다. barge-in이 활성화되었는지 여부와 관계없이요. barge-in 가능한 SPEAK 요청이 재생 중이었고 종료된 경우 응답에는 종료된 모든 SPEAK 요청의 요청 ID를 나열하는 Active-Request-Id-List 헤더 필드가 포함되어야 합니다. 서버는 이러한 요청에 대해 SPEAK-COMPLETE 이벤트를 생성하지 않습니다.

BARGE-IN-OCCURRED 메서드의 결과로 합성기 리소스에 의해 종료된 SPEAK 요청이 없는 경우, 서버는 BARGE-IN-OCCURRED에 200 "성공" 상태 코드로 응답해야 하며, 응답에는 Active-Request-Id-List 헤더 필드가 포함되어서는 안 됩니다.

신디사이저와 인식기 리소스가 동일한 MRCPv2 세션의 일부인 경우 인식기와 신디사이저가 직접 상호 작용하는 경우 더 빠른 kill-on-barge-in 응답을 위해 최적화할 수 있습니다. 이러한 경우 클라이언트는 신디사이저에 BARGE-IN-OCCURRED 메서드를 호출하여 인식기의 START-OF-INPUT 이벤트에 여전히 반응해야 합니다. 클라이언트는 PENDING 또는 IN-PROGRESS 상태의 신디사이저 리소스에 대한 미처리 요청이 있는 경우 BARGE-IN-OCCURRED를 호출해야 합니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543258
         Channel-Identifier:32AECB23433802@speechsynth
         Voice-gender:neutral
         Voice-Age:25
         Prosody-volume:medium
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
           <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams and arrived at
                <break/>
                <say-as interpret-as="vxml:time">0342p</say-as>.</s>
             <s>The subject is
                <prosody rate="-20%">ski trip</prosody></s>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543258 200 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857206027059

   C->S: MRCP/2.0 ... BARGE-IN-OCCURRED 543259
         Channel-Identifier:32AECB23433802@speechsynth
         Proxy-Sync-Id:987654321

   S->C:MRCP/2.0 ... 543259 200 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Active-Request-Id-List:543258
         Speech-Marker:timestamp=857206039059

                         BARGE-IN-OCCURRED Example
```

---
### **8.9.  PAUSE**

클라이언트에서 서버로의 PAUSE 메서드는 신디사이저 리소스에 무언가를 말하고 있는 경우 음성 출력을 일시 중지하라고 알립니다. SPEAK가 활성화되지 않은 세션에서 PAUSE 메서드가 발행되면 서버는 상태 코드 402 "이 상태에서는 메서드가 유효하지 않음"으로 응답해야 합니다. SPEAK가 활성화되고 일시 중지된 세션에서 PAUSE 메서드가 발행되면 서버는 상태 코드 200 "성공"으로 응답해야 합니다. SPEAK 요청이 활성화된 경우 서버는 일시 중지된 SPEAK 요청의 요청 ID가 포함된 값을 갖는 Active-Request-Id-List 헤더 필드를 반환해야 합니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543258
         Channel-Identifier:32AECB23433802@speechsynth
         Voice-gender:neutral
         Voice-Age:25
         Prosody-volume:medium
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
           <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams and arrived at
                <break/>
                <say-as interpret-as="vxml:time">0342p</say-as>.</s>

             <s>The subject is
                <prosody rate="-20%">ski trip</prosody></s>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543258 200 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857206027059

   C->S: MRCP/2.0 ... PAUSE 543259
         Channel-Identifier:32AECB23433802@speechsynth

   S->C: MRCP/2.0 ... 543259 200 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Active-Request-Id-List:543258

                               PAUSE Example
```

---
### **8.10.  RESUME**

클라이언트에서 서버로의 RESUME 메서드는 일시 중지된 신시사이저 리소스에 말하기를 재개하라고 알립니다. 활성 SPEAK 요청이 없는 세션에서 RESUME 요청이 발행되면 서버는 상태 코드 402 "이 상태에서는 메서드가 유효하지 않음"으로 응답해야 합니다. 말하기 중인 활성 SPEAK 요청\(즉, 일시 중지되지 않음\)이 있는 세션에서 RESUME 요청이 발행되면 서버는 상태 코드 200 "성공"으로 응답해야 합니다. SPEAK 요청이 일시 중지된 경우 서버는 재개된 SPEAK 요청의 요청 ID가 포함된 값을 갖는 Active-Request-Id-List 헤더 필드를 반환해야 합니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543258
         Channel-Identifier:32AECB23433802@speechsynth
         Voice-gender:neutral
         Voice-age:25
         Prosody-volume:medium
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
           <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams and arrived at
                <break/>
                <say-as interpret-as="vxml:time">0342p</say-as>.</s>
             <s>The subject is
                <prosody rate="-20%">ski trip</prosody></s>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543258 200 IN-PROGRESS@speechsynth
         Channel-Identifier:32AECB23433802
         Speech-Marker:timestamp=857206027059

   C->S: MRCP/2.0 ... PAUSE 543259
         Channel-Identifier:32AECB23433802@speechsynth

   S->C: MRCP/2.0 ... 543259 200 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Active-Request-Id-List:543258

   C->S: MRCP/2.0 ... RESUME 543260
         Channel-Identifier:32AECB23433802@speechsynth

   S->C: MRCP/2.0 ... 543260 200 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Active-Request-Id-List:543258

                              RESUME Example
```

---
### **8.11.  CONTROL**

클라이언트에서 서버로의 CONTROL 메서드는 말하는 신디사이저에게 말하는 내용을 즉석에서 수정하라고 말합니다. 이 메서드는 말하는 내용에서 앞으로 또는 뒤로 점프하고, 스피커 속도, 스피커 매개변수 등을 변경하도록 신디사이저에 요청하는 데 사용됩니다. 현재 진행 중인 SPEAK 요청에만 영향을 미칩니다. 신디사이저 리소스의 구현 및 기능에 따라 CONTROL 요청의 헤더 필드에서 지정한 다양한 수정 사항을 지원하거나 지원하지 않을 수 있습니다.

클라이언트가 CONTROL 메서드를 호출하여 앞으로 점프하고 작업이 활성 SPEAK 메서드 텍스트의 끝을 넘어갈 때에도 CONTROL 요청은 여전히 성공합니다. 활성 SPEAK 요청이 완료되고 CONTROL 메서드에 대한 응답에 따라 SPEAK-COMPLETE 이벤트를 반환합니다. 대기열에 SPEAK 요청이 더 있으면 신디사이저 리소스는 대기열의 다음 SPEAK 요청 시작 부분에서 시작합니다.

클라이언트가 뒤로 점프하기 위해 CONTROL 메서드를 호출하고 작업이 활성 SPEAK 메서드의 음성 데이터 시작 또는 시작을 넘어 점프하는 경우 CONTROL 요청은 여전히 성공합니다. CONTROL 요청에 대한 응답에는 speak-restart 헤더 필드가 포함되고 활성 SPEAK 요청은 음성 데이터 시작부터 다시 시작합니다.

클라이언트가 음성 마크업 텍스트를 여러 개의 SPEAK 요청으로 나누고 싶은 경우, 이 두 가지 동작을 사용하여 여러 음성 요청을 되감거나 빨리 전달할 수 있습니다.

CONTROL 메서드를 수신했을 때 SPEAK 요청이 활성화되어 있으면, 서버는 활성화되어 있던 SPEAK 요청의 요청 ID를 포함하는 Active-Request-Id-List 헤더 필드를 반환해야 합니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543258
         Channel-Identifier:32AECB23433802@speechsynth
         Voice-gender:neutral
         Voice-age:25
         Prosody-volume:medium
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
           <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams
                and arrived at <break/>
                <say-as interpret-as="vxml:time">0342p</say-as>.</s>

             <s>The subject is <prosody
                rate="-20%">ski trip</prosody></s>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543258 200 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857205016059

   C->S: MRCP/2.0 ... CONTROL 543259
         Channel-Identifier:32AECB23433802@speechsynth
         Prosody-rate:fast

   S->C: MRCP/2.0 ... 543259 200 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Active-Request-Id-List:543258
         Speech-Marker:timestamp=857206027059

   C->S: MRCP/2.0 ... CONTROL 543260
         Channel-Identifier:32AECB23433802@speechsynth
         Jump-Size:-15 Words

   S->C: MRCP/2.0 ... 543260 200 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Active-Request-Id-List:543258
         Speech-Marker:timestamp=857206039059

                              CONTROL Example
```

---
### **8.12.  SPEAK-COMPLETE**

이것은 해당 SPEAK 요청이 완료되었음을 나타내는 합성기 리소스에서 클라이언트로 보내는 이벤트 메시지입니다. request-id 필드는 방금 완료된 음성을 시작한 SPEAK 요청의 request-id와 일치합니다. request-state 필드는 서버에서 COMPLETE로 설정되어 해당 request-id가 있는 마지막 이벤트임을 나타냅니다. Completion-Cause 헤더 필드는 SPEAK가 정상적으로 완료되었는지 또는 오류, kill-on-barge-in 등으로 인해 완료되었는지와 같은 요청 완료의 상태 및 이유와 관련된 원인 코드를 지정합니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543260
         Channel-Identifier:32AECB23433802@speechsynth
         Voice-gender:neutral
         Voice-age:25
         Prosody-volume:medium
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
           <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams
                and arrived at <break/>
                <say-as interpret-as="vxml:time">0342p</say-as>.</s>
             <s>The subject is
                <prosody rate="-20%">ski trip</prosody></s>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543260 200 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857206027059

   S->C: MRCP/2.0 ... SPEAK-COMPLETE 543260 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Completion-Cause:000 normal
         Speech-Marker:timestamp=857206039059

                          SPEAK-COMPLETE Example
```

---
### **8.13.  SPEECH-MARKER**

이것은 합성기가 현재 처리 중인 음성 마크업에서 마커 태그를 발견했을 때 합성기 리소스에서 클라이언트에 생성하는 이벤트입니다. request-id 필드의 값은 해당 SPEAK 요청의 값과 일치해야 합니다. request-state 필드는 음성이 아직 완료되지 않았으므로 "IN-PROGRESS" 값을 가져야 합니다. 합성기가 음성 마크업에서 어디에 있는지 설명하는 음성 마커 태그 적중 값은 출력 음성 스트림에서 마커가 발견된 순간을 나타내는 NTP 타임스탬프와 함께 Speech-Marker 헤더 필드에 반환되어야 합니다. SPEECH-MARKER 이벤트는 또한 Pending-State\(즉, 대기열\)의 SPEAK 요청이 IN-PROGRESS 상태로 변경되고 말하기 시작하면 null 마커 값과 출력 NTP 타임스탬프로 생성되어야 합니다. NTP 타임스탬프는 표준 RTCP 장치를 통해 음성 스트림을 생성하는 데 사용된 RTP 타임스탬프와 동기화되어야 합니다.

```text
   C->S: MRCP/2.0 ... SPEAK 543261
         Channel-Identifier:32AECB23433802@speechsynth
         Voice-gender:neutral
         Voice-age:25
         Prosody-volume:medium
         Content-Type:application/ssml+xml
         Content-Length:...

         <?xml version="1.0"?>
           <speak version="1.0"
                xmlns="http://www.w3.org/2001/10/synthesis"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                   http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                xml:lang="en-US">
            <p>
             <s>You have 4 new messages.</s>
             <s>The first is from Stephanie Williams
                and arrived at <break/>

                <say-as interpret-as="vxml:time">0342p</say-as>.</s>
                <mark name="here"/>
             <s>The subject is
                <prosody rate="-20%">ski trip</prosody>
             </s>
             <mark name="ANSWER"/>
            </p>
           </speak>

   S->C: MRCP/2.0 ... 543261 200 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857205015059

   S->C: MRCP/2.0 ... SPEECH-MARKER 543261 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857206027059;here

   S->C: MRCP/2.0 ... SPEECH-MARKER 543261 IN-PROGRESS
         Channel-Identifier:32AECB23433802@speechsynth
         Speech-Marker:timestamp=857206039059;ANSWER

   S->C: MRCP/2.0 ... SPEAK-COMPLETE 543261 COMPLETE
         Channel-Identifier:32AECB23433802@speechsynth
         Completion-Cause:000 normal
         Speech-Marker:timestamp=857207689259;ANSWER

                           SPEECH-MARKER Example
```

---
### **8.14.  DEFINE-LEXICON**

클라이언트에서 서버로의 DEFINE-LEXICON 방법은 사전을 제공하고 서버에 사전을 로드하거나 언로드하도록 지시합니다\(8.4.16절 참조\). 사전의 미디어 유형은 Content-Type 헤더에 제공됩니다\(8.5.2절 참조\). 이러한 미디어 유형 중 하나는 발음 사전 사양\(PLS\) \[W3C.REC-pronunciation-lexicon-20081014\] \[RFC4267\]의 "application/pls+xml"입니다.

서버 리소스가 대화 중 또는 일시 중지 상태인 경우 서버는 402 "이 상태에서는 메서드가 유효하지 않습니다"라는 실패 상태 코드로 응답해야 합니다.

리소스가 유휴 상태이고 사전을 성공적으로 로드/언로드할 수 있는 경우, 상태는 200 "성공" 상태 코드를 반환해야 하며 요청 상태는 COMPLETE여야 합니다.

예를 들어, 다운로드가 실패하거나 사전이 지원되지 않는 형식인 경우 합성기가 어떤 이유로 사전을 정의할 수 없는 경우, 서버는 실패 상태 코드 407과 실패 이유를 설명하는 완료 원인 헤더 필드로 응답해야 합니다.

---
## **9.  Speech Recognizer Resource**

음성 인식기 리소스는 수신 음성 스트림을 수신하고 말한 내용에 대한 텍스트 형태의 해석을 클라이언트에게 제공합니다.

인식기 리소스는 클라이언트의 MRCPv2 요청에 의해 제어됩니다. 인식기 리소스는 이러한 요청에 응답하고 클라이언트에 비동기 이벤트를 생성하여 메서드 처리 중에 관심 조건을 나타낼 수 있습니다.

이 섹션은 다음 리소스 유형에 적용됩니다.

```text
   1.  speechrecog

   2.  dtmfrecog
```

위의 두 리소스의 차이점은 인식 문법에 대한 지원 수준에 있습니다. "dtmfrecog" 리소스 유형은 DTMF 숫자만 인식할 수 있으므로 DTMF 문법만 허용합니다. DTMF 입력에 대해서만 barge-in을 생성하고 음성은 무시합니다. "speechrecog" 리소스 유형은 일반 음성과 DTMF 숫자를 인식할 수 있으므로 음성이나 DTMF를 설명하는 문법을 지원해야 합니다. 이 리소스는 음성 및/또는 DTMF에 대한 barge-in 이벤트를 생성합니다. RECOGNIZE 메서드에 의해 활성화된 문법을 분석하여 음성 및/또는 DTMF에 대한 barge-in이 발생해야 하는지 여부를 판별합니다. 인식기가 barge-in을 생성해야 한다고 결정하면 클라이언트에 START-OF-INPUT 이벤트도 생성합니다. 인식기 리소스는 일반 모드 또는 핫워드 모드 또는 둘 다에서 인식을 지원할 수 있습니다\(단, 단일 "speechrecog" 리소스는 일반 모드와 핫워드 모드 인식을 동시에 수행하지 않는다는 점에 유의하세요\). 단일 인식기 리소스가 두 모드를 모두 지원하지 않거나 일반 모드와 핫워드 인식을 동시에 수행해야 하는 구현의 경우, 두 모드는 동일한 SIP 대화\(다른 MRCP 세션 식별자 사용\)에 할당된 별도의 리소스를 통해 호출할 수 있으며 RTP 오디오 피드를 공유할 수 있습니다.

인식기 리소스의 기능은 아래와 같습니다.

일반 모드 인식 일반 모드 인식은 모든 음성이나 DTMF를 문법과 일치시키려고 시도하고, 입력이 일치하지 않거나 메서드 시간이 초과되면 일치하지 않음 상태를 반환합니다.

핫워드 모드 인식 핫워드 모드는 인식기가 특정 음성 문법 또는 DTMF 시퀀스와 일치하는 것을 찾고 일치하지 않는 음성 또는 DTMF를 무시하는 모드입니다. 문법이 성공적으로 일치하거나 클라이언트가 요청을 취소하거나 비입력 또는 인식 시간 초과가 있는 경우에만 인식이 완료됩니다.

음성 등록 문법 인식기 리소스는 선택적으로 음성 등록 문법을 지원할 수 있습니다. 이 기능을 사용하면 사람의 음성을 사용하여 등록이 수행됩니다. 예를 들어, 발신자의 음성을 사용하여 사람의 이름을 기록하여 연락처 목록을 만들고 유지할 수 있습니다. 이 기술은 때때로 화자 의존 인식이라고도 합니다.

해석 인식기 리소스는 음성 대신 텍스트 문자열을 입력으로 제공하여 자연어 해석 기능에만 사용할 수 있습니다. 이 모드에서 리소스는 텍스트를 입력으로 받고 제공된 문법에 따라 입력의 "해석"을 생성합니다.

음성 등록은 등록 세션의 개념을 가지고 있습니다. 개인 문법에 새로운 구문을 추가하는 세션은 초기 등록과 새로운 구문을 개인 문법에 적용하기 전에 충분한 발화를 반복하는 것을 포함합니다. 발화가 기록될 때마다 다른 샘플과 유사성을 비교하고 개인 문법의 다른 항목에 대해 충돌 테스트를 수행하여 유사하고 혼동스러운 항목이 없는지 확인합니다.

등록은 인식기 리소스를 사용하여 수행됩니다. 어떤 발화가 새로운 구문의 등록을 위해 고려될지 제어하는 것은 Recognize 요청에서 헤더 필드\(섹션 9.4.39 참조\)를 설정하여 수행됩니다.

해석은 INTERPRET 메서드\(9.20절\)와 Interpret-Text 헤더 필드\(9.4.30절\)를 통해 수행됩니다.

---
### **9.1.  Recognizer State Machine**

인식기 리소스는 클라이언트의 MRCPv2 요청을 처리하기 위한 상태 머신을 유지 관리합니다.

```text
   Idle                   Recognizing               Recognized
   State                  State                     State
    |                       |                          |
    |---------RECOGNIZE---->|---RECOGNITION-COMPLETE-->|
    |<------STOP------------|<-----RECOGNIZE-----------|
    |                       |                          |
    |              |--------|              |-----------|
    |       START-OF-INPUT  |       GET-RESULT         |
    |              |------->|              |---------->|
    |------------|          |                          |
    |      DEFINE-GRAMMAR   |----------|               |
    |<-----------|          | START-INPUT-TIMERS       |
    |                       |<---------|               |
    |------|                |                          |
    |  INTERPRET            |                          |
    |<-----|                |------|                   |
    |                       |   RECOGNIZE              |
    |-------|               |<-----|                   |
    |      STOP                                        |
    |<------|                                          |
    |<-------------------STOP--------------------------|
    |<-------------------DEFINE-GRAMMAR----------------|

                         Recognizer State Machine
```

인식기 리소스가 음성 등록 문법을 지원하는 경우 등록 세션을 시작해도 인식기 리소스의 상태가 변경되지 않습니다. 등록 세션이 시작되면 RECOGNIZE 메서드를 반복적으로 호출하여 발화를 등록합니다. 음성 인식기 리소스의 상태는 RECOGNIZE가 호출될 때마다 IDLE에서 RECOGNIZING 상태로 전환됩니다.

---
### **9.2.  Recognizer Methods**

인식기는 다음과 같은 방법을 지원합니다.

```text
   recognizer-method    =  recog-only-method
                        /  enrollment-method

   recog-only-method    =  "DEFINE-GRAMMAR"
                        /  "RECOGNIZE"
                        /  "INTERPRET"
                        /  "GET-RESULT"
                        /  "START-INPUT-TIMERS"
                        /  "STOP"
```

인식기 리소스가 음성 등록 문법을 지원하는 것은 선택 사항입니다. 인식기 리소스가 음성 등록 문법을 지원하는 경우 다음 메서드를 지원해야 합니다.

```text
   enrollment-method    =  "START-PHRASE-ENROLLMENT"
                        /  "ENROLLMENT-ROLLBACK"
                        /  "END-PHRASE-ENROLLMENT"
                        /  "MODIFY-PHRASE"
                        /  "DELETE-PHRASE"
```

---
### **9.3.  Recognizer Events**

인식기는 다음과 같은 이벤트를 생성할 수 있습니다.

```text
   recognizer-event     =  "START-OF-INPUT"
                        /  "RECOGNITION-COMPLETE"
                        /  "INTERPRETATION-COMPLETE"
```

---
### **9.4.  Recognizer Header Fields**

인식기 메시지에는 요청 옵션과 연관된 메서드, 응답 또는 이벤트 메시지를 보강하기 위한 정보가 포함된 헤더 필드가 포함될 수 있습니다.

```text
   recognizer-header    =  recog-only-header
                        /  enrollment-header

   recog-only-header    =  confidence-threshold
                        /  sensitivity-level
                        /  speed-vs-accuracy
                        /  n-best-list-length
                        /  no-input-timeout
                        /  input-type
                        /  recognition-timeout
                        /  waveform-uri
                        /  input-waveform-uri
                        /  completion-cause
                        /  completion-reason
                        /  recognizer-context-block
                        /  start-input-timers
                        /  speech-complete-timeout

                        /  speech-incomplete-timeout
                        /  dtmf-interdigit-timeout
                        /  dtmf-term-timeout
                        /  dtmf-term-char
                        /  failed-uri
                        /  failed-uri-cause
                        /  save-waveform
                        /  media-type
                        /  new-audio-channel
                        /  speech-language
                        /  ver-buffer-utterance
                        /  recognition-mode
                        /  cancel-if-queue
                        /  hotword-max-duration
                        /  hotword-min-duration
                        /  interpret-text
                        /  dtmf-buffer-time
                        /  clear-dtmf-buffer
                        /  early-no-match
```

인식기 리소스가 음성 등록 문법을 지원하는 경우 다음 헤더 필드도 사용됩니다.

```text
   enrollment-header    =  num-min-consistent-pronunciations
                        /  consistency-threshold
                        /  clash-threshold
                        /  personal-grammar-uri
                        /  enroll-utterance
                        /  phrase-id
                        /  phrase-nl
                        /  weight
                        /  save-best-waveform
                        /  new-phrase-id
                        /  confusable-phrases-uri
                        /  abort-phrase-enrollment
```

SET-PARAMS 또는 GET-PARAMS 메서드의 일부로 나타날 수 있는 등록 관련 헤더 필드의 경우 다음과 같은 일반 규칙이 적용됩니다. 이러한 헤더 필드가 SET-PARAMS 메서드를 통해 설정되거나 GET-PARAMS 메서드를 통해 검색되기 전에 START-PHRASE-ENROLLMENT 메서드를 호출해야 합니다.

Recognizer 리소스의 Waveform-URI 헤더 필드는 END-PHRASE-ENROLLMENT 메서드에 대한 응답에도 나타날 수 있습니다.

---
#### **9.4.1.  Confidence-Threshold**

인식기 리소스가 문법의 일부와 함께 말한 문구를 인식하거나 일치시킬 때 해당 일치와 신뢰 수준을 연관시킵니다.Confidence-Threshold 헤더 필드는 인식기 리소스에 클라이언트가 성공적인 일치로 간주하는 신뢰 수준을 알려줍니다.이것은 인식기의 인식에 대한 신뢰도를 나타내는 0.0-1.0 사이의 float 값입니다.인식기가 신뢰도 임계값보다 큰 신뢰도를 가진 후보 일치가 없다고 판단하는 경우 인식 결과로 no-match를 반환해야 합니다.이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다.이 헤더 필드의 기본값은 구현에 따라 다르며 이 헤더 필드의 특정 값에 대한 해석도 마찬가지입니다.다른 공급업체의 서버에 대한 값은 비교할 수 없지만 클라이언트가 주어진 서버에 대해 시간이 지남에 따라 이 값을 조정할 것으로 예상됩니다.

```text
   confidence-threshold     =  "Confidence-Threshold" ":" FLOAT CRLF
```

---
#### **9.4.2.  Sensitivity-Level**

배경 소음을 걸러내고 음성으로 착각하지 않기 위해 인식기 리소스는 가변적인 수준의 사운드 감도를 지원합니다. Sensitivity-Level 헤더 필드는 0.0과 1.0 사이의 float 값이며 클라이언트가 인식기의 감도 수준을 설정할 수 있도록 합니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 이 헤더 필드의 값이 높을수록 감도가 높아집니다. 이 헤더 필드의 기본값은 구현에 따라 다르며 이 헤더 필드의 특정 값에 대한 해석도 마찬가지입니다. 다른 공급업체의 서버에 대한 값은 비교할 수 없지만 클라이언트가 주어진 서버에 대해 시간이 지남에 따라 이 값을 조정할 것으로 예상됩니다.

```text
   sensitivity-level        =  "Sensitivity-Level" ":" FLOAT CRLF
```

---
#### **9.4.3.  Speed-Vs-Accuracy**

인식기 리소스의 구현 및 기능에 따라 성능 또는 정확도를 향해 조정할 수 있습니다. 정확도가 높을수록 처리량이 늘어나고 CPU 사용률이 높아져 서버당 활성 세션이 줄어들고 그 반대의 경우도 마찬가지입니다. 값은 0.0과 1.0 사이의 부동 소수점입니다. 값 0.0은 가장 빠른 인식을 의미합니다. 값 1.0은 가장 좋은 정확도를 의미합니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 이 헤더 필드의 기본값은

헤더 필드는 구현에 따라 다릅니다. 다른 공급업체의 서버에 대한 값은 비교할 수 없지만 클라이언트가 주어진 서버에 대해 시간이 지남에 따라 이 값을 조정할 것으로 예상됩니다.

```text
   speed-vs-accuracy        =  "Speed-Vs-Accuracy" ":" FLOAT CRLF
```

---
#### **9.4.4.  N-Best-List-Length**

인식기가 들어오는 스트림을 문법과 일치시킬 때 특정 단어나 대화 경로의 신뢰 수준 때문에 두 개 이상의 대체 일치 항목을 찾을 수 있습니다. 이 헤더 필드가 지정되지 않으면 기본적으로 인식기 리소스는 신뢰 임계값 위의 최상의 일치 항목만 반환합니다. 클라이언트는 이 헤더 필드를 설정하여 인식 리소스에 두 개 이상의 대체 항목을 보내도록 요청할 수 있습니다. 모든 대체 항목은 여전히 신뢰 임계값 위에 있어야 합니다. 1보다 큰 값은 인식기가 요청한 수의 대체 항목을 제공할 것이라는 보장이 없습니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 이 헤더 필드의 최소값은 1입니다. 이 헤더 필드의 기본값은 1입니다.

```text
   n-best-list-length       =  "N-Best-List-Length" ":" 1*19DIGIT CRLF
```

---
#### **9.4.5.  Input-Type**

인식기가 바지인 가능한 입력을 감지하고 입력 시작 이벤트를 생성하는 경우, 해당 이벤트는 바지인을 발생시킨 입력이 DTMF인지 음성인지를 지정하기 위해 이 헤더 필드를 포함해야 합니다.

```text
   input-type         =  "Input-Type" ":"  inputs CRLF
   inputs             =  "speech" / "dtmf"
```

---
#### **9.4.6.  No-Input-Timeout**

인식이 시작되고 일정 시간 동안 음성이 감지되지 않으면 인식기는 "no-input-timeout"의 완료 원인과 함께 RECOGNITION-COMPLETE 이벤트를 클라이언트에 보내고 인식 작업을 종료할 수 있습니다. 클라이언트는 No-Input-Timeout 헤더 필드를 사용하여 이 시간 초과를 설정할 수 있습니다. 값은 밀리초 단위이며 0에서 구현별 최대값까지 범위가 될 수 있습니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다. 기본값은 구현별입니다.

```text
   no-input-timeout         =  "No-Input-Timeout" ":" 1*19DIGIT CRLF
```

---
#### **9.4.7.  Recognition-Timeout**

인식이 시작되고 일정 기간 동안 일치하는 것이 없으면 인식기는 클라이언트에 RECOGNITION-COMPLETE 이벤트를 보내고 인식 작업을 종료할 수 있습니다. Recognition-Timeout 헤더 필드를 사용하면 클라이언트가 이 시간 초과 값을 설정할 수 있습니다. 값은 밀리초 단위입니다. 이 헤더 필드의 값은 0에서 구현별 최대값까지입니다. 기본값은 10초입니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다.

```text
   recognition-timeout      =  "Recognition-Timeout" ":" 1*19DIGIT CRLF
```

---
#### **9.4.8.  Waveform-URI**

Save-Waveform 헤더 필드가 "true"로 설정된 경우 인식기는 인식의 수신 오디오 스트림을 저장된 양식에 기록하고 클라이언트가 액세스할 수 있는 URI를 제공해야 합니다. Save-Waveform 헤더 필드가 "true"로 설정된 경우 이 헤더 필드는 RECOGNITION-COMPLETE 이벤트에 있어야 합니다. 서버에서 기록하지 못하게 하는 오류 조건이 있는 경우 헤더 필드의 값은 비어 있어야 합니다. 그렇지 않은 경우 서버에서 생성한 URI는 서버와 모든 인식 세션에서 명확해야 합니다. URI와 연결된 콘텐츠는 MRCPv2 세션이 종료될 때까지 클라이언트에서 사용할 수 있어야 합니다.

마찬가지로 Save-Best-Waveform 헤더 필드가 "true"로 설정된 경우 인식기는 등록 세션 중에 사용된 문구의 가장 좋은 반복을 위해 오디오 스트림을 저장해야 합니다. 그런 다음 인식기는 인식된 오디오를 녹음하고 END-PHRASE-ENROLLMENT 메서드에 대한 응답으로 Waveform-URI 헤더 필드에 URI를 반환하여 클라이언트에서 사용할 수 있도록 해야 합니다. 서버에서 녹음을 방해하는 오류 조건이 있는 경우 헤더 필드의 값은 비어 있어야 합니다. 그렇지 않은 경우 서버에서 생성한 URI는 서버와 모든 인식 세션에서 모호하지 않아야 합니다. URI와 연결된 콘텐츠는 MRCPv2 세션이 종료될 때까지 클라이언트에서 사용할 수 있어야 합니다. 섹션 12에서 저장된 파형의 민감도에 대한 논의를 참조하세요.

서버는 또한 녹음된 오디오 파형의 크기를 옥텟 단위로, 지속 시간을 밀리초 단위로 헤더 필드와 연관된 매개변수로 반환해야 합니다.

```text
   waveform-uri             =  "Waveform-URI" ":" ["<" uri ">"
                               ";" "size" "=" 1*19DIGIT
                               ";" "duration" "=" 1*19DIGIT] CRLF
```

---
#### **9.4.9.  Media-Type**

이 헤더 필드는 SET-PARAMS, GET-PARAMS 또는 RECOGNIZE 메서드에서 지정할 수 있으며, 서버 리소스에 캡처된 오디오나 비디오를 저장할 미디어 유형\(예: Waveform-URI 헤더 필드에서 캡처되어 반환된 것\)을 알려줍니다.

```text
   media-type               =  "Media-Type" ":" media-type-value
                               CRLF
```

---
#### **9.4.10.  Input-Waveform-URI**

이 선택적 헤더 필드는 RECOGNIZE 작업에서 처리할 오디오 콘텐츠를 가리키는 URI를 지정합니다. 이를 통해 클라이언트는 지정된 버퍼나 오디오 파일에서 인식을 요청할 수 있습니다.

```text
   input-waveform-uri       =  "Input-Waveform-URI" ":" uri CRLF
```

---
#### **9.4.11.  Completion-Cause**

이 헤더 필드는 반드시 인식기 리소스에서 클라이언트로 오는 RECOGNITION-COMPLETE 이벤트의 일부여야 합니다. RECOGNIZE 메서드 완료의 이유를 나타냅니다. 이 헤더 필드는 실패 상태와 COMPLETE 상태로 반환되는 경우 DEFINE-GRAMMAR 및 RECOGNIZE 응답에서 반드시 전송해야 합니다. 아래 ABNF에서 cause-code는 다음 표의 Cause-Code 열에서 선택한 숫자 값을 포함합니다. cause-name은 Cause-Name 열에서 선택한 해당 토큰을 포함합니다.

```text
   completion-cause         =  "Completion-Cause" ":" cause-code SP
                               cause-name CRLF
   cause-code               =  3DIGIT
   cause-name               =  *VCHAR

   +------------+-----------------------+------------------------------+
   | Cause-Code | Cause-Name            | Description                  |
   +------------+-----------------------+------------------------------+
   | 000        | success               | RECOGNIZE completed with a   |
   |            |                       | match or DEFINE-GRAMMAR      |
   |            |                       | succeeded in downloading and |
   |            |                       | compiling the grammar.       |
   |            |                       |                              |
   | 001        | no-match              | RECOGNIZE completed, but no  |
   |            |                       | match was found.             |
   |            |                       |                              |
   | 002        | no-input-timeout      | RECOGNIZE completed without  |
   |            |                       | a match due to a             |
   |            |                       | no-input-timeout.            |
   |            |                       |                              |
   | 003        | hotword-maxtime       | RECOGNIZE in hotword mode    |
   |            |                       | completed without a match    |
   |            |                       | due to a                     |
   |            |                       | recognition-timeout.         |
   |            |                       |                              |
   | 004        | grammar-load-failure  | RECOGNIZE failed due to      |
   |            |                       | grammar load failure.        |
   |            |                       |                              |
   | 005        | grammar-compilation-  | RECOGNIZE failed due to      |
   |            | failure               | grammar compilation failure. |
   |            |                       |                              |
   | 006        | recognizer-error      | RECOGNIZE request terminated |
   |            |                       | prematurely due to a         |
   |            |                       | recognizer error.            |
   |            |                       |                              |
   | 007        | speech-too-early      | RECOGNIZE request terminated |
   |            |                       | because speech was too       |
   |            |                       | early. This happens when the |
   |            |                       | audio stream is already      |
   |            |                       | "in-speech" when the         |
   |            |                       | RECOGNIZE request was        |
   |            |                       | received.                    |
   |            |                       |                              |
   | 008        | success-maxtime       | RECOGNIZE request terminated |
   |            |                       | because speech was too long  |
   |            |                       | but whatever was spoken till |
   |            |                       | that point was a full match. |
   |            |                       |                              |
   | 009        | uri-failure           | Failure accessing a URI.     |
   |            |                       |                              |
   | 010        | language-unsupported  | Language not supported.      |
   |            |                       |                              |

   | 011        | cancelled             | A new RECOGNIZE cancelled    |
   |            |                       | this one, or a prior         |
   |            |                       | RECOGNIZE failed while this  |
   |            |                       | one was still in the queue.  |
   |            |                       |                              |
   | 012        | semantics-failure     | Recognition succeeded, but   |
   |            |                       | semantic interpretation of   |
   |            |                       | the recognized input failed. |
   |            |                       | The RECOGNITION-COMPLETE     |
   |            |                       | event MUST contain the       |
   |            |                       | Recognition result with only |
   |            |                       | input text and no            |
   |            |                       | interpretation.              |
   |            |                       |                              |
   | 013        | partial-match         | Speech Incomplete Timeout    |
   |            |                       | expired before there was a   |
   |            |                       | full match. But whatever was |
   |            |                       | spoken till that point was a |
   |            |                       | partial match to one or more |
   |            |                       | grammars.                    |
   |            |                       |                              |
   | 014        | partial-match-maxtime | The Recognition-Timeout      |
   |            |                       | expired before full match    |
   |            |                       | was achieved. But whatever   |
   |            |                       | was spoken till that point   |
   |            |                       | was a partial match to one   |
   |            |                       | or more grammars.            |
   |            |                       |                              |
   | 015        | no-match-maxtime      | The Recognition-Timeout      |
   |            |                       | expired. Whatever was spoken |
   |            |                       | till that point did not      |
   |            |                       | match any of the grammars.   |
   |            |                       | This cause could also be     |
   |            |                       | returned if the recognizer   |
   |            |                       | does not support detecting   |
   |            |                       | partial grammar matches.     |
   |            |                       |                              |
   | 016        | grammar-definition-   | Any DEFINE-GRAMMAR error     |
   |            | failure               | other than                   |
   |            |                       | grammar-load-failure and     |
   |            |                       | grammar-compilation-failure. |
   +------------+-----------------------+------------------------------+
```

---
#### **9.4.12.  Completion-Reason**

이 헤더 필드는 인식기 리소스에서 클라이언트로 오는 RECOGNITION-COMPLETE 이벤트에서 지정할 수 있습니다. 여기에는 RECOGNIZE 요청 완료의 이유 텍스트가 포함됩니다. 서버는 이 헤더 필드를 사용하여 문법 마크업을 구문 분석하는 동안 발생한 특정 오류와 같이 실패 이유를 설명하는 텍스트를 전달합니다.

완료 이유 텍스트는 클라이언트가 로그에서 사용하고 디버깅 및 계측 목적으로 제공됩니다. 클라이언트는 완료 이유 텍스트를 해석해서는 안 됩니다.

```text
   completion-reason        =  "Completion-Reason" ":"
                               quoted-string CRLF
```

---
#### **9.4.13.  Recognizer-Context-Block**

이 헤더 필드는 SET-PARAMS 또는 GET-PARAMS 요청의 일부로 전송될 수 있습니다. GET-PARAMS 메서드에 값이 없는 이 헤더 필드가 포함되어 있는 경우 인식기에 인식기 컨텍스트 블록을 반환하라는 요청입니다. 이러한 메시지에 대한 응답에는 인식기 컨텍스트 블록이 입력된 미디어 메시지 본문으로 포함될 수 있습니다. 서버가 인식기 컨텍스트 블록을 반환하는 경우 응답에는 이 헤더 필드가 포함되어야 하며 해당 값은 해당 미디어 블록의 Content-ID와 일치해야 합니다.

SET-PARAMS 메서드에 이 헤더 필드가 포함된 경우, 인식기 컨텍스트 데이터와 이 헤더 필드 값과 일치하는 Content-ID를 포함하는 메시지 본문도 포함해야 합니다. 이 Content-ID는 GET-PARAMS 작업 중에 컨텍스트 데이터와 함께 제공된 Content-ID와 일치해야 합니다.

이 메커니즘을 사용하여 서버 간에 인식기 컨텍스트 데이터를 전달하기로 선택한 구현은 IANA 미디어 유형 공급업체 트리에서 IANA 등록 콘텐츠 유형을 사용하여 구현별 데이터 블록을 구별해야 합니다.

```text
   recognizer-context-block  =  "Recognizer-Context-Block" ":"
                                [1*VCHAR] CRLF
```

---
#### **9.4.14.  Start-Input-Timers**

이 헤더 필드는 RECOGNIZE 요청의 일부로 전송될 수 있습니다. false 값은 인식기에 인식을 시작하지만 아직 입력 없음 타이머를 시작하지 말라고 알려줍니다. 인식기는 클라이언트가 인식기에 START-INPUT-TIMERS 요청을 보낼 때까지 타이머를 시작해서는 안 됩니다. 이것은 인식기와

신디사이저 엔진은 동일한 세션의 일부가 아닙니다. 이러한 구성에서 kill-on-barge-in 프롬프트가 재생될 때\(8.4.2절 참조\) 클라이언트는 kill-on-barge-in을 감지하고 구현할 수 있도록 RECOGNIZE 요청이 동시에 활성화되기를 원합니다. 그러나 인식기는 프롬프트가 완료될 때까지 no-input 타이머를 시작해서는 안 됩니다. 기본값은 "true"입니다.

```text
   start-input-timers  =  "Start-Input-Timers" ":" BOOLEAN CRLF
```

---
#### **9.4.15.  Speech-Complete-Timeout**

이 헤더 필드는 음성 인식기가 결과를 확정하기 전에\(수락하거나 불일치 결과를 생성하기 전에\) 사용자 음성에 따라 필요한 침묵의 길이를 지정합니다. Speech-Complete-Timeout 값은 인식기가 현재 활성 문법과 완전히 일치하는 경우 적용되며 인식기가 일치를 선언하기 전에 추가 입력을 기다려야 하는 시간을 지정합니다. 반면 Speech-Incomplete-Timeout은 음성이 활성 문법과 불완전하게 일치하는 경우 사용됩니다. 값은 밀리초 단위입니다.

```text
  speech-complete-timeout = "Speech-Complete-Timeout" ":" 1*19DIGIT CRLF
```

긴 Speech-Complete-Timeout 값은 클라이언트에 대한 결과를 지연시키므로 애플리케이션이 사용자에게 느리게 응답합니다. 짧은 Speech-Complete-Timeout은 발화가 부적절하게 끊어지는 결과를 초래할 수 있습니다. 합리적인 음성 완료 시간 초과 값은 일반적으로 0.3초에서 1.0초 범위입니다. 이 헤더 필드의 값은 0에서 구현에 따라 달라지는 최대값까지입니다. 이 헤더 필드의 기본값은 구현에 따라 달라집니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다.

---
#### **9.4.16.  Speech-Incomplete-Timeout**

이 헤더 필드는 인식기가 결과를 확정하기 전에 사용자 음성에 따른 필요한 침묵 길이를 지정합니다. 침묵 이전의 음성이 모든 활성 문법과 불완전하게 일치하는 경우 불완전한 시간 초과가 적용됩니다. 이 경우 시간 초과가 트리거되면 부분적인 결과가 거부됩니다\(Completion-Cause가 "partial-match"임\). 값은 밀리초 단위입니다. 이 헤더 필드의 값은 0에서 구현별 최대값까지입니다. 이 헤더 필드의 기본값은 구현에 따라 다릅니다.

```text
   speech-incomplete-timeout = "Speech-Incomplete-Timeout" ":" 1*19DIGIT
                                CRLF
```

Speech-Incomplete-Timeout은 침묵 이전의 음성이 활성 문법과 완전히 일치하지만 더 말할 수 있고 여전히 문법과 일치할 수 있는 경우에도 적용됩니다. 반면 Speech-Complete-Timeout은 음성이 활성 문법과 완전히 일치하고 더 이상 말할 단어가 일치를 계속 나타낼 수 없는 경우에 사용됩니다.

긴 Speech-Incomplete-Timeout 값은 클라이언트에 대한 결과를 지연시켜 애플리케이션이 사용자에게 느리게 응답하게 합니다. 짧은 Speech-Incomplete-Timeout은 발화가 부적절하게 끊어지는 결과를 초래할 수 있습니다.

Speech-Incomplete-Timeout은 일반적으로 Speech-Complete-Timeout보다 길어서 사용자가 발화 중간에 일시 정지할 수 있습니다\(예: 숨쉬기\). 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다.

---
#### **9.4.17.  DTMF-Interdigit-Timeout**

이 헤더 필드는 DTMF 입력을 인식할 때 사용할 숫자 간 시간 초과 값을 지정합니다. 값은 밀리초 단위입니다. 이 헤더 필드의 값은 0에서 구현별 최대값까지입니다. 기본값은 5초입니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다.

```text
  dtmf-interdigit-timeout = "DTMF-Interdigit-Timeout" ":" 1*19DIGIT CRLF
```

---
#### **9.4.18.  DTMF-Term-Timeout**

이 헤더 필드는 DTMF 입력을 인식할 때 사용할 종료 타임아웃을 지정합니다. DTMF-Term-Timeout은 문법에서 추가 입력이 허용되지 않을 때만 적용됩니다. 그렇지 않으면 DTMF-Interdigit-Timeout이 적용됩니다. 값은 밀리초 단위입니다. 이 헤더 필드의 값은 0에서 구현별 최대값까지입니다. 기본값은 10초입니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다.

```text
   dtmf-term-timeout        =  "DTMF-Term-Timeout" ":" 1*19DIGIT CRLF
```

---
#### **9.4.19.  DTMF-Term-Char**

이 헤더 필드는 DTMF 입력 인식을 위한 종료 DTMF 문자를 지정합니다. 기본값은 NULL이며, 이는 빈 헤더 필드 값으로 표시됩니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다.

```text
   dtmf-term-char           =  "DTMF-Term-Char" ":" VCHAR CRLF
```

---
#### **9.4.20.  Failed-URI**

인식기가 URI를 가져오거나 액세스해야 하고 액세스가 실패하면 서버는 반드시 메서드 응답의 이 헤더 필드에 실패한 URI를 제공해야 합니다. 단, URI 실패가 여러 개 있는 경우에는 실패한 URI 중 하나를 메서드 응답의 이 헤더 필드에 제공해야 합니다.

```text
   failed-uri               =  "Failed-URI" ":" absoluteURI CRLF
```

---
#### **9.4.21.  Failed-URI-Cause**

인식기 메서드가 URI를 페치하거나 액세스하기 위해 인식기를 필요로 하고 액세스가 실패하면 서버는 메서드 응답의 이 헤더 필드를 통해 Failed-URI 헤더 필드에서 URI에 대한 URI 특정 또는 프로토콜 특정 응답 코드를 제공해야 합니다. 값 인코딩은 UTF-8\(RFC 3629 \[RFC3629\]\)로 모든 액세스 프로토콜을 수용하며, 그 중 일부는 숫자 응답 코드 대신 응답 문자열을 가질 수 있습니다.

```text
   failed-uri-cause         =  "Failed-URI-Cause" ":" 1*UTFCHAR CRLF
```

---
#### **9.4.22.  Save-Waveform**

이 헤더 필드를 사용하면 클라이언트가 인식기 리소스에 오디오 입력을 인식기에 저장하도록 요청할 수 있습니다. 그런 다음 인식기 리소스는 엔드포인트 없이 인식된 오디오를 녹음하고 RECOGNITION-COMPLETE 이벤트의 Waveform-URI 헤더 필드에 반환된 URI 형태로 클라이언트에서 사용할 수 있도록 해야 합니다. 스트림을 녹음하는 데 오류가 있거나 오디오 콘텐츠를 사용할 수 없는 경우 인식기는 빈 Waveform-URI 헤더 필드를 반환해야 합니다. 이 필드의 기본값은 "false"입니다. 이 헤더 필드는 RECOGNIZE, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 섹션 12에서 저장된 파형의 민감도에 대한 논의를 참조하세요.

```text
   save-waveform            =  "Save-Waveform" ":" BOOLEAN CRLF
```

---
#### **9.4.23.  New-Audio-Channel**

이 헤더 필드는 RECOGNIZE 요청에서 지정할 수 있으며, 클라이언트가 이 지점부터 다른 오디오 소스, 채널 또는 스피커에서 추가 입력 오디오가 나온다는 것을 서버에 알릴 수 있습니다. 인식기 리소스가 입력 통계 또는 적응 상태를 수집한 경우 인식기 리소스는 특정 인식 기술에 적합한 작업을 수행해야 합니다. 여기에는 RECOGNIZE 요청을 시작하기 전에 수집된 입력 통계 또는 적응 상태를 삭제하는 것이 포함되지만 이에 국한되지 않습니다. 다음이 있는 경우

미디어 스트림을 공유하고 이 데이터를 수집하거나 사용하는 여러 리소스가 있고 클라이언트가 리소스 중 하나에 이 헤더 필드를 발행하면 재설정 작업은 공유 미디어 스트림을 사용하는 모든 리소스에 적용됩니다. 이는 클라이언트가 여러 전화 통화에 대해 기존 미디어 세션과 함께 열린 인식 세션을 재사용하려는 경우를 포함하여 여러 사용 사례에 도움이 됩니다.

```text
   new-audio-channel        =  "New-Audio-Channel" ":" BOOLEAN
                               CRLF
```

---
#### **9.4.24.  Speech-Language**

이 헤더 필드는 데이터 내에 지정되지 않은 경우 세션 또는 요청 내의 인식 문법 데이터의 언어를 지정합니다. 이 헤더 필드의 값은 값에 대해 RFC 5646 \[RFC5646\]을 따라야 합니다. 이는 DEFINE-GRAMMAR, RECOGNIZE, SET-PARAMS 또는 GET-PARAMS 요청에서 발생할 수 있습니다.

```text
   speech-language          =  "Speech-Language" ":" 1*VCHAR CRLF
```

---
#### **9.4.25.  Ver-Buffer-Utterance**

이 헤더 필드를 통해 클라이언트는 서버에 이 인식 요청과 관련된 발화를 공동 상주 검증자 리소스에서 사용할 수 있는 버퍼에 버퍼링하도록 요청할 수 있습니다. 버퍼는 세션 내의 리소스에서 공유되며 검증자 리소스가 이 세션에 추가될 때 할당됩니다. 클라이언트는 세션에 대한 검증자 리소스가 인스턴스화되지 않는 한 이 헤더 필드를 보내서는 안 됩니다. 검증자 리소스가 세션에서 해제되면 버퍼가 해제됩니다.

---
#### **9.4.26.  Recognition-Mode**

이 헤더 필드는 RECOGNIZE 메서드가 어떤 모드에서 작동할지 지정합니다. 값 선택은 "normal" 또는 "hotword"입니다. 값이 "normal"이면 RECOGNIZE는 RECOGNIZE 요청에서 지정한 문법에 맞게 음성과 DTMF를 일치시키기 시작합니다. 음성의 일부가 문법과 일치하지 않으면 RECOGNIZE 명령은 불일치 상태로 완료됩니다. 타이머가 활성화되어 오디오에서 음성을 감지할 수 있으므로\(섹션 9.4.14 참조\) RECOGNIZE 메서드는 음성을 기다리는 시간 초과로 인해 완료될 수 있습니다. 이 헤더 필드의 값이 "hotword"이면 RECOGNIZE 메서드는 핫워드 모드에서 작동하며, 여기서는 특정 키워드나 DTMF만 찾습니다.

문법에 지정된 시퀀스를 무시하고 오디오 스트림의 침묵이나 다른 음성을 무시합니다. 이 헤더 필드의 기본값은 "normal"입니다. 이 헤더 필드는 RECOGNIZE 메서드에서 발생할 수 있습니다.

```text
   recognition-mode         =  "Recognition-Mode" ":"
                               "normal" / "hotword" CRLF
```

---
#### **9.4.27.  Cancel-If-Queue**

이 헤더 필드는 이 RECOGNIZE 요청이 리소스에 대해 이미 진행 중일 때 클라이언트가 다른 RECOGNIZE 메서드를 호출하려고 시도하면 어떤 일이 발생하는지 지정합니다. 이 헤더 필드의 값은 부울입니다. "true" 값은 클라이언트가 동일한 리소스에 대해 다른 RECOGNIZE 요청을 발행하는 경우 서버가 "cancelled"의 Completion-Cause로 이 RECOGNIZE 요청을 종료해야 함을 의미합니다. 이 헤더 필드의 "false" 값은 이 RECOGNIZE 요청이 완료될 때까지 계속되고 클라이언트가 동일한 리소스에 대해 더 많은 RECOGNIZE 요청을 발행하는 경우 큐에 추가됨을 서버에 나타냅니다. 현재 활성화된 RECOGNIZE 요청이 중지되거나 성공적인 일치로 완료되면 큐의 첫 번째 RECOGNIZE 메서드가 활성화됩니다. 현재 RECOGNIZE가 실패하면 보류 중인 큐의 모든 RECOGNIZE 메서드가 취소되고 각각 "cancelled"의 Completion-Cause로 RECOGNITION-COMPLETE 이벤트를 생성합니다. 이 헤더 필드는 모든 RECOGNIZE 요청에 반드시 존재해야 합니다. 기본값은 없습니다.

```text
   cancel-if-queue          =  "Cancel-If-Queue" ":" BOOLEAN CRLF
```

---
#### **9.4.28.  Hotword-Max-Duration**

이 헤더 필드는 핫워드 모드 RECOGNIZE 요청에서 보낼 수 있습니다. 핫워드 인식을 위해 고려될 발화의 최대 길이\(초\)를 지정합니다. 이 헤더 필드는 Hotword-Min-Duration과 함께 사용하여 인식기가 문법의 핫워드 중 하나가 될 수 없을 만큼 짧거나 긴 발화를 평가하지 못하도록 하여 성능을 조정할 수 있습니다. 값은 밀리초입니다. 기본값은 구현에 따라 달라집니다. "핫워드"가 아닌 다른 모드를 지정하는 RECOGNIZE 요청에 존재하는 경우 헤더 필드는 무시됩니다.

```text
   hotword-max-duration     =  "Hotword-Max-Duration" ":" 1*19DIGIT
                               CRLF
```

---
#### **9.4.29.  Hotword-Min-Duration**

이 헤더 필드는 핫워드 모드 RECOGNIZE 요청에서 보낼 수 있습니다. 핫워드 인식을 위해 고려될 발언의 최소 길이\(초\)를 지정합니다. 이 헤더 필드는

Hotword-Max-Duration을 사용하면 인식기가 문법의 핫워드 중 하나가 될 수 없을 만큼 짧거나 긴 발화를 평가하지 못하도록 하여 성능을 조정할 수 있습니다. 값은 밀리초 단위입니다. 기본값은 구현에 따라 다릅니다. "핫워드"가 아닌 다른 모드를 지정하는 RECOGNIZE 요청에 있는 경우 헤더 필드는 무시됩니다.

```text
   hotword-min-duration     =  "Hotword-Min-Duration" ":" 1*19DIGIT CRLF
```

---
#### **9.4.30.  Interpret-Text**

이 헤더 필드의 값은 자연어 해석이 필요한 텍스트에 대한 포인터를 제공하는 데 사용됩니다. 값은 URI 또는 텍스트입니다. 값이 URI인 경우 메시지 본문의 'text/plain' 유형의 엔터티를 참조하는 Content-ID여야 합니다. 그렇지 않은 경우 서버는 값을 해석할 텍스트로 처리해야 합니다. 이 헤더 필드는 INTERPRET 메서드를 호출할 때 사용해야 합니다.

```text
   interpret-text           =  "Interpret-Text" ":" 1*VCHAR CRLF
```

---
#### **9.4.31.  DTMF-Buffer-Time**

이 헤더 필드는 GET-PARAMS 또는 SET-PARAMS 메서드에서 지정할 수 있으며 인식기의 유형 사전 버퍼 시간\(밀리초\)을 지정하는 데 사용됩니다. 이것은 RECOGNIZE 명령이 활성화되지 않은 경우에도 DTMF 숫자가 눌릴 때 이를 수집하는 버퍼입니다. 후속 RECOGNIZE 메서드가 수신되면 RECOGNIZE 요청과 일치하도록 이 버퍼를 확인해야 합니다. 버퍼의 숫자가 충분하지 않으면 문법과 일치하도록 더 많은 숫자를 계속 수신할 수 있습니다. 이 DTMF 버퍼의 기본 크기는 플랫폼에 따라 다릅니다.

```text
   dtmf-buffer-time  =  "DTMF-Buffer-Time" ":" 1*19DIGIT CRLF
```

---
#### **9.4.32.  Clear-DTMF-Buffer**

이 헤더 필드는 RECOGNIZE 메서드에서 지정할 수 있으며 인식기에 RECOGNIZE를 시작하기 전에 DTMF 타입 어헤드 버퍼를 지우라고 알리는 데 사용됩니다. 이 헤더 필드의 기본값은 "false"이며, RECOGNIZE 메서드를 시작하기 전에 타입 어헤드 버퍼를 지우지 않습니다. 이 헤더 필드가 "true"로 지정되면 RECOGNIZE는 인식을 시작하기 전에 DTMF 버퍼를 지웁니다. 즉, RECOGNIZE 명령이 실행되기 전에 호출자가 누른 숫자는 삭제됩니다.

```text
   clear-dtmf-buffer  = "Clear-DTMF-Buffer" ":" BOOLEAN CRLF
```

---
#### **9.4.33.  Early-No-Match**

이 헤더 필드는 RECOGNIZE 메서드에서 지정할 수 있으며 인식기에 수집된 음성을 처리하여 활성 문법과 일치시키기 전에 음성이 끝날 때까지 기다려서는 안 된다는 것을 알리는 데 사용됩니다. "true" 값은 인식기가 조기에 일치해야 함을 나타냅니다. 지정되지 않은 경우 이 헤더 필드의 기본값은 "false"입니다. 인식기가 음성이 끝나기 전에 수집된 오디오의 처리를 지원하지 않는 경우 이 헤더 필드는 안전하게 무시할 수 있습니다.

```text
   early-no-match  = "Early-No-Match" ":" BOOLEAN CRLF
```

---
#### **9.4.34.  Num-Min-Consistent-Pronunciations**

이 헤더 필드는 START-PHRASE-ENROLLMENT, SET-PARAMS 또는 GET-PARAMS 메서드에서 지정할 수 있으며 새 구문을 음성 등록하기 위해 얻어야 하는 일관된 발음의 최소 수를 지정하는 데 사용됩니다. 최소값은 1입니다. 기본값은 구현에 따라 다르며 1보다 클 수 있습니다.

```text
   num-min-consistent-pronunciations  =
                 "Num-Min-Consistent-Pronunciations" ":" 1*19DIGIT CRLF
```

---
#### **9.4.35.  Consistency-Threshold**

이 헤더 필드는 START-PHRASE-ENROLLMENT, SET-PARAMS 또는 GET-PARAMS 메서드의 일부로 전송될 수 있습니다. 음성 등록 중에 사용되는 이 헤더 필드는 발화가 "일관성"으로 간주되기 위해 이전에 등록된 동일한 구문의 발음과 얼마나 유사해야 하는지 지정합니다. 임계값이 높을수록 발음이 일관적이라고 간주되기 위해 발화와 이전 발음 간의 일치가 더 가까워야 합니다. 이 임계값의 범위는 0.0과 1.0 사이의 부동 소수점 값입니다. 이 헤더 필드의 기본값은 구현에 따라 다릅니다.

```text
   consistency-threshold    =  "Consistency-Threshold" ":" FLOAT CRLF
```

---
#### **9.4.36.  Clash-Threshold**

이 헤더 필드는 START-PHRASE-ENROLLMENT, SET-PARAMS 또는 GET-PARAMS 메서드의 일부로 전송될 수 있습니다. 음성 등록 중에 사용되는 이 헤더 필드는 두 개의 다른 구문의 발음이 충돌하는 것으로 간주되기 전에 얼마나 유사할 수 있는지 지정합니다. 예를 들어, "John Smith" 및 "Jon Smits"와 같은 구문의 발음은 너무 유사하여 올바르게 구별하기 어려울 수 있습니다. 더 작은 임계값은 감지된 충돌 수를 줄입니다. 이 임계값의 범위는 0.0 사이의 부동 소수점 값입니다.

그리고 1.0. 이 헤더 필드의 기본값은 구현에 따라 다릅니다. Clash-Threshold 헤더 필드 값을 0으로 설정하면 Clash 테스트를 완전히 끌 수 있습니다.

```text
   clash-threshold          =  "Clash-Threshold" ":" FLOAT CRLF
```

---
#### **9.4.37.  Personal-Grammar-URI**

이 헤더 필드는 등록 작업 중에 사용하거나 참조할 화자 훈련 문법을 지정합니다. 등록 중에 이 문법에 구문이 추가됩니다. 예를 들어, 사용자 "Jeff"의 연락처 목록은 Personal-Grammar-URI "http://myserver.example.com/myenrollmentdb/jeff-list"에 저장될 수 있습니다. 생성된 문법 구문은 구현에 따라 다를 수 있습니다. 이 헤더 필드에는 기본값이 없습니다. 이 헤더 필드는 START-PHRASE-ENROLLMENT, SET-PARAMS 또는 GET-PARAMS 메서드의 일부로 전송될 수 있습니다.

```text
   personal-grammar-uri     =  "Personal-Grammar-URI" ":" uri CRLF
```

---
#### **9.4.38.  Enroll-Utterance**

이 헤더 필드는 RECOGNIZE 메서드에서 지정할 수 있습니다. 이 헤더 필드가 "true"로 설정되고 등록이 활성화된 경우 RECOGNIZE 명령은 수집된 발화를 등록 중인 개인 문법에 추가해야 합니다. 이것이 발생하는 방식은 엔진에 따라 다르며 향후 표준화 영역이 될 수 있습니다. 이 헤더 필드의 기본값은 "false"입니다.

```text
   enroll-utterance     =  "Enroll-Utterance" ":" BOOLEAN CRLF
```

---
#### **9.4.39.  Phrase-Id**

요청의 이 헤더 필드는 등록이 필요한 기존 개인 문법의 구문을 식별합니다. 또한 RECOGNIZE 완료 이벤트에서 클라이언트에게 반환됩니다. 이 헤더 필드는 START-PHRASE-ENROLLMENT, MODIFY-PHRASE 또는 DELETE-PHRASE 요청에서 발생할 수 있습니다. 이 헤더 필드에는 기본값이 없습니다.

```text
   phrase-id                =  "Phrase-ID" ":" 1*VCHAR CRLF
```

---
#### **9.4.40.  Phrase-NL**

이 문자열은 구문이 인식될 때 반환될 해석된 텍스트를 지정합니다. 이 헤더 필드는 START-PHRASE-ENROLLMENT 및 MODIFY-PHRASE 요청에서 발생할 수 있습니다. 이 헤더 필드에 대한 기본값은 없습니다.

```text
   phrase-nl                =  "Phrase-NL" ":" 1*UTFCHAR CRLF
```

---
#### **9.4.41.  Weight**

이 헤더 필드의 값은 등록된 문법에서 구문의 발생 가능성을 나타냅니다. 문법 등록을 사용할 때 시스템은 본질적으로 가능한 일치 구문 목록으로 구성된 문법 세그먼트를 구성합니다. 이는 W3C 문법 사양의 <one-of\> 태그의 동적 구성과 유사하다고 생각할 수 있습니다. 각 enrolled-phrase는 <one-of\> 목록 내의 <item\>과 유사한 음성 입력과 일치할 수 있는 목록의 항목이 됩니다. 이 헤더 필드를 사용하면 등록된 <one-of\> 목록의 구문\(즉, <item\> 항목\)에 가중치를 지정할 수 있습니다. 문법 가중치는 문법 컴파일 시 합산 1로 정규화되므로 등록된 문법 목록의 각 구문에 대한 가중치 값 1은 해당 목록의 모든 항목에 동일한 가중치가 있음을 나타냅니다. 이 헤더 필드는 START-PHRASE-ENROLLMENT 및 MODIFY-PHRASE 요청에서 발생할 수 있습니다. 이 헤더 필드의 기본값은 구현에 따라 다릅니다.

```text
   weight                   =  "Weight" ":" FLOAT CRLF
```

---
#### **9.4.42.  Save-Best-Waveform**

이 헤더 필드를 사용하면 클라이언트가 인식기 리소스에 등록 세션 동안 사용된 문구의 최상의 반복을 위해 오디오 스트림을 저장하도록 요청할 수 있습니다. 인식기는 인식된 오디오를 녹음하고 END-PHRASE-ENROLLMENT 메서드에 대한 응답으로 Waveform-URI 헤더 필드에 반환된 URI 형태로 클라이언트에서 사용할 수 있도록 해야 합니다. 스트림을 녹음하는 데 오류가 있거나 오디오 데이터를 사용할 수 없는 경우 인식기는 빈 Waveform-URI 헤더 필드를 반환해야 합니다. 이 헤더 필드는 START-PHRASE-ENROLLMENT, SET-PARAMS 및 GET-PARAMS 메서드에서 발생할 수 있습니다.

```text
   save-best-waveform  =  "Save-Best-Waveform" ":" BOOLEAN CRLF
```

---
#### **9.4.43.  New-Phrase-Id**

이 헤더 필드는 개인 문법에서 구문을 식별하는 데 사용되는 ID를 대체합니다. 인식기는 등록 문법을 사용할 때 새 ID를 반환합니다. 이 헤더 필드는 MODIFY-PHRASE 요청에서 발생할 수 있습니다.

```text
   new-phrase-id            =  "New-Phrase-ID" ":" 1*VCHAR CRLF
```

---
#### **9.4.44.  Confusable-Phrases-URI**

이 헤더 필드는 등록에 대한 유효하지 않은 구문을 정의하는 문법을 지정합니다. 예를 들어, 일반적인 애플리케이션은 명령어이기도 한 등록된 구문을 허용하지 않습니다. 이 헤더 필드는 등록 세션의 일부인 RECOGNIZE 요청에서 발생할 수 있습니다.

```text
   confusable-phrases-uri   =  "Confusable-Phrases-URI" ":" uri CRLF
```

---
#### **9.4.45.  Abort-Phrase-Enrollment**

이 헤더 필드는 개인 문법에 맞게 구문을 커밋하는 대신 구문 등록을 중단하기 위해 END-PHRASE-ENROLLMENT 메서드에서 지정될 수 있습니다.

```text
   abort-phrase-enrollment  =  "Abort-Phrase-Enrollment" ":"
                               BOOLEAN CRLF
```

---
### **9.5.  Recognizer Message Body**

인식기 메시지는 요청, 응답 또는 이벤트와 관련된 추가 데이터를 전달할 수 있습니다. 클라이언트는 DEFINE-GRAMMAR 또는 RECOGNIZE 요청에서 인식할 문법을 제공할 수 있습니다. DEFINE-GRAMMAR 메서드를 사용하여 하나 이상의 문법이 지정된 경우 서버는 DEFINE-GRAMMAR 메서드에 대한 응답을 반환하기 전에 문법을 페치, 컴파일 및 최적화하려고 시도해야 합니다. RECOGNIZE 요청은 RECOGNIZE 메서드가 문법을 등록하는 데 사용되는 경우를 제외하고 인식 작업 중에 활성화할 문법을 완전히 지정해야 합니다. 문법 등록 중에 이러한 문법은 선택 사항입니다. 서버 리소스는 RECOGNITION-COMPLETE 이벤트와 GET-RESULT 응답에서 인식 결과를 보냅니다. 문법 및 인식 결과는 해당 MRCPv2 메시지의 메시지 본문에 전달됩니다.

---
#### **9.5.1.  Recognizer Grammar Data**

클라이언트에서 서버로 인식기 문법 데이터는 인라인 또는 참조로 제공될 수 있습니다. 어느 쪽이든 문법 데이터는 RECOGNIZE 또는 DEFINE-GRAMMAR의 메시지 본문에 입력된 미디어 엔터티로 전달됩니다.

요청. 모든 MRCPv2 서버는 W3C의 XML 기반 음성 문법 마크업 형식\(SRGS\) \[W3C.REC-speech-grammar-20040316\]의 XML 형식\(미디어 유형 'application/srgs+xml'\)의 문법을 허용해야 하며 다른 형식의 문법을 허용할 수 있습니다. 예를 들어 다음이 포함되지만 이에 국한되지는 않습니다.

- SRGS의 ABNF 형식\(미디어 유형 'application/srgs'\)

```text
   o  Sun's Java Speech Grammar Format (JSGF)
      [refs.javaSpeechGrammarFormat]
```

또한 MRCPv2 서버는 음성 인식을 위한 의미 해석\(SISR\) \[W3C.REC-semantic-interpretation-20070405\] 사양을 지원할 수 있습니다.

요청에서 문법이 인라인으로 지정된 경우 클라이언트는 콘텐츠 헤더 필드의 일부로 해당 문법에 대한 Content-ID를 제공해야 합니다. 서버에 인라인 문법을 저장할 공간이 없는 경우 요청은 완료 원인 코드 016 "grammar-definition-failure"와 함께 반환해야 합니다. 그렇지 않은 경우 서버는 인라인 문법 블록을 해당 Content-ID와 연결하고 세션 기간 동안 서버에 저장해야 합니다. 그러나 세션에서 나중에 후속 DEFINE-GRAMMAR를 통해 Content-ID가 다시 정의되는 경우 이전에 Content-ID와 연결된 인라인 문법을 해제해야 합니다. 빈 메시지 본문\(즉, 문법 정의 없음\)으로 후속 DEFINE-GRAMMAR를 통해 Content-ID가 다시 정의된 경우 이전에 Content-ID와 연결된 문법을 해제하는 것 외에도 서버는 Content-ID에 대한 모든 바인딩과 연결을 지워야 합니다. 이후 다시 정의되지 않는 한, 이 URI는 서버에서 한 번도 설정된 적이 없는 URI로 해석되어야 합니다.

Content-ID와 연관된 문법은 'session' URI 체계를 통해 참조할 수 있습니다\(섹션 13.6 참조\). 예: session:help@root-level.store

문법 데이터는 외부 URI 참조를 사용하여 지정할 수 있습니다. 이를 위해 클라이언트는 미디어 유형 'text/uri-list'의 본문을 사용하여\(RFC 2483 \[RFC2483\] 참조\) 문법 데이터를 가리키는 하나 이상의 URI를 나열합니다. 클라이언트는 문법 URI 목록에 가중치를 지정하려는 경우 미디어 유형 'text/grammar-ref-list'의 본문을 사용할 수 있습니다\(섹션 13.5.1 참조\). 모든 MRCPv2 서버는 'http' 및 'https' URI 체계를 사용하여 문법 액세스를 지원해야 합니다.

클라이언트가 요청에서 사용하려는 문법 데이터가 URI와 인라인 문법 데이터의 혼합으로 구성된 경우 클라이언트는 'multipart/mixed' 미디어 유형을 사용하여 'text/uri-list'를 묶습니다.

'application/srgs' 또는 'application/srgs+xml' 콘텐츠 엔터티. 문법 데이터에서 사용되는 문자 집합과 인코딩은 표준 미디어 유형 정의를 사용하여 지정됩니다.

RECOGNIZE 요청의 메시지 본문에 두 개 이상의 문법 URI나 인라인 문법 블록이 지정된 경우, 서버는 이를 일치시킬 문법 대안 목록으로 해석합니다.

```text
   Content-Type:application/srgs+xml
   Content-ID:<request1@form-level.store>
   Content-Length:...

   <?xml version="1.0"?>

   <!-- the default grammar language is US English -->
   <grammar xmlns="http://www.w3.org/2001/06/grammar"
            xml:lang="en-US" version="1.0" root="request">

   <!-- single language attachment to tokens -->
         <rule id="yes">
               <one-of>
                     <item xml:lang="fr-CA">oui</item>
                     <item xml:lang="en-US">yes</item>
               </one-of>
         </rule>

   <!-- single language attachment to a rule expansion -->
         <rule id="request">
               may I speak to
               <one-of xml:lang="fr-CA">
                     <item>Michel Tremblay</item>
                     <item>Andre Roy</item>
               </one-of>
         </rule>

         <!-- multiple language attachment to a token -->
         <rule id="people1">
               <token lexicon="en-US,fr-CA"> Robert </token>
         </rule>

         <!-- the equivalent single-language attachment expansion -->
         <rule id="people2">
               <one-of>
                     <item xml:lang="en-US">Robert</item>
                     <item xml:lang="fr-CA">Robert</item>
               </one-of>
         </rule>

         </grammar>

                           SRGS Grammar Example

   Content-Type:text/uri-list
   Content-Length:...

   session:help@root-level.store
   http://www.example.com/Directory-Name-List.grxml
   http://www.example.com/Department-List.grxml
   http://www.example.com/TAC-Contact-List.grxml
   session:menu1@menu-level.store

                         Grammar Reference Example

   Content-Type:multipart/mixed; boundary="break"

   --break
   Content-Type:text/uri-list
   Content-Length:...

   http://www.example.com/Directory-Name-List.grxml
   http://www.example.com/Department-List.grxml
   http://www.example.com/TAC-Contact-List.grxml

   --break
   Content-Type:application/srgs+xml
   Content-ID:<request1@form-level.store>
   Content-Length:...

   <?xml version="1.0"?>

   <!-- the default grammar language is US English -->
   <grammar xmlns="http://www.w3.org/2001/06/grammar"
            xml:lang="en-US" version="1.0">

   <!-- single language attachment to tokens -->
         <rule id="yes">
               <one-of>
                     <item xml:lang="fr-CA">oui</item>
                     <item xml:lang="en-US">yes</item>
               </one-of>
         </rule>

   <!-- single language attachment to a rule expansion -->
         <rule id="request">
               may I speak to
               <one-of xml:lang="fr-CA">
                     <item>Michel Tremblay</item>
                     <item>Andre Roy</item>
               </one-of>
         </rule>

         <!-- multiple language attachment to a token -->
         <rule id="people1">
               <token lexicon="en-US,fr-CA"> Robert </token>
         </rule>

         <!-- the equivalent single-language attachment expansion -->
         <rule id="people2">
               <one-of>
                     <item xml:lang="en-US">Robert</item>
                     <item xml:lang="fr-CA">Robert</item>
               </one-of>
         </rule>

         </grammar>
   --break--

                      Mixed Grammar Reference Example
```

---
#### **9.5.2.  Recognizer Result Data**

인식 결과는 섹션 6.3에 설명된 대로 RECOGNITION-COMPLETE 이벤트의 메시지 본문 또는 GET-RESULT 응답 메시지에서 클라이언트에게 반환됩니다. NLSML 형식의 인식 부분에 대한 요소 및 속성 설명은 섹션 9.6에 제공되며 스키마의 규범적 정의는 섹션 16.1에 제공됩니다.

```text
   Content-Type:application/nlsml+xml
   Content-Length:...

   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           xmlns:ex="http://www.example.com/example"
           grammar="http://www.example.com/theYesNoGrammar">
       <interpretation>
           <instance>
                   <ex:response>yes</ex:response>
           </instance>
           <input>OK</input>
       </interpretation>
   </result>

                              Result Example
```

---
#### **9.5.3.  Enrollment Result Data**

등록 결과는 섹션 6.3에 설명된 대로 RECOGNITION-COMPLETE 이벤트의 메시지 본문에서 클라이언트에게 반환됩니다. NLSML 형식의 등록 부분에 대한 요소 및 속성 설명은 섹션 9.7에 제공되며 스키마의 규범적 정의는 섹션 16.2에 제공됩니다.

---
#### **9.5.4.  Recognizer Context Block**

클라이언트가 동일한 수신 통신 세션을 대신하여 작동하는 동안 서버를 변경하면 이 헤더 필드를 통해 클라이언트가 한 서버에서 불투명한 데이터 블록을 수집하여 다른 서버에 제공할 수 있습니다. 이 기능은 클라이언트가 다른 언어 지원이 필요하거나 서버에서 리디렉션을 발행했기 때문에 바람직합니다. 여기서 첫 번째 인식기 리소스는 인식 방법을 실행하는 동안 음향 및 기타 데이터를 수집했을 수 있습니다. 서버 전환 후 이 데이터를 전달하면 새 서버의 인식기 리소스가 더 나은 인식을 제공할 수 있습니다. 이 데이터 블록은 구현에 따라 다르며 메시지 본문에서 미디어 유형 'application/octets'으로 전달되어야 합니다.

이 데이터 블록은 SET-PARAMS 및 GET-PARAMS 메서드/응답 메시지에서 전달됩니다. GET-PARAMS 메서드에서 빈 Recognizer-Context-Block 헤더 필드가 있는 경우 인식기는 메시지 본문에 특정 Content-ID가 있는 미디어 유형 'application/octets'의 엔터티로 공급업체별 컨텍스트 블록\(있는 경우\)을 반환해야 합니다. Content-ID 값은 GET-PARAMS 응답의 Recognizer-Context-Block 헤더 필드에서도 지정해야 합니다. 이 공급업체별 데이터를 제공하려는 SET-PARAMS 요청은 동일한 유형이 지정된 엔터티로 메시지 본문에 보내야 합니다.

GET-PARAMS에서 수신한 Content-ID. Content-ID는 SET-PARAMS 메시지의 Recognizer-Context-Block 헤더 필드에서도 전송되어야 합니다.

이 메커니즘을 사용하여 인식기 컨텍스트 데이터를 서버 간에 전달하기로 선택한 각 음성 인식 구현은 참여 서버에서 인식 가능하고 다른 구현에서 선택한 값과 충돌할 가능성이 없는 Content-ID를 선택하여 구현별 데이터 블록을 다른 구현과 구별해야 합니다.

---
### **9.6.  Recognizer Results**

NLSML의 인식기 부분\(6.3.1절 참조\)은 의미 해석 구성요소가 사용자의 발화에서 자동으로 추출한 정보를 나타냅니다. 여기서 "발화"는 MRCPv2 구현에서 지원하는 모든 모달리티의 의미 있는 사용자 입력이라는 일반적인 의미로 받아들여져야 합니다.

---
#### **9.6.1.  Markup Functions**

MRCPv2 인식기 리소스는 자연어 의미 마크업 언어\(NLSML\)를 사용하여 자연어 음성 입력을 해석하고 MRCPv2 클라이언트가 사용할 수 있도록 해석 형식을 지정합니다.

마크업 요소는 해석, 부가 정보, 멀티모달 통합이라는 일반적인 기능 범주에 속합니다.

---
##### **9.6.1.1.  Interpretation**

요소와 속성은 <result\>, <interpretation\>, <instance\> 요소를 포함하여 사용자 발화의 의미를 나타냅니다. <result\> 요소에는 한 발화를 처리한 전체 결과가 포함됩니다. 음성 인식이나 자연어 이해의 불확실성으로 인해 발화의 해석이 여러 개의 대체 의미를 가져오는 경우 여러 개의 <interpretation\> 요소를 포함할 수 있습니다. 여러 해석을 제공하는 데는 적어도 두 가지 이유가 있습니다.

1. 클라이언트 애플리케이션에는 의미 해석기에서 반환된 가능한 해석 중에서 선호하는 해석을 선택할 수 있도록 하는 추가 정보\(예: 데이터베이스의 정보\)가 있을 수 있습니다.

1. 여러 경쟁 해석 중에서 선택할 수 없는 클라이언트 기반 대화 관리자\(예: VoiceXML \[W3C.REC-voicexml20-20040316\]\)는 이 정보를 사용하여 사용자에게 돌아가 의도한 바를 알아낼 수 있습니다. 예를 들어, 합성기 리소스에 SPEAK 요청을 발행하여 "'Boston' 또는 'Austin'이라고 말했나요?"를 내보낼 수 있습니다.

---
##### **9.6.1.2.  Side Information**

이는 해석 자체를 넘어 해석에 대한 추가 정보를 나타내는 요소와 속성입니다. 부가 정보에는 다음이 포함됩니다.

1. 해석이 달성되었는지\(<nomatch\> 요소\) 및 해석에 대한 시스템의 신뢰도\(<interpretation\>의 "confidence" 속성\).

```text
   2.  Alternative interpretations (<interpretation>)
```

1. 입력 형식 및 자동 음성 인식\(ASR\) 정보: 의미 해석기에 대한 입력을 나타내는 <input\> 요소입니다.

---
##### **9.6.1.3.  Multi-Modal Integration**

입력에 두 개 이상의 모달리티를 사용할 수 있는 경우 입력의 해석을 조정해야 합니다. <input\>의 "mode" 속성은 발화가 음성, DTMF, 포인팅 등으로 입력되었는지 여부를 표시하여 이를 지원합니다. <input\>의 "timestamp-start" 및 "timestamp-end" 속성은 입력이 발생한 시점을 표시하여 시간적 조정도 제공합니다.

---
#### **9.6.2.  Overview of Recognizer Result Elements and Their Relationships**

NLSML의 인식기 요소는 두 가지 범주로 나뉩니다.

1. 처리된 입력에 대한 설명 및

1. 입력에서 추출된 의미에 대한 설명.

각 요소 옆에는 해당 속성이 있습니다. 또한 일부 요소는 다른 요소의 여러 인스턴스를 포함할 수 있습니다. 예를 들어, <result\>는 여러 <interpretation\> 요소를 포함할 수 있으며, 각각은 대안으로 간주됩니다. 마찬가지로 <input\>은 여러 자식 <input\> 요소를 포함할 수 있으며, 이는 누적으로 간주됩니다. 이러한 요소의 기본 사용법을 설명하기 위해 간단한 예를 들어 보겠습니다.

"OK"\(예로 해석됨\)라는 발화를 생각해 보세요. 이 예는 해당 발화와 그 해석이 NLSML 마크업에서 어떻게 표현되는지 보여줍니다.

```text
   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           xmlns:ex="http://www.example.com/example"
           grammar="http://www.example.com/theYesNoGrammar">
     <interpretation>
        <instance>
           <ex:response>yes</ex:response>
         </instance>
       <input>OK</input>
     </interpretation>
   </result>
```

이 예에는 필요한 최소한의 정보만 포함됩니다. 하나의 해석과 입력 요소를 포함하는 전체 <result\> 요소가 있습니다. 해석에는 의미적으로 해석된 결과인 애플리케이션별 요소 "<response\>"가 포함됩니다.

---
#### **9.6.3.  Elements and Attributes**
---
##### **9.6.3.1.  <result> Root Element**

마크업의 루트 요소는 <result\>입니다. <result\> 요소에는 하나 이상의 <interpretation\> 요소가 포함됩니다. 입력이나 의미 해석의 모호성으로 인해 여러 해석이 발생할 수 있습니다. "grammar" 속성이 결과의 모든 해석에 적용되지 않는 경우 <interpretation\> 수준에서 개별 해석에 대해 재정의할 수 있습니다.

```text
   Attributes:
```

1. grammar: 이 결과와 일치하는 문법 또는 인식 규칙. grammar 속성의 형식은 문법 사양에 정의된 규칙 참조 의미론과 일치합니다. 구체적으로, 규칙 참조는 문법 규칙 참조에 대한 외부 XML 형식입니다. 마크업 인터프리터는 여러 규칙이 동시에 활성화될 수 있으므로 발화와 일치하는 문법 규칙을 알아야 합니다. 값은 마크업 인터프리터가 문법을 지정하는 데 사용하는 문법 URI입니다. 입력이 어떤 문법과 일치하는지 모호한 경우 <interpretation\> 요소의 grammar 속성으로 문법을 재정의할 수 있습니다. result 요소 내의 모든 interpretation 요소에 고유한 grammar 속성이 포함된 경우 result 요소에서 속성을 삭제할 수 있습니다.

```text
   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           grammar="http://www.example.com/grammar">
     <interpretation>
      ....
     </interpretation>
   </result>
```

---
##### **9.6.3.2.  <interpretation> Element**

<interpretation\> 요소에는 단일 의미 해석이 포함됩니다.

```text
   Attributes:
```

1. confidence: 의미 분석기의 이 해석에 대한 확신도를 나타내는 0.0-1.0의 float 값. 1.0의 값은 최대 확신도를 나타냅니다. 값은 구현에 따라 다르지만 섹션 9.4.1에 정의된 confidence MRCPv2 헤더 필드에 대한 값 해석과 일치하도록 의도되었습니다. 이 속성은 선택 사항입니다.

1. grammar: 이 해석에 일치하는 문법 또는 인식 규칙\(<interpretation\> 수준에서 문법 사양을 재정의하는 데 필요한 경우\). 이 속성은 <interpretation\>에서 <result\> 수준에서 정의된 문법을 재정의하는 데 필요한 경우에만 필요합니다. <result\> 요소에 grammar 속성이 지정된 경우에만 interpretation 요소에 대한 grammar 속성이 선택 사항입니다.

해석은 반드시 "좋음"의 척도에 따라 가장 좋은 것부터 순서대로 정렬해야 합니다. 좋음의 척도는 "신뢰도"가 있는 경우이고, 그렇지 않은 경우 품질에 대한 구현별 표시입니다.

문법은 <result\> 수준에서 가장 자주 지정될 것으로 예상됩니다. 그러나 다른 해석이 다른 문법 규칙과 일치할 수 있으므로 <interpretation\> 수준에서 재정의될 수 있습니다.

<interpretation\> 요소에는 분석되는 입력을 포함하는 선택적 <input\> 요소와 발화의 해석을 포함하는 하나 이상의 <instance\> 요소가 포함됩니다.

```text
   <interpretation confidence="0.75"
                   grammar="http://www.example.com/grammar">
       ...
   </interpretation>
```

---
##### **9.6.3.3.  <instance> Element**

<instance\> 요소는 발화의 해석을 포함합니다. Semantic Interpretation for Speech Recognition 형식을 사용하는 경우 <instance\> 요소는 해당 사양에 정의된 접근 방식을 사용하여 결과의 XML 직렬화를 포함합니다. 문법에 의미 객체를 생성하지 않고 대신 입력의 일부에 대한 의미 번역만 수행하는 의미 마크업이 있는 경우\(예: "coke"를 "coca-cola"로 번역\) 인스턴스는 전체 입력을 포함하지만 번역이 적용됩니다. NLSML은 아래 그림 2의 마크업과 유사합니다. 생성된 의미 객체가 없고 의미 번역도 없는 경우 인스턴스 값은 입력 값과 동일합니다.

```text
   Attributes:
```

1. confidence: 인스턴스의 각 요소는 NLSML 네임스페이스에 정의된 confidence 속성을 가질 수 있습니다. confidence 속성은 해당 슬롯 분석에 대한 시스템의 확신도를 반영하는 0.0-1.0 범위의 float 값을 포함합니다. 1.0 값은 최대 확신도를 나타냅니다. 값은 구현에 따라 다르지만 섹션 9.4.1에 정의된 MRCPv2 헤더 필드 Confidence-Threshold에 대한 값 해석과 일치하도록 의도되었습니다. 이 속성은 선택 사항입니다.

<instance\> <nameAddress\> <street confidence="0.75"\>123 Maple Street</street\> <city\>Mill Valley</city\> <state\>CA</state\> <zip\>90952</zip\> </nameAddress\> </instance\> <input\> 내 주소는 123 Maple Street, Mill Valley, California, 90952입니다. </input\>

<instance\> - 코카콜라를 사고 싶습니다. </instance\> <input\> 콜라를 사고 싶습니다. </input\>

```text
                          Figure 2: NSLML Example
```

---
##### **9.6.3.4.  <input> Element**

<input\> 요소는 사용자 입력의 텍스트 표현입니다. 여기에는 인식기의 인식 결과에 대한 확신을 나타내는 선택적 "confidence" 속성이 포함됩니다\(해석에 대한 확신은 <interpretation\>의 "confidence" 속성으로 나타냄\). 선택적 "timestamp-start" 및 "timestamp-end" 속성은 ISO 8601 형식\[ISO.8601.1988\]으로 말한 발화의 시작 및 종료 시간을 나타냅니다.

```text
   Attributes:
```

1. timestamp-start: 입력이 시작된 시간입니다. \(선택 사항\)

1. timestamp-end: 입력이 종료된 시간입니다. \(선택 사항\)

1. 모드: 입력 모드, 예를 들어 음성, DTMF 등\(선택 사항\)

1. confidence: 0.0\~1.0 범위 내 입력의 정확성에 대한 인식기의 신뢰도. \(선택 사항\)

일시적으로 겹치는 입력이 동일한 모드를 갖는 것은 합리적이지 않을 수 있습니다. 그러나 이러한 제약은 구현에서 적용될 것으로 예상되지 않습니다.

시간대 지정이 없는 경우 ISO 8601 시간은 기본적으로 현지 시간으로 표시됩니다.

<input\> 요소에는 세 가지 가능한 형식이 있습니다.

1. <input\> 요소는 간단한 텍스트를 포함할 수 있습니다.

```text
       <input>onions</input>
```

- 앞으로 <input\>에 텍스트뿐만 아니라 음성 인식기가 추출한 원래 발화에 포함된 음성 정보를 나타내는 추가 마크업을 포함할 가능성이 있습니다. 이는 음성 정보를 생성할 수 있는 ASR의 가용성에 따라 달라집니다. MRCPv2 클라이언트는 이러한 마크업을 수신할 준비가 되어 있어야 하며 이를 활용할 수도 있습니다.

1. <input\> 태그는 추가 <input\> 태그를 포함할 수도 있습니다. 추가 입력 요소가 있으면 표현이 향후 멀티모달 입력은 물론 개별 단어의 타임스탬프와 단어 수준 신뢰도와 같은 더 세분화된 음성 정보를 지원할 수 있습니다.

```text
       <input>
            <input mode="speech" confidence="0.5"
                timestamp-start="2000-04-03T0:00:00"
                timestamp-end="2000-04-03T0:00:00.2">fried</input>
            <input mode="speech" confidence="1.0"
                timestamp-start="2000-04-03T0:00:00.25"
                timestamp-end="2000-04-03T0:00:00.6">onions</input>
       </input>
```

1. 마지막으로, <input\> 요소는 <nomatch\> 및 <noinput\> 요소를 포함할 수 있습니다. 이는 음성 인식기가 처리할 수 없는 입력을 받았거나 전혀 입력을 받지 못한 상황을 설명합니다.

---
##### **9.6.3.5.  <nomatch> Element**

<input\> 아래의 <nomatch\> 요소는 의미 해석기가 임계값 이상의 확신을 가지고 어떤 입력과도 성공적으로 매치할 수 없었음을 나타내는 데 사용됩니다. 선택적으로 \(거부된\) 매치 중 가장 좋은 텍스트를 포함할 수 있습니다.

```text
   <interpretation>
      <instance/>
         <input confidence="0.1">
            <nomatch/>
         </input>
   </interpretation>
   <interpretation>
      <instance/>
      <input mode="speech" confidence="0.1">
        <nomatch>I want to go to New York</nomatch>
      </input>
   </interpretation>
```

---
##### **9.6.3.6.  <noinput> Element**

<noinput\>은 입력이 없었음을 나타냅니다. 침묵으로 인해 음성 인식기에서 시간 초과가 발생했습니다. <interpretation\> <instance/\> <input\> <noinput/\> </input\> </interpretation\>

여러 레벨의 입력이 있는 경우 <nomatch\> 및 <noinput\> 요소가 나타나는 가장 자연스러운 위치는 <noinput\>의 경우 가장 높은 레벨의 <input\> 아래이고, <noinput\>의 경우 적절한 레벨의 <input\> 아래입니다.

<해석\>은 <nomatch\>에 대한 것입니다. 따라서 <noinput\>은 "전혀 입력이 없음"을 의미하고 <nomatch\>는 "음성 모달리티에서 일치하지 않음" 또는 "DTMF 모달리티에서 일치하지 않음"을 의미합니다. 예를 들어, DTMF "1 2 3 4"와 결합된 왜곡된 음성을 표현하려면 마크업이 다음과 같습니다. <input\> <input mode="speech"\><nomatch/\></input\> <input mode="dtmf"\>1 2 3 4</input\> </input\>

참고: <noinput\>은 input의 속성으로 표현될 수 있지만, <nomatch\>는 최상의 매치를 가진 PCDATA 콘텐츠를 포함할 가능성이 있으므로 표현될 수 없습니다. 병렬 처리를 위해 <noinput\>도 요소입니다.

---
### **9.7.  Enrollment Results**

모든 등록 요소는 <result\> 아래의 단일 <enrollment-result\> 요소에 포함됩니다. 요소는 아래에 설명되어 있으며 섹션 16.2에서 정의된 스키마를 갖습니다. 다음 요소가 정의됩니다.

```text
   1.  num-clashes

   2.  num-good-repetitions

   3.  num-repetitions-still-needed

   4.  consistency-status

   5.  clash-phrase-ids

   6.  transcriptions

   7.  confusable-phrases
```

---
#### **9.7.1.  <num-clashes> Element**

<num-clashes\> 요소에는 이 발음이 활성 등록 세션에서 다른 발음과 충돌하는 횟수가 포함됩니다. 연관된 Clash-Threshold 헤더 필드는 충돌 측정의 민감도를 결정합니다. Clash-Threshold 헤더 필드 값을 0으로 설정하면 충돌 테스트를 완전히 끌 수 있습니다.

---
#### **9.7.2.  <num-good-repetitions> Element**

<num-good-repetitions\> 요소에는 활성 등록 세션에서 지금까지 얻은 일관된 발음 수가 포함됩니다.

---
#### **9.7.3.  <num-repetitions-still-needed> Element**

<num-repetitions-still-needed\> 요소에는 등록 문법에 새 구문을 추가하기 전에 여전히 얻어야 하는 일관된 발음 수가 포함됩니다. 필요한 일관된 발음 수는 클라이언트가 요청 헤더 필드 Num-Min-Consistent-Pronunciations에서 지정합니다. 반환된 값은 클라이언트가 등록 세션을 종료하여 구문을 문법에 성공적으로 커밋하기 전에 0이어야 합니다.

---
#### **9.7.4.  <consistency-status> Element**

<consistency-status\> 요소는 새로운 구문을 학습할 때 반복이 얼마나 일관된지 나타내는 데 사용됩니다. 이 요소는 일관적, 비일관적, 미정의 값을 가질 수 있습니다.

---
#### **9.7.5.  <clash-phrase-ids> Element**

<clash-phrase-ids\> 요소는 충돌하는 발음의 구문 ID를 포함합니다\(있는 경우\). 충돌이 없는 경우 이 요소는 없습니다.

---
#### **9.7.6.  <transcriptions> Element**

<transcriptions\> 요소에는 등록되는 문구의 마지막 반복에서 반환된 전사본이 포함되어 있습니다.

---
#### **9.7.7.  <confusable-phrases> Element**

<confusable-phrases\> 요소에는 개인 문법에 추가되는 구문과 혼동될 수 있는 명령 문법의 구문 목록이 들어 있습니다. 혼동될 수 있는 구문이 없는 경우 이 요소가 없어도 됩니다.

---
### **9.8.  DEFINE-GRAMMAR**

DEFINE-GRAMMAR 메서드는 클라이언트에서 서버로 하나 이상의 문법을 제공하고 서버에 필요에 따라 문법에 액세스하고, 가져오고, 컴파일하도록 요청합니다. DEFINE-GRAMMAR 메서드 구현은 해당 작업의 일부인 모든 외부 URI를 가져와야 합니다. 캐싱이 구현된 경우 이 URI 페칭은 URI를 캐시에서 페치할지 외부 서버에서 페치할지 결정할 때 메서드와 연관된 캐시 제어 힌트 및 매개변수 헤더 필드를 따라야 합니다. 이러한 힌트/매개변수가 메서드에 지정되지 않은 경우 SET-PARAMS/GET-PARAMS를 사용하여 세션에 설정된 값이 적용됩니다. 세션에 설정되지 않은 경우 기본값이 적용됩니다.

서버 리소스가 인식 상태인 경우, DEFINE-GRAMMAR 요청은 실패 상태로 응답해야 합니다.

리소스가 유휴 상태이고 제공된 문법을 성공적으로 처리할 수 있는 경우, 서버는 성공 코드 상태를 반환해야 하며 요청 상태는 COMPLETE여야 합니다.

인식기 리소스가 어떤 이유로 문법을 정의할 수 없는 경우\(예: 다운로드가 실패하거나, 문법이 컴파일되지 않았거나, 문법이 지원되지 않는 형식인 경우\), DEFINE-GRAMMAR 메서드에 대한 MRCPv2 응답은 실패 상태 코드 407을 포함해야 하며 실패 이유를 설명하는 완료 원인 헤더 필드를 포함해야 합니다.

```text
   C->S:MRCP/2.0 ... DEFINE-GRAMMAR 543257
   Channel-Identifier:32AECB23433801@speechrecog
   Content-Type:application/srgs+xml
   Content-ID:<request1@form-level.store>
   Content-Length:...

   <?xml version="1.0"?>

   <!-- the default grammar language is US English -->
   <grammar xmlns="http://www.w3.org/2001/06/grammar"
            xml:lang="en-US" version="1.0">

   <!-- single language attachment to tokens -->
   <rule id="yes">
               <one-of>
                     <item xml:lang="fr-CA">oui</item>
                     <item xml:lang="en-US">yes</item>
               </one-of>
         </rule>

   <!-- single language attachment to a rule expansion -->
         <rule id="request">
               may I speak to
               <one-of xml:lang="fr-CA">
                     <item>Michel Tremblay</item>
                     <item>Andre Roy</item>
               </one-of>
         </rule>

         </grammar>

   S->C:MRCP/2.0 ... 543257 200 COMPLETE
   Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success

   C->S:MRCP/2.0 ... DEFINE-GRAMMAR 543258
   Channel-Identifier:32AECB23433801@speechrecog
   Content-Type:application/srgs+xml
   Content-ID:<helpgrammar@root-level.store>
   Content-Length:...

   <?xml version="1.0"?>

   <!-- the default grammar language is US English -->
   <grammar xmlns="http://www.w3.org/2001/06/grammar"
            xml:lang="en-US" version="1.0">

         <rule id="request">
               I need help
         </rule>

   S->C:MRCP/2.0 ... 543258 200 COMPLETE
   Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success

   C->S:MRCP/2.0 ... DEFINE-GRAMMAR 543259
   Channel-Identifier:32AECB23433801@speechrecog
   Content-Type:application/srgs+xml
   Content-ID:<request2@field-level.store>
   Content-Length:...

   <?xml version="1.0" encoding="UTF-8"?>

   <!DOCTYPE grammar PUBLIC "-//W3C//DTD GRAMMAR 1.0//EN"
                     "http://www.w3.org/TR/speech-grammar/grammar.dtd">

   <grammar xmlns="http://www.w3.org/2001/06/grammar" xml:lang="en"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://www.w3.org/2001/06/grammar
              http://www.w3.org/TR/speech-grammar/grammar.xsd"
              version="1.0" mode="voice" root="basicCmd">

   <meta name="author" content="Stephanie Williams"/>
```

<rule id="basicCmd" scope="public"\> <example\> 창을 옮겨주세요 </example\> <example\> 파일을 열어주세요 </example\>

```text
     <ruleref
       uri="http://grammar.example.com/politeness.grxml#startPolite"/>

     <ruleref uri="#command"/>
     <ruleref
       uri="http://grammar.example.com/politeness.grxml#endPolite"/>
   </rule>

   <rule id="command">
     <ruleref uri="#action"/> <ruleref uri="#object"/>
   </rule>

   <rule id="action">
      <one-of>
         <item weight="10"> open   <tag>open</tag>   </item>
         <item weight="2">  close  <tag>close</tag>  </item>
         <item weight="1">  delete <tag>delete</tag> </item>
         <item weight="1">  move   <tag>move</tag>   </item>
      </one-of>
   </rule>
```

<rule id="object"\> <item repeat="0-1"\> <one-of\> <item\> </item\> <item\> a </item\> </one-of\> </item\>

```text
     <one-of>
         <item> window </item>
         <item> file </item>
         <item> menu </item>
     </one-of>
   </rule>

   </grammar>

   S->C:MRCP/2.0 ... 543259 200 COMPLETE
   Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success

   C->S:MRCP/2.0 ... RECOGNIZE 543260
   Channel-Identifier:32AECB23433801@speechrecog
           N-Best-List-Length:2
   Content-Type:text/uri-list
   Content-Length:...

   session:request1@form-level.store
   session:request2@field-level.store
   session:helpgramar@root-level.store

   S->C:MRCP/2.0 ... 543260 200 IN-PROGRESS
   Channel-Identifier:32AECB23433801@speechrecog

   S->C:MRCP/2.0 ... START-OF-INPUT 543260 IN-PROGRESS
   Channel-Identifier:32AECB23433801@speechrecog

   S->C:MRCP/2.0 ... RECOGNITION-COMPLETE 543260 COMPLETE
   Channel-Identifier:32AECB23433801@speechrecog
   Completion-Cause:000 success
   Waveform-URI:<http://web.media.com/session123/audio.wav>;
                size=124535;duration=2340
   Content-Type:application/x-nlsml
   Content-Length:...

   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           xmlns:ex="http://www.example.com/example"
           grammar="session:request1@form-level.store">
           <interpretation>
               <instance name="Person">
               <ex:Person>
                   <ex:Name> Andre Roy </ex:Name>
               </ex:Person>
            </instance>
            <input>   may I speak to Andre Roy </input>
       </interpretation>
   </result>

                          Define Grammar Example
```

---
### **9.9.  RECOGNIZE**

클라이언트에서 서버로의 RECOGNIZE 메서드는 인식기에 인식을 시작하도록 요청하고 입력 미디어와 일치시킬 문법에 대한 하나 이상의 문법 참조를 제공합니다. RECOGNIZE 메서드는 인식기가 제공하는 결과의 민감도, 신뢰 수준 및 세부 정보 수준을 제어하기 위한 헤더 필드를 전달할 수 있습니다. 이러한 헤더 필드 값은 이전 SET-PARAMS 메서드에서 설정한 현재 값을 재정의합니다.

RECOGNIZE 메서드는 Recognition-Mode 헤더 필드에서 지정한 대로 인식기 리소스가 일반 모드 또는 핫워드 모드로 작동하도록 요청할 수 있습니다. 기본값은 "normal"입니다. 리소스가 인식을 시작할 수 없는 경우 서버는 실패 상태로 응답해야 합니다.

407 코드와 실패 원인을 설명하는 응답의 완료 원인 헤더 필드.

RECOGNIZE 요청은 메시지 본문을 사용하여 요청에 적용할 수 있는 문법을 지정합니다. 요청에 대한 활성 문법은 세 가지 방법 중 하나로 지정할 수 있습니다. 클라이언트가 인식 작업에 대한 문법 가중치를 명시적으로 제어해야 하는 경우 아래 방법 3을 사용해야 합니다. 이러한 문법의 순서는 목록에 있는 두 개 이상의 문법이 음성과 일치할 때 사용되는 문법의 우선순위를 지정합니다. 이 경우 우선순위가 더 높은 문법이 일치 항목으로 반환됩니다. 이 우선순위 기능은 VoiceXML 브라우저와 같은 애플리케이션에서 VoiceXML 애플리케이션의 대화, 문서 및 루트 수준에서 지정된 문법을 정렬하는 데 유용합니다.

1. 문법은 입력된 콘텐츠로 메시지 본문에 직접 배치할 수 있습니다. 본문에 두 개 이상의 문법이 포함된 경우 포함 순서는 인식 중에 문법에 대한 해당 우선순위를 제어하며 본문의 이전 문법은 나중 문법보다 우선순위가 높습니다.

1. 본문에는 'text/uri-list' 미디어 유형 콘텐츠에 지정된 문법 URI 목록이 포함될 수 있습니다. \[RFC2483\] URI 순서는 인식 중에 문법에 대한 해당 우선순위를 결정하며, 가장 높은 우선순위가 먼저이고 그 이후의 각 URI에 대해 감소합니다.

1. 본문에는 'text/grammar-ref-list' 미디어 유형의 콘텐츠에 지정된 문법 URI 목록이 포함될 수 있습니다. 이 유형은 문법 URI 목록을 정의하고 각 문법 URI에 목록에서 가중치를 지정할 수 있도록 합니다. 이 가중치는 Speech Grammar Markup Format\(SRGS\) \[W3C.REC-speech-grammar-20040316\]의 섹션 2.4.1에 설명된 가중치와 동일한 의미를 갖습니다.

입력에 대한 인식을 수행하는 것 외에도 인식기는 Enroll-Utterance 헤더 필드가 true로 설정되고 Enrollment가 활성화된 경우\(START-PHRASE-ENROLLMENT 메서드의 이전 실행을 통해\) 수집된 발화를 개인 문법에 등록해야 합니다. 그렇다면 RECOGNIZE 요청에 Content-ID 헤더 필드가 포함된 경우 결과 문법\(개인 문법을 하위 문법으로 포함\)을 'session' URI 체계를 통해 참조할 수 있습니다\(섹션 13.6 참조\).

리소스가 인식을 성공적으로 시작할 수 있었다면 서버는 성공 상태 코드와 IN-PROGRESS 요청 상태를 반환해야 합니다. 즉, 인식기가 활성화되어 있고 클라이언트가 이 요청 ID로 추가 이벤트를 수신할 준비가 되어 있어야 합니다.

리소스가 요청을 큐에 넣을 수 있는 경우, 서버는 반드시 성공 코드와 PENDING의 요청 상태를 반환해야 합니다. 즉, 인식기가 현재 다른 요청으로 활성화되어 있고 이 요청이 처리를 위해 큐에 들어 있음을 의미합니다.

리소스가 인식을 시작할 수 없는 경우, 서버는 실패 상태 코드 407과 실패 원인을 설명하는 응답의 완료 원인 헤더 필드로 응답해야 합니다.

인식기 리소스의 경우, RECOGNIZE와 INTERPRET은 IN-PROGRESS 요청 상태를 반환하는 유일한 요청으로, 인식이 진행 중임을 의미합니다. 인식이 문법 대안 중 하나와 일치하거나, 일치하지 않는 시간 초과 또는 다른 이유로 완료되면, 인식기 리소스는 클라이언트에 RECOGNITION-COMPLETE 이벤트\(또는 INTERPRET이 요청인 경우 INTERPRETATION-COMPLETE\)를 인식 결과와 COMPLETE 요청 상태로 보내야 합니다.

큰 문법은 서버에서 컴파일하는 데 오랜 시간이 걸릴 수 있습니다. 반복적으로 사용되는 문법의 경우 클라이언트는 문법을 미리 DEFINE-GRAMMAR 요청으로 발행하여 서버 성능을 개선할 수 있습니다. 그런 경우 클라이언트는 RECOGNIZE 요청을 발행하고 '세션' URI 체계를 통해 문법을 참조할 수 있습니다\(섹션 13.6 참조\). 이는 클라이언트가 이전 인라인 문법으로 인식을 반복하려는 경우에도 일반적으로 적용됩니다.

RECOGNIZE 메서드 구현은 해당 작업의 일부인 모든 외부 URI를 페치해야 합니다. 캐싱이 구현된 경우 이 URI 페치는 캐시에서 페치할지 외부 서버에서 페치할지 결정할 때 메서드와 관련된 캐시 제어 힌트 및 매개변수 헤더 필드를 따라야 합니다. 메서드에 이러한 힌트/매개변수가 지정되지 않은 경우 SET-PARAMS/GET-PARAMS를 사용하여 세션에 설정된 값이 적용됩니다. 세션에 설정되지 않은 경우 기본값이 적용됩니다.

오디오와 메시지가 별도의 통신 경로를 통해 전달되므로 오디오 흐름의 시작과 RECOGNIZE 메서드 수신 사이에 경쟁 조건이 있을 수 있습니다. 예를 들어, 클라이언트가 RECOGNIZE 메서드를 보내는 것과 동시에 오디오 흐름을 시작하면 오디오나 RECOGNIZE가 먼저 인식기에 도착할 수 있습니다. 또 다른 예로, 클라이언트는 오디오를 서버로 지속적으로 보내고 RECOGNIZE 메서드를 사용하여 인식하도록 서버에 신호를 보낼 수 있습니다. 이 조건을 해결하는 메커니즘은 이 사양의 범위를 벗어납니다. 인식기는 RECOGNIZE 요청을 수신하면 미디어가 흐르기 시작할 것으로 예상할 수 있지만, 애플리케이션 작성자가 입력 타이머와 관련하여 기대하는 의미를 보존하기 위해 미리 수신한 내용을 버퍼링해서는 안 됩니다.

RECOGNIZE 메서드가 수신되면 스트림에서 인식이 시작됩니다. Start-Input-Timers 헤더 필드가 "true"로 지정된 경우 이때 No-Input-Timer가 시작되어야 합니다. 이 헤더 필드가 "false"로 설정된 경우 클라이언트에서 START-INPUT-TIMERS 메서드를 수신하면 No-Input-Timer가 시작되어야 합니다. 인식 리소스가 미디어 스트림에서 음성이나 DTMF 숫자를 감지하면 Recognition-Timeout이 시작되어야 합니다.

핫워드 모드가 아닐 때 인식을 위해:

인식기 리소스가 미디어 스트림에서 음성이나 DTMF 숫자를 감지하면 START-OF-INPUT 이벤트를 보내야 합니다. 서버에서 처리할 만큼 충분한 음성이 수집되면 인식기는 수집된 음성을 활성 문법과 일치시키려고 시도할 수 있습니다. 이 시점에서 수집된 음성이 활성 문법 중 하나와 완전히 일치하면 Speech-Complete-Timer가 시작됩니다. 하나 이상의 활성 문법과 부분적으로 일치하고 완전히 일치하려면 더 많은 음성이 필요한 경우 Speech-Incomplete-Timer가 시작됩니다.

1. No-Input-Timer가 만료되면 인식기는 "no-input-timeout" 완료 원인 코드로 완료해야 합니다.

1. 인식기는 음성 종료를 감지할 때 불일치 조건 감지를 지원해야 합니다. 인식기는 음성 종료를 기다리기 전에 불일치 조건 감지를 지원할 수 있습니다. 이것이 지원되는 경우 Early-No-Match 헤더 필드를 "true"로 설정하여 이 기능을 활성화합니다. 불일치 조건을 감지하면 RECOGNIZE는 "no-match"를 반환해야 합니다.

1. Speech-Incomplete-Timer가 만료되면 인식기는 "partial-match"의 완료 원인 코드로 완료해야 합니다. 단, 인식기가 부분 일치를 구별할 수 없는 경우에는 "no-match"의 완료 원인 코드를 반환해야 합니다. 인식기는 부분적으로 일치하는 문법에 대한 결과를 반환할 수 있습니다.

1. Speech-Complete-Timer가 만료되면 인식기는 "success"의 완료 원인 코드로 완료해야 합니다.

1. 인식 시간 초과가 만료되면 다음 중 하나가 발생해야 합니다.

```text
       5.1.  If there was a partial-match, the recognizer SHOULD
             complete with a Completion-Cause code of "partial-match-
             maxtime", unless the recognizer cannot differentiate a
             partial-match, in which case it MUST complete with a
             Completion-Cause code of "no-match-maxtime".  The
             recognizer MAY return results for the partially matched
             grammar.

       5.2.  If there was a full-match, the recognizer MUST complete
             with a Completion-Cause code of "success-maxtime".

       5.3.  If there was a no match, the recognizer MUST complete with
             a Completion-Cause code of "no-match-maxtime".
```

핫워드 모드에서 인식을 위해:

핫워드 모드에서 인식의 경우 음성이나 DTMF 숫자가 감지되면 입력 시작 이벤트가 생성되지 않습니다.

1. No-Input-Timer가 만료되면 인식기는 "no-input-timeout" 완료 원인 코드로 완료해야 합니다.

1. 어느 시점에서든 일치가 발생하면 RECOGNIZE는 "성공"의 완료 원인 코드로 완료되어야 합니다.

1. 인식 시간 초과가 만료되고 일치하는 항목이 없는 경우, 인식은 "hotword-maxtime" 완료 원인 코드로 완료되어야 합니다.

1. 인식 시간 초과가 만료되고 일치 항목이 있는 경우 인식은 "성공-maxtime" 완료 원인 코드로 완료되어야 합니다.

1. Recognition-Timeout이 실행 중이지만 감지된 음성/DTMF가 일치하지 않으면 Recognition-Timeout을 중지하고 재설정해야 합니다. 그런 다음 음성/DTMF가 다시 감지되면 Recognition-Timeout을 다시 시작해야 합니다.

아래는 RECOGNIZE를 사용하는 완전한 예입니다. RECOGNIZE에 대한 호출, IN-PROGRESS 및 START-OF-INPUT 상태 메시지, 그리고 결과를 포함하는 최종 RECOGNITION-COMPLETE 메시지를 보여줍니다.

```text
   C->S:MRCP/2.0 ... RECOGNIZE 543257
   Channel-Identifier:32AECB23433801@speechrecog
           Confidence-Threshold:0.9
   Content-Type:application/srgs+xml
   Content-ID:<request1@form-level.store>
   Content-Length:...

   <?xml version="1.0"?>

   <!-- the default grammar language is US English -->
   <grammar xmlns="http://www.w3.org/2001/06/grammar"
            xml:lang="en-US" version="1.0" root="request">

   <!-- single language attachment to tokens -->
       <rule id="yes">
               <one-of>
                     <item xml:lang="fr-CA">oui</item>
                     <item xml:lang="en-US">yes</item>
               </one-of>
         </rule>

   <!-- single language attachment to a rule expansion -->
         <rule id="request">
               may I speak to
               <one-of xml:lang="fr-CA">
                     <item>Michel Tremblay</item>
                     <item>Andre Roy</item>
               </one-of>
         </rule>

     </grammar>

   S->C: MRCP/2.0 ... 543257 200 IN-PROGRESS
   Channel-Identifier:32AECB23433801@speechrecog

   S->C:MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS
   Channel-Identifier:32AECB23433801@speechrecog

   S->C:MRCP/2.0 ... RECOGNITION-COMPLETE 543257 COMPLETE
   Channel-Identifier:32AECB23433801@speechrecog
   Completion-Cause:000 success
   Waveform-URI:<http://web.media.com/session123/audio.wav>;
                 size=424252;duration=2543
   Content-Type:application/nlsml+xml
   Content-Length:...

   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           xmlns:ex="http://www.example.com/example"
           grammar="session:request1@form-level.store">
       <interpretation>
           <instance name="Person">
               <ex:Person>
                   <ex:Name> Andre Roy </ex:Name>
               </ex:Person>
           </instance>
               <input>   may I speak to Andre Roy </input>
       </interpretation>
   </result>
```

아래는 다른 문법으로 RECOGNIZE를 호출하는 예입니다. 이 예에서는 상태나 완료 메시지가 표시되지 않지만, 물론 일반적인 사용에서는 발생할 것입니다.

```text
   C->S:   MRCP/2.0 ... RECOGNIZE 543257
           Channel-Identifier:32AECB23433801@speechrecog
           Confidence-Threshold:0.9
           Fetch-Timeout:20
           Content-Type:application/srgs+xml
           Content-Length:...

           <?xml version="1.0"? Version="1.0" mode="voice"
                 root="Basic md">
            <rule id="rule_list" scope="public">
                <one-of>
                    <item weight=10>
                        <ruleref uri=
               "http://grammar.example.com/world-cities.grxml#canada"/>
                   </item>
                   <item weight=1.5>
                       <ruleref uri=
               "http://grammar.example.com/world-cities.grxml#america"/>
                   </item>
                  <item weight=0.5>
                       <ruleref uri=
               "http://grammar.example.com/world-cities.grxml#india"/>
                  </item>
              </one-of>
           </rule>
```

---
### **9.10.  STOP**

클라이언트에서 서버로의 STOP 메서드는 요청이 활성화된 경우 리소스에 인식을 중지하라고 알립니다. RECOGNIZE 요청이 활성화되어 있고 STOP 요청이 성공적으로 종료된 경우 응답 헤더 섹션에는 종료된 RECOGNIZE 요청의 요청 ID가 포함된 Active-Request-Id-List 헤더 필드가 포함됩니다. 이 경우 종료된 요청에 대해 RECOGNITION-COMPLETE 이벤트가 전송되지 않습니다. 활성화된 인식이 없는 경우 응답에는 Active-Request-Id-List 헤더 필드가 포함되어서는 안 됩니다. 어느 쪽이든 응답에는 200 "성공" 상태 코드가 포함되어야 합니다.

```text
   C->S:   MRCP/2.0 ... RECOGNIZE 543257
           Channel-Identifier:32AECB23433801@speechrecog
           Confidence-Threshold:0.9
           Content-Type:application/srgs+xml
           Content-ID:<request1@form-level.store>
           Content-Length:...

           <?xml version="1.0"?>

           <!-- the default grammar language is US English -->
           <grammar xmlns="http://www.w3.org/2001/06/grammar"
                    xml:lang="en-US" version="1.0" root="request">

           <!-- single language attachment to tokens -->
               <rule id="yes">
                   <one-of>
                         <item xml:lang="fr-CA">oui</item>
                         <item xml:lang="en-US">yes</item>
                   </one-of>
               </rule>

           <!-- single language attachment to a rule expansion -->
               <rule id="request">
               may I speak to
                   <one-of xml:lang="fr-CA">
                         <item>Michel Tremblay</item>
                         <item>Andre Roy</item>
                   </one-of>
               </rule>
           </grammar>

   S->C:   MRCP/2.0 ... 543257 200 IN-PROGRESS
           Channel-Identifier:32AECB23433801@speechrecog

   C->S:   MRCP/2.0 ... STOP 543258 200
           Channel-Identifier:32AECB23433801@speechrecog

   S->C:   MRCP/2.0 ... 543258 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
           Active-Request-Id-List:543257
```

---
### **9.11.  GET-RESULT**

클라이언트에서 서버로의 GET-RESULT 메서드는 인식자 리소스가 인식된 상태일 때 발행될 수 있습니다. 이 요청을 통해 클라이언트는 완료된 인식에 대한 결과를 검색할 수 있습니다. 이는 클라이언트가 더 많은 대안이나 더 많은 정보를 원한다고 결정할 때 유용합니다. 서버가 이 요청을 받으면 GET-RESULT 요청에서 제공된 인식 제약 조건에 따라 결과를 다시 계산하여 반환합니다.

GET-RESULT 요청은 다른 신뢰 임계값 또는 n-best-list-length와 같은 제약 조건을 지정할 수 있습니다. 이 기능은 MRCPv2 서버의 경우 선택 사항이며 서버의 자동 음성 인식 엔진은 지원되지 않는 경우 지원되지 않는 기능 상태를 반환해야 합니다.

```text
   C->S:   MRCP/2.0 ... GET-RESULT 543257
           Channel-Identifier:32AECB23433801@speechrecog
           Confidence-Threshold:0.9

   S->C:   MRCP/2.0 ... 543257 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
           Content-Type:application/nlsml+xml
           Content-Length:...

           <?xml version="1.0"?>
           <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                   xmlns:ex="http://www.example.com/example"
                   grammar="session:request1@form-level.store">
               <interpretation>
                   <instance name="Person">
                       <ex:Person>
                           <ex:Name> Andre Roy </ex:Name>
                       </ex:Person>
                   </instance>
                   <input>   may I speak to Andre Roy </input>
               </interpretation>
           </result>
```

---
### **9.12.  START-OF-INPUT**

이것은 인식기 리소스가 미디어 스트림에서 음성이나 DTMF 숫자를 감지했음을 나타내는 서버에서 클라이언트로의 이벤트입니다. 이 이벤트는 신디사이저 리소스가 인식기 리소스와 다른 세션에 있고 따라서 들어오는 오디오 소스를 인식하지 못하는 kill-on-barge-in 시나리오를 구현하는 데 유용합니다\(섹션 8.4.2 참조\). 이러한 경우 클라이언트가 중개자 역할을 하고 신디사이저 리소스에 BARGE-IN-OCCURRED 이벤트를 발행하여 이 이벤트에 응답해야 합니다. 인식기 리소스는 또한 이 이벤트에 대한 고유한 값이 있는 Proxy-Sync-Id 헤더 필드를 보내야 합니다.

이 이벤트는 합성기와 인식기가 동일한 서버에 있는지 여부와 관계없이 서버에서 생성되어야 합니다.

---
### **9.13.  START-INPUT-TIMERS**

이 요청은 kill-on-barge-in 프롬프트가 재생을 마쳤음을 알 때 클라이언트에서 인식기 리소스로 전송됩니다\(섹션 8.4.2 참조\). 이는 인식 및 신시사이저 엔진이 동일한 세션에 있지 않은 시나리오에서 유용합니다. kill-on-barge-in 프롬프트가 재생 중일 때 클라이언트는 kill-on-barge-in을 감지하고 구현할 수 있도록 RECOGNIZE 요청이 동시에 활성화되기를 원할 수 있습니다. 하지만 동시에 클라이언트는 프롬프트가 완료될 때까지 인식기가 무입력 타이머를 시작하지 않기를 원합니다. RECOGNIZE 요청의 Start-Input-Timers 헤더 필드를 통해 클라이언트는 타이머를 즉시 시작해야 하는지 여부를 말할 수 있습니다. 그렇지 않은 경우 인식기 리소스는 클라이언트가 인식기에 START-INPUT-TIMERS 메서드를 보낼 때까지 타이머를 시작해서는 안 됩니다.

---
### **9.14.  RECOGNITION-COMPLETE**

이것은 인식이 완료되었음을 나타내는 인식기 리소스에서 클라이언트로의 이벤트입니다. 인식 결과는 MRCPv2 메시지 본문에 전송됩니다. 요청 상태 필드는 COMPLETE여야 하며, 이는 해당 요청 ID를 가진 마지막 이벤트이고 해당 요청 ID를 가진 요청이 이제 완료되었음을 나타냅니다. 서버는 해당 리소스에 대한 다음 RECOGNIZE 요청이 발행되거나 세션이 종료될 때까지 해당 인식의 결과와 오디오 파형 입력을 포함하는 인식기 컨텍스트를 유지해야 합니다. 서버가 오디오 파형에 대한 URI를 반환하는 경우 RECOGNITION-COMPLETE 이벤트의 Waveform-URI 헤더 필드에서 반환해야 합니다. 클라이언트는 이 URI를 사용하여 오디오를 검색하거나 재생할 수 있습니다.

참고로, 등록 세션이 활성화된 경우 RECOGNITION-COMPLETE 이벤트는 말한 내용에 따라 인식 또는 등록 결과를 포함할 수 있습니다. 다음 예는 인식 결과가 있는 완전한 교환을 보여줍니다.

```text
   C->S:   MRCP/2.0 ... RECOGNIZE 543257
           Channel-Identifier:32AECB23433801@speechrecog
           Confidence-Threshold:0.9
           Content-Type:application/srgs+xml
           Content-ID:<request1@form-level.store>
           Content-Length:...

           <?xml version="1.0"?>

           <!-- the default grammar language is US English -->
           <grammar xmlns="http://www.w3.org/2001/06/grammar"
                    xml:lang="en-US" version="1.0" root="request">

           <!-- single language attachment to tokens -->
               <rule id="yes">
                      <one-of>
                          <item xml:lang="fr-CA">oui</item>
                          <item xml:lang="en-US">yes</item>
                      </one-of>
                 </rule>

           <!-- single language attachment to a rule expansion -->
                 <rule id="request">
                     may I speak to
                      <one-of xml:lang="fr-CA">
                             <item>Michel Tremblay</item>
                             <item>Andre Roy</item>
                      </one-of>
                 </rule>
           </grammar>

   S->C:   MRCP/2.0 ... 543257 200 IN-PROGRESS
           Channel-Identifier:32AECB23433801@speechrecog

   S->C:   MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS
           Channel-Identifier:32AECB23433801@speechrecog

   S->C:   MRCP/2.0 ... RECOGNITION-COMPLETE 543257 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success
           Waveform-URI:<http://web.media.com/session123/audio.wav>;
                        size=342456;duration=25435
           Content-Type:application/nlsml+xml
           Content-Length:...

           <?xml version="1.0"?>
           <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                   xmlns:ex="http://www.example.com/example"
                   grammar="session:request1@form-level.store">
               <interpretation>
                   <instance name="Person">
                       <ex:Person>
                           <ex:Name> Andre Roy </ex:Name>
                       </ex:Person>
                   </instance>
                   <input>   may I speak to Andre Roy </input>
               </interpretation>
           </result>
```

결과가 등록 결과였다면 위 서버의 최종 메시지는 다음과 같았을 수 있습니다.

```text
   S->C:   MRCP/2.0 ... RECOGNITION-COMPLETE 543257 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success
           Content-Type:application/nlsml+xml
           Content-Length:...

           <?xml version= "1.0"?>
           <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                   grammar="Personal-Grammar-URI">
               <enrollment-result>
                   <num-clashes> 2 </num-clashes>
                   <num-good-repetitions> 1 </num-good-repetitions>
                   <num-repetitions-still-needed>
                      1
                   </num-repetitions-still-needed>
                   <consistency-status> consistent </consistency-status>
                   <clash-phrase-ids>
                       <item> Jeff </item> <item> Andre </item>
                   </clash-phrase-ids>
                   <transcriptions>
                        <item> m ay b r ow k er </item>
                        <item> m ax r aa k ah </item>
                   </transcriptions>

                   <confusable-phrases>
                        <item>
                             <phrase> call </phrase>
                             <confusion-level> 10 </confusion-level>
                        </item>
                   </confusable-phrases>
               </enrollment-result>
           </result>
```

---
### **9.15.  START-PHRASE-ENROLLMENT**

클라이언트에서 서버로의 START-PHRASE-ENROLLMENT 메서드는 클라이언트가 문법에 새로운 발화를 등록하기 위해 RECOGNIZE를 여러 번 호출할 수 있는 새로운 구문 등록 세션을 시작합니다. 등록 세션은 호출자가 구문을 여러 번 말하는 RECOGNIZE에 대한 호출 세트로 구성되어 시스템이 구문을 "학습"할 수 있습니다. 그런 다음 구문은 개인 문법\(화자 훈련 문법\)에 추가되어 시스템이 나중에 인식할 수 있습니다.

리소스에 대해 한 번에 하나의 구문 등록 세션만 활성화할 수 있습니다. Personal-Grammar-URI는 등록 중에 개인 구문 목록을 저장하는 데 사용되는 문법을 식별합니다. RECOGNIZE가 호출되면 결과는 RECOGNITION-COMPLETE 이벤트에서 반환되고 등록 결과 또는 일반 인식에 대한 인식 결과가 포함됩니다.

END-PHRASE-ENROLLMENT를 호출하면 진행 중인 구문 등록 세션이 종료됩니다. 이는 일반적으로 RECOGNIZE에 대한 일련의 성공적인 호출 후에 수행됩니다. 이 메서드는 새 구문을 개인 문법에 커밋하거나 구문 등록 세션을 중단하기 위해 호출할 수 있습니다.

Personal-Grammar-URI로 지정된 새로 등록된 구문을 포함하는 문법은 존재하지 않으면 생성됩니다. 또한, 개인 문법은 구문 등록 세션을 통해 추가된 구문만 포함해야 합니다.

이 메서드에 전달된 Phrase-ID는 문법에서 이 구문을 식별하는 데 사용되며 문법에서 RECOGNIZE를 수행할 때 음성 입력으로 반환됩니다. Phrase-NL도 마찬가지로 문법의 다른 자연어\(NL\)와 동일한 방식으로 RECOGNITION-COMPLETE 이벤트로 반환됩니다. 이 NL의 태그 형식은 구현에 따라 다릅니다.

클라이언트가 Save-Best-Waveform을 true로 지정한 경우, 구문 등록 세션을 종료한 후의 응답에는 학습된 구문의 가장 좋은 반복을 녹음한 위치/URI가 포함되어야 합니다.

```text
   C->S:   MRCP/2.0 ... START-PHRASE-ENROLLMENT 543258
           Channel-Identifier:32AECB23433801@speechrecog
           Num-Min-Consistent-Pronunciations:2
           Consistency-Threshold:30
           Clash-Threshold:12
           Personal-Grammar-URI:<personal grammar uri>
           Phrase-Id:<phrase id>
           Phrase-NL:<NL phrase>
           Weight:1
           Save-Best-Waveform:true

   S->C:   MRCP/2.0 ... 543258 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
```

---
### **9.16.  ENROLLMENT-ROLLBACK**

ENROLLMENT-ROLLBACK 메서드는 RECOGNIZE 작업에서 마지막 라이브 발화를 삭제합니다. 클라이언트는 호출자가 비음성 잡음, 부사어, 명령, RECOGNIZE 문법의 발화 등과 같은 바람직하지 않은 입력을 제공할 때 이 메서드를 호출할 수 있습니다. 이 메서드는 롤백 상태 스택을 제공하지 않는다는 점에 유의하세요. 개입 인식 작업 없이 ENROLLMENT-ROLLBACK을 연속으로 두 번 실행해도 두 번째에는 효과가 없습니다.

```text
   C->S:   MRCP/2.0 ... ENROLLMENT-ROLLBACK 543261
           Channel-Identifier:32AECB23433801@speechrecog

   S->C:   MRCP/2.0 ... 543261 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
```

---
### **9.17.  END-PHRASE-ENROLLMENT**

클라이언트는 활성 구문 등록 세션 중에만 END-PHRASE-ENROLLMENT 메서드를 호출할 수 있습니다. 진행 중인 RECOGNIZE 작업 중에는 호출해서는 안 됩니다. 문법에서 새 구문을 커밋하기 위해 클라이언트는 RECOGNIZE에 대한 연속적인 호출이 성공하고 RECOGNITION-COMPLETE 이벤트에서 Num-Repetitions-Still-Needed가 0으로 반환되면 이 메서드를 호출할 수 있습니다. 또는 클라이언트는 Abort-Phrase-Enrollment 헤더 필드와 함께 이 메서드를 호출하여 구문 등록 세션을 중단할 수 있습니다.

클라이언트가 START-PHRASE-ENROLLMENT 요청에서 Save-Best-Waveform을 "true"로 지정한 경우 응답에는 학습된 문구의 가장 좋은 반복을 녹음한 위치/URI를 값으로 하는 Waveform-URI 헤더가 포함되어야 합니다.

```text
  C->S:   MRCP/2.0 ... END-PHRASE-ENROLLMENT 543262
          Channel-Identifier:32AECB23433801@speechrecog

  S->C:   MRCP/2.0 ... 543262 200 COMPLETE
          Channel-Identifier:32AECB23433801@speechrecog
          Waveform-URI:<http://mediaserver.com/recordings/file1324.wav>;
                       size=242453;duration=25432
```

---
### **9.18.  MODIFY-PHRASE**

클라이언트에서 서버로 전송되는 MODIFY-PHRASE 방식은 개인 문법에서 주어진 구문의 구문 ID, NL 구문 및/또는 가중치를 변경하는 데 사용됩니다.

필드가 제공되지 않으면 이 메서드를 호출해도 아무런 효과가 없습니다.

```text
   C->S:   MRCP/2.0 ... MODIFY-PHRASE 543265
           Channel-Identifier:32AECB23433801@speechrecog
           Personal-Grammar-URI:<personal grammar uri>
           Phrase-Id:<phrase id>
           New-Phrase-Id:<new phrase id>
           Phrase-NL:<NL phrase>
           Weight:1

   S->C:   MRCP/2.0 ... 543265 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
```

---
### **9.19.  DELETE-PHRASE**

클라이언트에서 서버로 전송된 DELETE-PHRASE 방법은 개인 문법에 있는 단계를 삭제하는 데 사용되며 음성 등록 또는 텍스트 등록을 통해 추가되었습니다. 지정된 구문이 없으면 이 방법은 효과가 없습니다.

```text
   C->S:   MRCP/2.0 ... DELETE-PHRASE 543266
           Channel-Identifier:32AECB23433801@speechrecog
           Personal-Grammar-URI:<personal grammar uri>
           Phrase-Id:<phrase id>

   S->C:   MRCP/2.0 ... 543266 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
```

---
### **9.20.  INTERPRET**

클라이언트에서 서버로의 INTERPRET 메서드는 의미 해석이 필요한 텍스트를 포함하는 Interpret-Text 헤더 필드를 입력으로 받고 INTERPRETATION-COMPLETE 이벤트를 통해 RECOGNIZE 메서드 호출에서 반환된 것과 매우 유사한 해석 결과를 반환합니다.

음향 매칭과 관련된 결과의 일부는 결과에서 제외됩니다. Interpret-Text 헤더 필드는 INTERPRET 요청에 포함되어야 합니다.

인식기 문법 데이터는 RECOGNIZE 메서드 호출을 실행할 때와 동일한 방식으로 처리됩니다.

리소스에 대해 RECOGNIZE, RECORD 또는 다른 INTERPRET 작업이 이미 진행 중인 경우 서버는 402 "이 상태에서는 메서드가 유효하지 않음" 상태 코드와 COMPLETE 요청 상태를 갖는 응답으로 요청을 거부해야 합니다.

```text
   C->S:   MRCP/2.0 ... INTERPRET 543266
           Channel-Identifier:32AECB23433801@speechrecog
           Interpret-Text:may I speak to Andre Roy
           Content-Type:application/srgs+xml
           Content-ID:<request1@form-level.store>
           Content-Length:...

           <?xml version="1.0"?>
           <!-- the default grammar language is US English -->
           <grammar xmlns="http://www.w3.org/2001/06/grammar"
                    xml:lang="en-US" version="1.0" root="request">
           <!-- single language attachment to tokens -->
               <rule id="yes">
                   <one-of>
                       <item xml:lang="fr-CA">oui</item>
                       <item xml:lang="en-US">yes</item>
                   </one-of>
               </rule>

           <!-- single language attachment to a rule expansion -->
               <rule id="request">
                   may I speak to
                   <one-of xml:lang="fr-CA">
                       <item>Michel Tremblay</item>
                       <item>Andre Roy</item>
                   </one-of>
               </rule>
           </grammar>

   S->C:   MRCP/2.0 ... 543266 200 IN-PROGRESS
           Channel-Identifier:32AECB23433801@speechrecog

   S->C:   MRCP/2.0 ... INTERPRETATION-COMPLETE 543266 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success
           Content-Type:application/nlsml+xml
           Content-Length:...

           <?xml version="1.0"?>
           <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                   xmlns:ex="http://www.example.com/example"
                   grammar="session:request1@form-level.store">
               <interpretation>
                   <instance name="Person">
                       <ex:Person>
                           <ex:Name> Andre Roy </ex:Name>
                       </ex:Person>
                   </instance>
                   <input>   may I speak to Andre Roy </input>
               </interpretation>
           </result>
```

---
### **9.21.  INTERPRETATION-COMPLETE**

인식기 리소스에서 클라이언트로의 이 이벤트는 INTERPRET 작업이 완료되었음을 나타냅니다. 해석 결과는 MRCP 메시지 본문에 전송됩니다. 요청 상태는 COMPLETE로 설정해야 합니다.

이 이벤트에는 완료-원인 헤더 필드가 반드시 포함되어야 하며 원인 코드 목록에서 적절한 값으로 설정해야 합니다.

```text
   C->S:    MRCP/2.0 ... INTERPRET 543266
           Channel-Identifier:32AECB23433801@speechrecog
           Interpret-Text:may I speak to Andre Roy
           Content-Type:application/srgs+xml
           Content-ID:<request1@form-level.store>
           Content-Length:...

           <?xml version="1.0"?>
           <!-- the default grammar language is US English -->
           <grammar xmlns="http://www.w3.org/2001/06/grammar"
                    xml:lang="en-US" version="1.0" root="request">
           <!-- single language attachment to tokens -->
               <rule id="yes">
                   <one-of>
                       <item xml:lang="fr-CA">oui</item>
                       <item xml:lang="en-US">yes</item>
                   </one-of>
               </rule>

           <!-- single language attachment to a rule expansion -->
               <rule id="request">
                   may I speak to
                   <one-of xml:lang="fr-CA">
                       <item>Michel Tremblay</item>
                       <item>Andre Roy</item>
                   </one-of>
               </rule>
           </grammar>

   S->C:    MRCP/2.0 ... 543266 200 IN-PROGRESS
           Channel-Identifier:32AECB23433801@speechrecog

   S->C:    MRCP/2.0 ... INTERPRETATION-COMPLETE 543266 200 COMPLETE
           Channel-Identifier:32AECB23433801@speechrecog
           Completion-Cause:000 success
           Content-Type:application/nlsml+xml
           Content-Length:...

           <?xml version="1.0"?>
           <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                   xmlns:ex="http://www.example.com/example"
                   grammar="session:request1@form-level.store">
               <interpretation>
                   <instance name="Person">
                       <ex:Person>
                           <ex:Name> Andre Roy </ex:Name>
                       </ex:Person>
                   </instance>
                   <input>   may I speak to Andre Roy </input>
               </interpretation>
           </result>
```

---
### **9.22.  DTMF Detection**

DTMF 톤으로 수신된 숫자는 RFC 4733 \[RFC4733\]에 따라 RTP 스트림의 MRCPv2 서버에 있는 인식 리소스에 전달됩니다. 자동 음성 인식기\(ASR\)는 숫자를 인식하기 위해 RFC 4733을 지원해야 하며 오디오에서 DTMF 톤 \[Q.23\] 인식을 지원할 수 있습니다.

---
## **10.  Recorder Resource**

이 리소스는 수신된 오디오 및 비디오를 캡처하여 URI가 가리키는 콘텐츠로 저장합니다. 레코더의 주요 용도는 다음과 같습니다.

1. 나중에 인식을 위해 제출할 수 있는 음성 오디오를 캡처하고,

1. 음성이나 영상 메일을 녹음합니다.

이 두 애플리케이션은 모두 RTSP \[RFC2326\]와 같은 프로토콜에서 지정한 것 이상의 기능이 필요합니다. 여기에는 오디오 엔드포인트\(즉, 음성 또는 침묵 감지\)가 포함됩니다. 비디오 지원은 선택 사항이며 주로 위에서 언급한 음성 또는 오디오 처리가 필요할 수 있는 비디오 메일을 캡처합니다.

레코더는 녹음의 시작과 끝에서 무음을 억제하기 위한 엔드포인트 기능을 제공해야 하며, 녹음 중간에 무음을 억제할 수도 있습니다. 이러한 억제가 수행되는 경우 레코더는 녹음된 미디어의 실제 타임 스탬프를 나타내는 타이밍 메타데이터를 유지해야 합니다.

12장에서 저장된 파형의 민감도에 대한 논의를 참조하세요.

---
### **10.1.  Recorder State Machine**

```text
   Idle                   Recording
   State                  State
    |                       |
    |---------RECORD------->|
    |                       |
    |<------STOP------------|
    |                       |
    |<--RECORD-COMPLETE-----|
    |                       |
    |              |--------|
    |       START-OF-INPUT  |
    |              |------->|
    |                       |
    |              |--------|
    |    START-INPUT-TIMERS |
    |              |------->|
    |                       |

                          Recorder State Machine
```

---
### **10.2.  Recorder Methods**

레코더 리소스는 다음과 같은 방법을 지원합니다.

```text
   recorder-method      =  "RECORD"
                        /  "STOP"
                        /  "START-INPUT-TIMERS"
```

---
### **10.3.  Recorder Events**

레코더 리소스는 다음과 같은 이벤트를 생성할 수 있습니다.

```text
   recorder-event       =  "START-OF-INPUT"
                        /  "RECORD-COMPLETE"
```

---
### **10.4.  Recorder Header Fields**

레코더 리소스에 대한 메서드 호출에는 요청 옵션과 연관된 메서드, 응답 또는 이벤트 메시지를 보강하기 위한 정보가 포함된 리소스별 헤더 필드가 포함될 수 있습니다.

```text
   recorder-header      =  sensitivity-level
                        /  no-input-timeout
                        /  completion-cause
                        /  completion-reason
                        /  failed-uri
                        /  failed-uri-cause
                        /  record-uri
                        /  media-type
                        /  max-time
                        /  trim-length
                        /  final-silence
                        /  capture-on-speech
                        /  ver-buffer-utterance
                        /  start-input-timers
                        /  new-audio-channel
```

---
#### **10.4.1.  Sensitivity-Level**

배경 소음을 걸러내고 음성으로 착각하지 않기 위해 레코더는 가변적인 수준의 사운드 감도를 지원할 수 있습니다. Sensitivity-Level 헤더 필드는 0.0과 1.0 사이의 float 값이며 클라이언트가 레코더의 감도 수준을 설정할 수 있도록 합니다. 이 헤더 필드는 RECORD, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 이 헤더 필드의 값이 높을수록 감도가 높아집니다. 이 헤더 필드의 기본값은 구현에 따라 다릅니다.

```text
   sensitivity-level    =     "Sensitivity-Level" ":" FLOAT CRLF
```

---
#### **10.4.2.  No-Input-Timeout**

녹음이 시작되고 일정 시간 동안 음성이 감지되지 않으면 레코더는 클라이언트에 RECORD-COMPLETE 이벤트를 보내고 녹음 작업을 종료할 수 있습니다. No-Input-Timeout 헤더 필드는 이 시간 초과 값을 설정할 수 있습니다. 값은 밀리초입니다. 이 헤더 필드는 RECORD, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다. 이 헤더 필드의 값은 0에서 구현별 최대값까지입니다. 이 헤더 필드의 기본값은 구현에 따라 다릅니다.

```text
   no-input-timeout    =     "No-Input-Timeout" ":" 1*19DIGIT CRLF
```

---
#### **10.4.3.  Completion-Cause**

이 헤더 필드는 레코더 리소스에서 클라이언트로 전송되는 RECORD-COMPLETE 이벤트의 일부여야 합니다. 이는 RECORD 메서드 완료의 이유를 나타냅니다. 이 헤더 필드는 실패 상태와 COMPLETE 상태로 반환되는 경우 RECORD 응답에서 보내야 합니다. 아래 ABNF에서 'cause-code'에는 다음 표의 Cause-Code 열에서 선택한 숫자 값이 포함됩니다. 'cause-name'에는 Cause-Name 열에서 선택한 해당 토큰이 포함됩니다.

```text
   completion-cause         =  "Completion-Cause" ":" cause-code SP
                               cause-name CRLF
   cause-code               =  3DIGIT
   cause-name               =  *VCHAR

   +------------+-----------------------+------------------------------+
   | Cause-Code | Cause-Name            | Description                  |
   +------------+-----------------------+------------------------------+
   | 000        | success-silence       | RECORD completed with a      |
   |            |                       | silence at the end.          |
   | 001        | success-maxtime       | RECORD completed after       |
   |            |                       | reaching maximum recording   |
   |            |                       | time specified in record     |
   |            |                       | method.                      |
   | 002        | no-input-timeout      | RECORD failed due to no      |
   |            |                       | input.                       |
   | 003        | uri-failure           | Failure accessing the record |
   |            |                       | URI.                         |
   | 004        | error                 | RECORD request terminated    |
   |            |                       | prematurely due to a         |
   |            |                       | recorder error.              |
   +------------+-----------------------+------------------------------+
```

---
#### **10.4.4.  Completion-Reason**

이 헤더 필드는 레코더 리소스에서 클라이언트로 오는 RECORD-COMPLETE 이벤트에 존재할 수 있습니다. 여기에는 RECORD 요청 완료의 이유 텍스트가 포함됩니다. 이 헤더 필드는 실패 이유를 설명하는 텍스트를 전달합니다.

완료 이유 텍스트는 클라이언트가 로그에서 사용하고 디버깅 및 계측 목적으로 제공됩니다. 클라이언트는 완료 이유 텍스트를 해석해서는 안 됩니다.

```text
   completion-reason        =  "Completion-Reason" ":"
                               quoted-string CRLF
```

---
#### **10.4.5.  Failed-URI**

레코더 메서드가 오디오를 URI에 게시해야 하고 URI에 대한 액세스가 실패하는 경우, 서버는 메서드 응답의 이 헤더 필드에 실패한 URI를 제공해야 합니다.

```text
   failed-uri               =  "Failed-URI" ":" absoluteURI CRLF
```

---
#### **10.4.6.  Failed-URI-Cause**

레코더 메서드가 URI에 오디오를 게시해야 하고 URI에 대한 액세스가 실패하면 서버는 메서드 응답의 이 헤더 필드를 통해 URI 특정 또는 프로토콜 특정 응답 코드를 제공할 수 있습니다. 값 인코딩은 모든 액세스 프로토콜을 수용하기 위해 UTF-8\(RFC 3629 \[RFC3629\]\)입니다. 일부 액세스 프로토콜은 숫자 응답 코드 대신 응답 문자열을 가질 수 있습니다.

```text
   failed-uri-cause         =  "Failed-URI-Cause" ":" 1*UTFCHAR
                               CRLF
```

---
#### **10.4.7.  Record-URI**

레코더 메서드에 이 헤더 필드가 포함된 경우 서버는 오디오를 캡처하여 저장해야 합니다. 헤더 필드가 있지만 값 없이 지정된 경우 서버는 콘텐츠를 로컬에 저장하고 이를 가리키는 URI를 생성해야 합니다. 그런 다음 이 URI는 STOP 응답 또는 RECORD-COMPLETE 이벤트에서 반환됩니다. RECORD 메서드의 헤더 필드가 URI를 지정하는 경우 서버는 해당 위치에서 오디오를 캡처하여 저장하려고 시도해야 합니다. RECORD 요청에서 이 헤더 필드가 지정되지 않은 경우 서버는 오디오를 캡처하고 인코딩하고 STOP 응답 또는 RECORD-COMPLETE 이벤트에서 메시지 본문으로 보내야 합니다. 이 경우

오디오 콘텐츠를 전달하는 응답에는 메시지 본문의 Content-ID를 가리키는 이 헤더에 Content ID\(cid\) \[RFC2392\] 값이 포함되어야 합니다.

서버는 또한 녹음된 오디오 파형의 크기를 옥텟 단위로, 지속 시간을 밀리초 단위로 헤더 필드와 연관된 매개변수로 반환해야 합니다.

구현은 URI에서 'http' \[RFC2616\], 'https' \[RFC2818\], 'file' \[RFC3986\] 및 'cid' \[RFC2392\] 체계를 지원해야 합니다. 다른 체계를 지원하는 구현이 이미 존재한다는 점에 유의하세요.

```text
   record-uri               =  "Record-URI" ":" ["<" uri ">"
                               ";" "size" "=" 1*19DIGIT
                               ";" "duration" "=" 1*19DIGIT] CRLF
```

---
#### **10.4.8.  Media-Type**

RECORD 메서드는 캡처된 오디오나 비디오의 미디어 유형을 서버에 지정하는 이 헤더 필드를 포함해야 합니다.

```text
   media-type               =  "Media-Type" ":" media-type-value
                               CRLF
```

---
#### **10.4.9.  Max-Time**

녹음이 시작되면 실제 캡처 및 저장이 시작되는 시간부터 계산된 최대 녹음 길이\(밀리초\)를 지정하며 반드시 RECORD 메서드가 수신되는 시간은 아닙니다. 레코더 리소스에서 무음 억제\(있는 경우\)가 적용되기 전의 기간을 지정합니다. 이 시간 이후에는 녹음이 중지되고 서버는 RECORD-COMPLETE 이벤트를 클라이언트에 반환해야 하며 요청 상태가 COMPLETE여야 합니다. 이 헤더 필드는 RECORD, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다. 이 헤더 필드의 값은 0에서 구현별 최대값까지입니다. 값 0은 무한대를 의미하므로 다른 중지 조건 중 하나 이상이 충족될 때까지 녹음이 계속됩니다. 이 헤더 필드의 기본값은 0입니다.

```text
   max-time                 =  "Max-Time" ":" 1*19DIGIT CRLF
```

---
#### **10.4.10.  Trim-Length**

이 헤더 필드는 STOP 메서드에서 전송될 수 있으며, 정지 후 녹음 끝에서 트리밍할 오디오 길이를 지정합니다. 길이는 밀리초로 해석됩니다. 이 헤더 필드의 기본값은 0입니다.

```text
   trim-length                 =  "Trim-Length" ":" 1*19DIGIT CRLF
```

---
#### **10.4.11.  Final-Silence**

레코더가 시작되고 실제 캡처가 시작되면 이 헤더 필드는 녹음의 끝으로 해석될 오디오의 무음 길이를 지정합니다. 이 헤더 필드는 RECORD, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 이 헤더 필드의 값은 0에서 구현에 따라 달라지는 최대값까지이며 밀리초로 해석됩니다. 값 0은 무한대를 의미하므로 다른 중지 조건 중 하나가 충족될 때까지 녹음이 계속됩니다. 이 헤더 필드의 기본값은 구현에 따라 달라집니다.

```text
   final-silence            =  "Final-Silence" ":" 1*19DIGIT CRLF
```

---
#### **10.4.12.  Capture-On-Speech**

"false"이면 레코더는 시작하자마자 즉시 캡처를 시작해야 합니다. "true"이면 레코더는 캡처를 시작하기 전에 엔드포인트 기능이 음성을 감지할 때까지 기다려야 합니다. 이 헤더 필드는 RECORD, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 이 헤더 필드의 값은 부울입니다. 이 헤더 필드의 기본값은 "false"입니다.

```text
   capture-on-speech        =  "Capture-On-Speech " ":" BOOLEAN CRLF
```

---
#### **10.4.13.  Ver-Buffer-Utterance**

이 헤더 필드는 검증자 리소스에 대해 설명된 것과 동일합니다\(섹션 11.4.14 참조\). 이것은 서버에 이 녹음 요청과 관련된 발화를 검증 버퍼에 버퍼링하라고 지시합니다. 이 헤더 필드를 보내는 것은 검증 버퍼가 세션을 위한 경우에만 허용됩니다. 이 버퍼는 세션 내의 리소스에서 공유됩니다. 이 세션에 검증자 리소스가 추가되면 인스턴스화되고, 세션에서 검증자 리소스가 해제되면 해제됩니다.

---
#### **10.4.14.  Start-Input-Timers**

이 헤더 필드는 RECORD 요청의 일부로 전송될 수 있습니다. "false" 값은 레코더 리소스에 작업을 시작하도록 지시하지만 클라이언트가 레코더 리소스에 START-INPUT-TIMERS 요청을 보낼 때까지 무입력 타이머를 시작하지 않도록 지시합니다. 이것은 레코더와 신시사이저 리소스가 동일한 세션의 일부가 아닌 시나리오에서 유용합니다. kill-on-barge-in 프롬프트가 재생되는 경우 클라이언트는 RECORD 요청이 동시에 활성화되어 kill-on-barge-in을 감지하고 구현할 수 있기를 원할 수 있습니다\(섹션 8.4.2 참조\). 그러나 동시에 클라이언트는 프롬프트가 완료될 때까지 레코더 리소스가 무입력 타이머를 시작하지 않기를 원합니다. 기본값은 "true"입니다.

```text
   start-input-timers       =  "Start-Input-Timers" ":"
                               BOOLEAN CRLF
```

---
#### **10.4.15.  New-Audio-Channel**

이 헤더 필드는 인식기 리소스에 대해 설명된 것과 동일합니다\(섹션 9.4.23 참조\).

---
### **10.5.  Recorder Message Body**

RECORD 요청에 Record-URI 헤더 필드가 없는 경우 STOP 응답 또는 RECORD-COMPLETE 이벤트에는 캡처된 오디오를 전달하는 메시지 본문이 포함되어야 합니다. 이 경우 오디오 콘텐츠를 전달하는 메시지에는 녹음된 오디오를 포함하는 메시지 본문 엔터티를 가리키는 콘텐츠 ID 값이 있는 Record-URI 헤더 필드가 있습니다. 자세한 내용은 섹션 10.4.7을 참조하십시오.

---
### **10.6.  RECORD**

RECORD 요청은 레코더 리소스를 레코딩 상태로 전환합니다. RECORD 메서드에 지정된 헤더 필드에 따라 리소스는 오디오를 즉시 레코딩하거나 엔드포인트 기능이 오디오에서 음성을 감지할 때까지 기다릴 수 있습니다. 그런 다음 오디오는 메시지 본문이나 Record-URI에서 지정한 대로 클라이언트에서 사용할 수 있습니다.

서버는 반드시 'https' URI 체계를 지원해야 하며 다른 체계를 지원할 수도 있습니다. 음성 녹음의 민감한 특성으로 인해 참조 해제에 사용되는 모든 프로토콜은 제어된 환경 사용\(섹션 4.2 참조\)과 같은 다른 수단을 사용하지 않는 한 무결성과 기밀성을 사용해야 합니다.

RECORD 작업이 이미 진행 중이면 이 메서드를 호출하면 서버는 상태 코드 402 "이 상태에서는 메서드가 유효하지 않음"과 요청 상태 COMPLETE를 갖는 응답을 발행합니다.

Record-URI가 유효하지 않으면 응답에서 404 "헤더 필드에 대한 불법 값" 상태 코드가 반환됩니다. 서버가 요청된 저장된 콘텐츠를 생성할 수 없는 경우 407 "메서드 또는 작업 실패" 상태 코드가 반환됩니다.

Media-Type 헤더 필드에 지정된 유형이 지원되지 않는 경우, 서버는 응답에 Media-Type 헤더 필드를 포함하여 409 "지원되지 않는 헤더 필드 값" 상태 코드로 응답해야 합니다.

녹음 작업이 시작되면 응답은 IN-PROGRESS 요청 상태를 나타냅니다. 서버는 음성이 감지되면 후속 START-OF-INPUT 이벤트를 생성할 수 있습니다. 녹음 작업이 완료되면 서버는 RECORD-COMPLETE 이벤트를 생성합니다.

```text
   C->S:  MRCP/2.0 ... RECORD 543257
          Channel-Identifier:32AECB23433802@recorder
          Record-URI:<file://mediaserver/recordings/myfile.wav>
          Media-Type:audio/wav
          Capture-On-Speech:true
          Final-Silence:300
          Max-Time:6000

   S->C:  MRCP/2.0 ... 543257 200 IN-PROGRESS
          Channel-Identifier:32AECB23433802@recorder

   S->C:  MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS
          Channel-Identifier:32AECB23433802@recorder

   S->C:  MRCP/2.0 ... RECORD-COMPLETE 543257 COMPLETE
          Channel-Identifier:32AECB23433802@recorder
          Completion-Cause:000 success-silence
          Record-URI:<file://mediaserver/recordings/myfile.wav>;
                     size=242552;duration=25645

                              RECORD Example
```

---
### **10.7.  STOP**

STOP 메서드는 레코더를 레코딩 상태에서 유휴 상태로 다시 옮깁니다. RECORD 요청이 활성화되어 있고 STOP 요청이 성공적으로 종료하는 경우 STOP 응답에는 종료된 RECORD 요청 ID가 포함된 Active-Request-Id-List 헤더 필드가 포함되어야 합니다. 이 경우 RECORD-COMPLETE 이벤트가 전송되지 않습니다.

종료된 요청의 경우. 활성화된 녹음이 없는 경우 응답에는 Active-Request-Id-List 헤더 필드가 포함되어서는 안 됩니다. 녹음이 성공한 경우 STOP 응답에는 녹음된 오디오 콘텐츠나 녹음된 오디오가 포함된 STOP 응답 본문의 입력된 엔터티를 가리키는 Record-URI 헤더 필드가 포함되어야 합니다. STOP 메서드에는 Trim-Length 헤더 필드가 있을 수 있으며, 이 경우 지정된 길이의 오디오가 중지 후 녹음 끝에서 트리밍됩니다. 어떤 경우든 응답에는 200 "성공" 상태 코드가 포함되어야 합니다.

```text
   C->S:  MRCP/2.0 ... RECORD 543257
          Channel-Identifier:32AECB23433802@recorder
          Record-URI:<file://mediaserver/recordings/myfile.wav>
          Capture-On-Speech:true
          Final-Silence:300
          Max-Time:6000

   S->C:  MRCP/2.0 ... 543257 200 IN-PROGRESS
          Channel-Identifier:32AECB23433802@recorder

   S->C:  MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS
          Channel-Identifier:32AECB23433802@recorder

   C->S:  MRCP/2.0 ... STOP 543257
          Channel-Identifier:32AECB23433802@recorder
          Trim-Length:200

   S->C:  MRCP/2.0 ... 543257 200 COMPLETE
          Channel-Identifier:32AECB23433802@recorder
          Record-URI:<file://mediaserver/recordings/myfile.wav>;
                     size=324253;duration=24561
          Active-Request-Id-List:543257

                               STOP Example
```

---
### **10.8.  RECORD-COMPLETE**

입력이 없거나, 음성 후 침묵하거나, 최대 시간에 도달하여 녹음이 완료되면 서버는 COMPLETE 요청 상태로 클라이언트에 RECORD-COMPLETE 이벤트를 생성해야 합니다. 녹음이 성공한 경우 RECORD-COMPLETE 이벤트에는 서버의 녹음된 오디오 파일이나 녹음된 오디오가 포함된 메시지 본문의 입력된 엔터티를 가리키는 Record-URI 헤더 필드가 포함됩니다.

```text
   C->S:  MRCP/2.0 ... RECORD 543257
          Channel-Identifier:32AECB23433802@recorder
          Record-URI:<file://mediaserver/recordings/myfile.wav>
          Capture-On-Speech:true
          Final-Silence:300
          Max-Time:6000

   S->C:  MRCP/2.0 ... 543257 200 IN-PROGRESS
          Channel-Identifier:32AECB23433802@recorder

   S->C:  MRCP/2.0 ... START-OF-INPUT 543257 IN-PROGRESS
          Channel-Identifier:32AECB23433802@recorder

   S->C:  MRCP/2.0 ... RECORD-COMPLETE 543257 COMPLETE
          Channel-Identifier:32AECB23433802@recorder
          Completion-Cause:000 success
          Record-URI:<file://mediaserver/recordings/myfile.wav>;
                     size=325325;duration=24652

                          RECORD-COMPLETE Example
```

---
### **10.9.  START-INPUT-TIMERS**

이 요청은 kill-on-barge-in 프롬프트가 재생을 마쳤음을 발견했을 때 클라이언트에서 레코더 리소스로 전송됩니다\(섹션 8.4.2 참조\). 레코더와 신시사이저 리소스가 동일한 MRCPv2 세션에 없는 시나리오에서 유용합니다. kill-on-barge-in 프롬프트가 재생 중일 때 클라이언트는 RECORD 요청이 동시에 활성화되어 kill-on-barge-in을 감지하고 구현할 수 있기를 원합니다. 하지만 동시에 클라이언트는 프롬프트가 완료될 때까지 레코더 리소스가 무입력 타이머를 시작하지 않기를 원합니다. RECORD 요청의 Start-Input-Timers 헤더 필드를 통해 클라이언트는 타이머를 시작해야 할지 여부를 지정할 수 있습니다. 위의 경우, 클라이언트가 레코더에 START-INPUT-TIMERS 메서드를 보낼 때까지 레코더 리소스는 타이머를 시작하지 않습니다.

---
### **10.10.  START-OF-INPUT**

START-OF-INPUT 이벤트는 서버에서 음성을 감지하면 클라이언트로 반환됩니다. 이 이벤트는 음성이 감지되면 항상 레코더 리소스에서 반환됩니다. 레코더 리소스는 또한 이 이벤트에 대한 고유한 값이 있는 Proxy-Sync-Id 헤더 필드를 보내야 합니다.

```text
   S->C:  MRCP/2.0 ... START-OF-INPUT 543259 IN-PROGRESS
          Channel-Identifier:32AECB23433801@recorder
          Proxy-Sync-Id:987654321
```

---
## **11.  Speaker Verification and Identification**

이 섹션에서는 MRCPv2가 화자 확인/식별을 위해 사용하는 방법, 응답 및 이벤트를 설명합니다.

화자 검증은 사용자에게 민감한 정보와 거래에 대한 액세스 권한을 부여하기 위해 화자를 식별하는 데 사용할 수 있는 음성 인증 방법입니다. 음성은 생체 인식이므로 생체 인증 기술과 관련된 여러 가지 필수적인 보안 고려 사항이 구현 및 사용에 적용됩니다. 구현자는 이 문서의 섹션 12와 SPEECHSC 요구 사항 \[RFC4313\]의 해당 섹션을 주의 깊게 읽어야 합니다. 이 기술의 구현자 및 배포자는 최신 위험과 개발되었을 수 있는 솔루션이 있는지 최신 기술을 확인하는 것이 좋습니다.

화자 검증에서 녹음된 발화는 이전에 저장된 음성 지문과 비교되고, 이는 다시 해당 사용자의 주장된 신원과 연결됩니다. 검증은 일반적으로 두 단계로 구성됩니다. 호출자의 주장된 신원을 확립하는 지정 단계와 음성 지문이 생성\(훈련\)되거나 주장된 신원을 인증하는 데 사용되는 실행 단계\(검증\).

화자 식별은 알려지지 않은 화자를 인구의 구성원과 연관시키는 프로세스입니다. 신원 주장을 사용하지 않습니다. 개인이 그룹\(예: 공동 은행 계좌 소유자 중 한 명\)에 속한다고 주장하면 그룹 인증이 수행됩니다. 이는 일반적으로 두 개 이상의 음성 모델과 비교하는 일종의 검증으로 구현됩니다. 이를 '다중 검증'이라고도 합니다. 개별 화자를 그룹에서 식별할 수 있는 경우 여러 사용자가 일부 데이터 또는 애플리케이션에 대한 동일한 액세스 권한을 공유하는 애플리케이션에 유용할 수 있습니다. 화자 식별 및 그룹 인증도 지정 단계와 실행 단계의 두 단계로 수행됩니다. 기능적 관점에서 식별은 그룹이 전체 인구인 그룹 인증\(개인이 식별된 경우\)의 특수한 경우로 간주될 수 있지만 화자 식별 구현은 그룹 인증이 수행되는 방식과 다를 수 있습니다. 단일 음성 지문 검증, 다중 음성 지문에 대한 검증, 그룹 인증 및 식별을 수용하기 위해 이 사양은 "음성 지문 식별자"라고 하는 식별자 목록을 가져와서 각 식별자에 대한 점수가 있는 식별자 목록을 반환할 수 있는 단일 메서드 집합을 제공합니다. 이 점수는 입력 음성이 각 식별자와 얼마나 잘 일치하는지를 나타냅니다. 식별자의 입력 및 출력 목록은 일치할 필요가 없으므로 공급업체별 그룹 식별자를 입력으로 사용하여 식별이

수행되어야 합니다. 이 명세서에서 "식별" 및 "다중 검증"이라는 용어는 입력이 그룹\(잠재적으로 전체 인구\)을 나타내고 여러 음성 지문에 대한 결과가 반환될 수 있음을 나타내는 데 사용됩니다.

검증자 리소스가 인식자 리소스와 동일한 세션을 공유하거나 독립적으로 작동할 수 있습니다. 동일한 세션을 공유하려면 검증자 및 인식자 리소스를 동일한 SIP 대화 내에서 할당해야 합니다. 그렇지 않으면 동일한 물리적 서버 또는 별도의 서버에서 실행되는 독립적인 검증자 리소스가 설정됩니다. 두 리소스를 동일한 INVITE에서 할당할 수 있을 뿐만 아니라, 처음에 하나를 할당하고 나중에 re-INVITE를 통해 다른 하나를 할당할 수도 있습니다.

아래에 설명된 일부 스피커 검증 방법은 특정 작동 모드에만 적용됩니다.

검증자 리소스에는 연관된 검증 버퍼가 있습니다\(섹션 11.4.14 참조\). 이를 통해 버퍼링된 음성에서 검증, 식별 또는 학습을 목적으로 음성 발화를 저장할 수 있습니다. 이 버퍼는 검증자 리소스가 소유하지만 다른 입력 리소스\(예: 인식자 리소스 또는 레코더 리소스\)가 여기에 쓸 수 있습니다. 이를 통해 인식 또는 녹음 작업의 일부로 수신된 음성을 나중에 검증, 식별 또는 학습에 사용할 수 있습니다. 버퍼에 대한 액세스는 한 번에 하나의 작업으로 제한됩니다. 따라서 리소스가 ver-buffer-utterance가 켜진 RECOGNIZE와 같이 읽기, 쓰기 또는 삭제 작업을 수행하는 경우 버퍼와 관련된 다른 작업이 상태 코드 402로 실패합니다. 검증 버퍼는 클라이언트의 CLEAR-BUFFER 요청으로 지울 수 있으며 검증자 리소스가 할당 해제되거나 서버와의 세션이 종료되면 해제됩니다.

검증 버퍼는 파형을 수집하여 실시간 오디오 스트림이나 저장된 오디오를 사용하여 처리하는 것과 다릅니다. 이 버퍼링 메커니즘은 단순히 음성을 버퍼에 축적하지 않기 때문입니다. 검증 버퍼에는 인식기 리소스가 수집한 추가 정보가 포함되어 검증 성능을 개선하는 데 도움이 될 수 있습니다.

---
### **11.1.  Speaker Verification State Machine**

스피커 검증은 훈련 또는 검증 세션에서 작동할 수 있습니다. 이러한 세션 중 하나를 시작해도 검증자 리소스의 상태는 변경되지 않습니다. 즉, 유휴 상태로 유지됩니다. 검증 또는 훈련 세션이 시작되면 발화가 훈련되거나 검증됩니다.

VERIFY 또는 VERIFY-FROM-BUFFER 메서드를 호출하여. 검증자 리소스의 상태는 VERIFY 또는 VERIFY-FROM-BUFFER가 호출될 때마다 IDLE에서 VERIFYING 상태로 전환됩니다.

```text
     Idle              Session Opened       Verifying/Training
     State             State                State
      |                   |                         |
      |--START-SESSION--->|                         |
      |                   |                         |
      |                   |----------|              |
      |                   |     START-SESSION       |
      |                   |<---------|              |
      |                   |                         |
      |<--END-SESSION-----|                         |
      |                   |                         |
      |                   |---------VERIFY--------->|
      |                   |                         |
      |                   |---VERIFY-FROM-BUFFER--->|
      |                   |                         |
      |                   |----------|              |
      |                   |  VERIFY-ROLLBACK        |
      |                   |<---------|              |
      |                   |                         |
      |                   |                |--------|
      |                   | GET-INTERMEDIATE-RESULT |
      |                   |                |------->|
      |                   |                         |
      |                   |                |--------|
      |                   |     START-INPUT-TIMERS  |
      |                   |                |------->|
      |                   |                         |
      |                   |                |--------|
      |                   |         START-OF-INPUT  |
      |                   |                |------->|
      |                   |                         |
      |                   |<-VERIFICATION-COMPLETE--|
      |                   |                         |
      |                   |<--------STOP------------|
      |                   |                         |
      |                   |----------|              |
      |                   |         STOP            |
      |                   |<---------|              |
      |                   |                         |
      |----------|        |                         |
      |         STOP      |                         |
      |<---------|        |                         |

      |                   |----------|              |
      |                   |    CLEAR-BUFFER         |
      |                   |<---------|              |
      |                   |                         |
      |----------|        |                         |
      |   CLEAR-BUFFER    |                         |
      |<---------|        |                         |
      |                   |                         |
      |                   |----------|              |
      |                   |   QUERY-VOICEPRINT      |
      |                   |<---------|              |
      |                   |                         |
      |----------|        |                         |
      | QUERY-VOICEPRINT  |                         |
      |<---------|        |                         |
      |                   |                         |
      |                   |----------|              |
      |                   |  DELETE-VOICEPRINT      |
      |                   |<---------|              |
      |                   |                         |
      |----------|        |                         |
      | DELETE-VOICEPRINT |                         |
      |<---------|        |                         |

                      Verifier Resource State Machine
```

---
### **11.2.  Speaker Verification Methods**

검증자 리소스는 다음과 같은 방법을 지원합니다.

```text
   verifier-method          =  "START-SESSION"
                            / "END-SESSION"
                            / "QUERY-VOICEPRINT"
                            / "DELETE-VOICEPRINT"
                            / "VERIFY"
                            / "VERIFY-FROM-BUFFER"
                            / "VERIFY-ROLLBACK"
                            / "STOP"
                            / "CLEAR-BUFFER"
                            / "START-INPUT-TIMERS"
                            / "GET-INTERMEDIATE-RESULT"
```

이러한 방법을 사용하면 클라이언트가 세션 컨텍스트 내에서 검증 또는 식별 작업의 모드와 대상을 제어할 수 있습니다. 세션 내에서 발생하는 모든 검증 입력 작업은 다음을 생성, 업데이트 또는 검증하는 데 사용할 수 있습니다.

세션 중에 지정된 음성 지문. 각 세션의 시작 시, 검증자 리소스는 이전 검증 세션 이전의 상태로 재설정됩니다.

검증/식별 작업은 라이브 또는 버퍼링된 오디오에 대해 실행될 수 있습니다. 검증자 리소스는 라이브 오디오 데이터를 수집하고 평가하는 방법과 검증자 리소스를 제어하고 구성된 동작을 조정하는 방법을 제공합니다.

버퍼링된 오디오 데이터를 수집하기 위한 전용 방법은 없습니다. 이는 리소스에 적합한 VERIFY, RECOGNIZE 또는 RECORD를 호출하여 헤더 필드 Ver-Buffer-Utterance로 수행합니다. 그런 다음 다음 메서드가 호출되면 버퍼링된 오디오 세트를 사용하여 검증이 수행됩니다.

```text
   1.  VERIFY-FROM-BUFFER
```

라이브 오디오 발언을 검증하는 데는 다음 방법을 사용합니다.

```text
   1.  VERIFY

   2.  START-INPUT-TIMERS
```

다음 방법은 검증자 리소스를 구성하고 리소스 상태를 설정하는 데 사용됩니다.

```text
   1.  START-SESSION

   2.  END-SESSION

   3.  QUERY-VOICEPRINT

   4.  DELETE-VOICEPRINT

   5.  VERIFY-ROLLBACK

   6.  STOP

   7.  CLEAR-BUFFER
```

다음 방법을 사용하면 진행 중인 검증에 대한 중간 결과를 폴링할 수 있습니다.

```text
   1.  GET-INTERMEDIATE-RESULT
```

---
### **11.3.  Verification Events**

검증 리소스는 다음 이벤트를 생성합니다.

```text
   verifier-event       =  "VERIFICATION-COMPLETE"
                        /  "START-OF-INPUT"
```

---
### **11.4.  Verification Header Fields**

검증 리소스 메시지에는 요청 옵션과 연관된 요청, 응답 또는 이벤트 메시지를 보강하기 위한 정보가 포함된 헤더 필드가 포함될 수 있습니다.

```text
   verification-header      =  repository-uri
                            /  voiceprint-identifier
                            /  verification-mode
                            /  adapt-model
                            /  abort-model
                            /  min-verification-score
                            /  num-min-verification-phrases
                            /  num-max-verification-phrases
                            /  no-input-timeout
                            /  save-waveform
                            /  media-type
                            /  waveform-uri
                            /  voiceprint-exists
                            /  ver-buffer-utterance
                            /  input-waveform-uri
                            /  completion-cause
                            /  completion-reason
                            /  speech-complete-timeout
                            /  new-audio-channel
                            /  abort-verification
                            /  start-input-timers
```

---
#### **11.4.1.  Repository-URI**

이 헤더 필드는 화자 검증 또는 식별 작업 중에 사용하거나 참조할 음성 지문 저장소를 지정합니다. 이 헤더 필드는 START-SESSION, QUERY-VOICEPRINT 및 DELETE-VOICEPRINT 메서드에서 필요합니다.

```text
   repository-uri           =  "Repository-URI" ":" uri CRLF
```

---
#### **11.4.2.  Voiceprint-Identifier**

이 헤더 필드는 검증 애플리케이션에 대한 클레임된 ID를 지정합니다. 클레임된 ID는 기존 음성 지문을 지정하거나 새 음성 지문을 설정하는 데 사용될 수 있습니다. 이 헤더 필드는 QUERY-VOICEPRINT 및 DELETE-VOICEPRINT 메서드에 반드시 있어야 합니다. Voiceprint-Identifier는 검증 작업을 위해 START-SESSION 메서드에 반드시 있어야 합니다. 식별 또는 다중 검증 작업의 경우 이 헤더 필드에는 세미콜론으로 구분된 음성 지문 식별자 목록이 포함될 수 있습니다. 식별 작업의 경우 클라이언트는 음성 지문 식별자 목록 대신 음성 지문 그룹 식별자를 지정할 수도 있습니다.

```text
   voiceprint-identifier        =  "Voiceprint-Identifier" ":"
                                   vid *[";" vid] CRLF
   vid                          =  1*VCHAR ["." 1*VCHAR]
```

---
#### **11.4.3.  Verification-Mode**

이 헤더 필드는 검증자 리소스의 모드를 지정하며 START-SESSION 메서드에 의해 설정됩니다. 허용되는 값은 검증 세션이 음성 지문을 훈련\("train"\)할지 또는 기존 음성 지문을 사용하여 검증/식별\("verify"\)할지 여부를 나타냅니다.

훈련 및 검증 세션은 모두 START-SESSION에서 음성 지문 저장소 URI를 지정해야 합니다. 그러나 많은 사용 시나리오에서 시스템은 사용자가 액세스하려는 계정 번호를 인식하는 등의 인식 작업이 수행될 때까지 화자가 주장한 신원을 알지 못합니다. 대화의 처음 몇 개의 발화를 인식하고 검증할 수 있도록 MRCPv2 서버의 검증 리소스는 버퍼를 유지합니다. 이 버퍼에서 MRCPv2 서버는 인식된 발화를 누적합니다. 클라이언트는 나중에 검증 방법을 실행하고 버퍼링된 발화를 현재 검증 세션에 적용할 수 있습니다.

일부 음성 사용자 인터페이스는 검증 대상이 되어서는 안 되는 추가 사용자 입력이 필요할 수 있습니다. 예를 들어, 사용자 입력이 낮은 신뢰도로 인식되어 확인 주기가 필요할 수 있습니다. 이러한 경우 클라이언트는 호출자의 입력을 수집하고 분석하기 위해 VERIFY 또는 VERIFY-FROM-BUFFER 메서드를 실행해서는 안 됩니다. 별도의 인식자 리소스는 검증자 리소스의 참여 없이 호출자의 응답을 분석할 수 있습니다.

다음 조건이 충족되면:

1. START-SESSION 메서드의 Voiceprint-Identifier 헤더 필드를 통해 음성 지문 ID가 성공적으로 설정되었으며,

1. 검증 모드가 "train" 또는 "verify" 중 하나로 설정되었습니다.

검증자 리소스는 검증 작업 중에 검증 정보 제공을 시작할 수 있습니다. 검증자 리소스가 두 가지 주요 상태\("train" 또는 "verify"\) 중 하나에 도달하지 못하면 MRCPv2 상태 코드에서 오류 조건을 보고하여 검증자 리소스가 해당 용도에 대해 준비되지 않은 이유를 표시해야 합니다.

verification-mode의 값은 검증 세션 내에서 지속됩니다. 클라이언트가 검증 세션 중에 모드를 변경하려고 하면 verifier 리소스가 오류를 보고하고 모드는 현재 값을 유지합니다.

```text
   verification-mode            =  "Verification-Mode" ":"
                                   verification-mode-string

   verification-mode-string     =  "train"
                                /  "verify"
```

---
#### **11.4.4.  Adapt-Model**

이 헤더 필드는 성공적인 검증 작업 후 검증자 리소스의 원하는 동작을 나타냅니다. 이 헤더 필드의 값이 "true"인 경우 서버는 검증 세션 동안 수집된 오디오를 사용하여 화자의 수신 음성 특성의 지속적인 변화를 고려하여 음성 지문을 업데이트해야 합니다. 단, 로컬 정책에서 음성 지문 업데이트를 금지하는 경우는 예외입니다. 값이 "false"\(기본값\)인 경우 서버는 음성 지문을 업데이트해서는 안 됩니다. 이 헤더 필드는 START-SESSION 메서드에서 발생할 수 있습니다.

```text
   adapt-model              = "Adapt-Model" ":" BOOLEAN CRLF
```

---
#### **11.4.5.  Abort-Model**

Abort-Model 헤더 필드는 세션 종료 시 검증자 리소스의 원하는 동작을 나타냅니다. 이 헤더 필드의 값이 "true"이면 서버는 검증 훈련 또는 검증 적응으로 인해 보류 중인 음성 지문 변경 사항을 모두 삭제해야 합니다. 값이 "false"\(기본값\)이면 서버는 훈련 세션 또는 성공적인 세션에 대한 보류 중인 변경 사항을 모두 커밋해야 합니다.

음성 지문 저장소에 대한 검증 세션. Abort-Model에 대한 "true" 값은 Adapt-Model 헤더 필드에 대한 "true" 값을 재정의합니다. 이 헤더 필드는 END-SESSION 메서드에서 발생할 수 있습니다.

```text
   abort-model             = "Abort-Model" ":" BOOLEAN CRLF
```

---
#### **11.4.6.  Min-Verification-Score**

Min-Verification-Score 헤더 필드는 SET-PARAMS, GET-PARAMS 또는 START-SESSION 메서드를 통해 검증자 리소스와 함께 사용될 때 서버에서 "accepted" 검증 결정을 선언할 수 있는 최소 검증 점수를 결정합니다. 이는 -1.0과 1.0 사이의 float 값입니다. 이 헤더 필드의 기본값은 구현에 따라 다릅니다.

```text
   min-verification-score  = "Min-Verification-Score" ":"
                             [ %x2D ] FLOAT CRLF
```

---
#### **11.4.7.  Num-Min-Verification-Phrases**

Num-Min-Verification-Phrases 헤더 필드는 검증을 위해 긍정적인 결정이 내려지기 전에 유효한 발화의 최소 개수를 지정하는 데 사용됩니다. 이 헤더 필드의 값은 정수이고 기본값은 1입니다. 검증자 리소스는 Num-Min-Verification-Phrases 유효한 발화를 수신하지 않는 한 검증을 '허용됨'으로 선언해서는 안 됩니다. 최소값은 1입니다. 이 헤더 필드는 START-SESSION, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다.

```text
   num-min-verification-phrases =  "Num-Min-Verification-Phrases" ":"
                                   1*19DIGIT CRLF
```

---
#### **11.4.8.  Num-Max-Verification-Phrases**

Num-Max-Verification-Phrases 헤더 필드는 검증을 위해 결정을 강제하기 전에 필요한 유효한 발화의 수를 지정하는 데 사용됩니다. 검증자 리소스는 Num-Max-Verification-Phrases가 수집되어 검증 점수를 결정하는 데 사용된 후에는 'undecided' 결정을 반환해서는 안 됩니다. 이 헤더 필드의 값은 정수이고 최소값은 1입니다. 기본값은 구현에 따라 다릅니다. 이 헤더 필드는 START-SESSION, SET-PARAMS 또는 GET-PARAMS에서 발생할 수 있습니다.

```text
   num-max-verification-phrases =  "Num-Max-Verification-Phrases" ":"
                                    1*19DIGIT CRLF
```

---
#### **11.4.9.  No-Input-Timeout**

No-Input-Timeout 헤더 필드는 검증 타이머의 시작\(START-INPUT-TIMERS 참조\)부터 VERIFICATION-COMPLETE 서버 이벤트 메시지가 입력을 받지 못했다고 선언할 때까지의 시간 길이를 설정합니다\(즉, Completion-Cause가 no-input-timeout임\). 값은 밀리초 단위입니다. 이 헤더 필드는 VERIFY, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다. 이 헤더 필드의 값은 0에서 구현별 최대값까지입니다. 이 헤더 필드의 기본값은 구현별입니다.

```text
   no-input-timeout         = "No-Input-Timeout" ":" 1*19DIGIT CRLF
```

---
#### **11.4.10.  Save-Waveform**

이 헤더 필드를 사용하면 클라이언트가 검증자 리소스에 검증/식별에 사용된 오디오 스트림을 저장하도록 요청할 수 있습니다. 검증자 리소스는 오디오를 녹음하고 VERIFICATION-COMPLETE 이벤트의 Waveform-URI 헤더 필드에 반환된 URI 형태로 클라이언트에서 사용할 수 있도록 해야 합니다. 스트림을 녹음하는 데 오류가 있거나 오디오 콘텐츠를 사용할 수 없는 경우 검증자 리소스는 빈 Waveform-URI 헤더 필드를 반환해야 합니다. 이 헤더 필드의 기본값은 "false"입니다. 이 헤더 필드는 VERIFY 메서드에 나타날 수 있습니다. 이 헤더 필드는 라이브 검증/식별 작업을 위해 파형을 저장할지 여부만 제어하기 때문에 VERIFY-FROM-BUFFER 메서드에 나타나지 않습니다.

```text
   save-waveform            =  "Save-Waveform" ":" BOOLEAN CRLF
```

---
#### **11.4.11.  Media-Type**

이 헤더 필드는 SET-PARAMS, GET-PARAMS 또는 VERIFY 메서드에서 지정할 수 있으며, 서버 리소스에 Waveform-URI 헤더 필드에서 캡처되어 반환된 것과 같은 캡처된 오디오 또는 비디오의 미디어 유형을 알려줍니다.

```text
   media-type               =  "Media-Type" ":" media-type-value
                               CRLF
```

---
#### **11.4.12.  Waveform-URI**

Save-Waveform 헤더 필드가 "true"로 설정된 경우, 검증 리소스는 검증의 수신 오디오 스트림을 파일에 기록하고 클라이언트가 액세스할 수 있는 URI를 제공해야 합니다. Save-Waveform 헤더 필드가 클라이언트에 의해 true로 설정된 경우 이 헤더 필드는 VERIFICATION-COMPLETE 이벤트에 있어야 합니다. 헤더 필드의 값은 비어 있어야 합니다.

서버가 기록하지 못하게 하는 오류 조건. 그렇지 않으면 서버에서 생성한 URI는 서버와 모든 검증 세션에서 전역적으로 고유해야 합니다. 콘텐츠는 검증 세션이 끝날 때까지 URI를 통해 사용할 수 있어야 합니다. Save-Waveform 헤더 필드는 라이브 검증/식별 작업에만 적용되므로 서버는 라이브 검증/식별 작업에 대한 VERIFICATION-COMPLETE 이벤트에서만 Waveform-URI를 반환할 수 있습니다.

서버는 또한 녹음된 오디오 파형의 크기를 옥텟 단위로, 지속 시간을 밀리초 단위로 헤더 필드와 연관된 매개변수로 반환해야 합니다.

```text
   waveform-uri             =  "Waveform-URI" ":" ["<" uri ">"
                               ";" "size" "=" 1*19DIGIT
                               ";" "duration" "=" 1*19DIGIT] CRLF
```

---
#### **11.4.13.  Voiceprint-Exists**

이 헤더 필드는 QUERY-VOICEPRINT 및 DELETE-VOICEPRINT 응답에서 반환되어야 합니다. 이는 QUERY-VOICEPRINT 메서드에서 지정된 음성 지문의 상태입니다. DELETE-VOICEPRINT 메서드의 경우 이 헤더 필드는 메서드 실행이 시작된 순간의 음성 지문 상태를 나타냅니다.

```text
   voiceprint-exists    =  "Voiceprint-Exists" ":" BOOLEAN CRLF
```

---
#### **11.4.14.  Ver-Buffer-Utterance**

이 헤더 필드는 이 발화가 나중에 화자 검증을 위해 고려될 수 있음을 나타내는 데 사용됩니다. 이런 방식으로 클라이언트는 정기적인 인식 또는 검증 활동을 수행하는 동안 서버에 발화를 버퍼링하도록 요청할 수 있으며, 나중에 버퍼링된 발화에 대해 화자 검증을 요청할 수 있습니다. 이 헤더 필드는 RECOGNIZE, VERIFY 및 RECORD 메서드에서 선택 사항입니다. 이 헤더 필드의 기본값은 "false"입니다.

```text
   ver-buffer-utterance     = "Ver-Buffer-Utterance" ":" BOOLEAN
                              CRLF
```

---
#### **11.4.15.  Input-Waveform-URI**

이 헤더 필드는 클라이언트가 서버에 현재 검증 모드에 따라 가져오고 처리하도록 요청하는 저장된 오디오 콘텐츠를 지정하여 음성 지문을 훈련하거나 주장된 신원을 검증합니다. 이 헤더 필드를 통해 클라이언트는 다음을 구현할 수 있습니다.

인식자와 검증자 리소스가 다른 세션에 있고 검증 버퍼 기술을 사용할 수 없는 버퍼링 사용 사례. VERIFY 요청에서 지정할 수 있습니다.

```text
   input-waveform-uri           =  "Input-Waveform-URI" ":" uri CRLF
```

---
#### **11.4.16.  Completion-Cause**

이 헤더 필드는 verifier 리소스에서 클라이언트로 전송되는 VERIFICATION-COMPLETE 이벤트의 일부여야 합니다. 이는 VERIFY 또는 VERIFY-FROM-BUFFER 메서드 완료의 원인을 나타냅니다. 이 헤더 필드는 실패 상태와 COMPLETE 상태로 반환되는 경우 VERIFY, VERIFY-FROM-BUFFER 및 QUERY-VOICEPRINT 응답에서 반드시 전송되어야 합니다. 아래 ABNF에서 'cause-code'에는 다음 표의 Cause-Code 열에서 선택한 숫자 값이 포함됩니다. 'cause-name'에는 Cause-Name 열에서 선택한 해당 토큰이 포함됩니다.

```text
   completion-cause         =  "Completion-Cause" ":" cause-code SP
                               cause-name CRLF
   cause-code               =  3DIGIT
   cause-name               =  *VCHAR

   +------------+--------------------------+---------------------------+
   | Cause-Code | Cause-Name               | Description               |
   +------------+--------------------------+---------------------------+
   | 000        | success                  | VERIFY or                 |
   |            |                          | VERIFY-FROM-BUFFER        |
   |            |                          | request completed         |
   |            |                          | successfully. The verify  |
   |            |                          | decision can be           |
   |            |                          | "accepted", "rejected",   |
   |            |                          | or "undecided".           |
   | 001        | error                    | VERIFY or                 |
   |            |                          | VERIFY-FROM-BUFFER        |
   |            |                          | request terminated        |
   |            |                          | prematurely due to a      |
   |            |                          | verifier resource or      |
   |            |                          | system error.             |
   | 002        | no-input-timeout         | VERIFY request completed  |
   |            |                          | with no result due to a   |
   |            |                          | no-input-timeout.         |
   | 003        | too-much-speech-timeout  | VERIFY request completed  |
   |            |                          | with no result due to too |
   |            |                          | much speech.              |
   | 004        | speech-too-early         | VERIFY request completed  |
   |            |                          | with no result due to     |
   |            |                          | speech too soon.          |

   | 005        | buffer-empty             | VERIFY-FROM-BUFFER        |
   |            |                          | request completed with no |
   |            |                          | result due to empty       |
   |            |                          | buffer.                   |
   | 006        | out-of-sequence          | Verification operation    |
   |            |                          | failed due to             |
   |            |                          | out-of-sequence method    |
   |            |                          | invocations, for example, |
   |            |                          | calling VERIFY before     |
   |            |                          | QUERY-VOICEPRINT.         |
   | 007        | repository-uri-failure   | Failure accessing         |
   |            |                          | Repository URI.           |
   | 008        | repository-uri-missing   | Repository-URI is not     |
   |            |                          | specified.                |
   | 009        | voiceprint-id-missing    | Voiceprint-Identifier is  |
   |            |                          | not specified.            |
   | 010        | voiceprint-id-not-exist  | Voiceprint-Identifier     |
   |            |                          | does not exist in the     |
   |            |                          | voiceprint repository.    |
   | 011        | speech-not-usable        | VERIFY request completed  |
   |            |                          | with no result because    |
   |            |                          | the speech was not usable |
   |            |                          | (too noisy, too short,    |
   |            |                          | etc.)                     |
   +------------+--------------------------+---------------------------+
```

---
#### **11.4.17.  Completion-Reason**

이 헤더 필드는 검증자 리소스에서 클라이언트로 오는 VERIFICATION-COMPLETE 이벤트에서 지정될 수 있습니다. 여기에는 VERIFY 요청 완료의 이유 텍스트가 포함됩니다. 이 헤더 필드는 실패 이유를 설명하는 텍스트를 전달합니다.

완료 이유 텍스트는 클라이언트가 로그에서 사용하고 디버깅 및 계측 목적으로 제공됩니다. 클라이언트는 완료 이유 텍스트를 해석해서는 안 됩니다.

```text
   completion-reason        =  "Completion-Reason" ":"
                               quoted-string CRLF
```

---
#### **11.4.18.  Speech-Complete-Timeout**

이 헤더 필드는 Recognizer 리소스에 대해 설명된 것과 동일합니다. 섹션 9.4.15를 참조하세요. 이 헤더 필드는 VERIFY, SET-PARAMS 또는 GET-PARAMS에 나타날 수 있습니다.

---
#### **11.4.19.  New-Audio-Channel**

이 헤더 필드는 Recognizer 리소스에 대해 설명된 것과 동일합니다. 섹션 9.4.23을 참조하세요. 이 헤더 필드는 VERIFY 요청에서 지정될 수 있습니다.

---
#### **11.4.20.  Abort-Verification**

이 헤더 필드는 진행 중인 VERIFY 메서드를 중단할지 여부를 나타내기 위해 STOP 요청에서 반드시 전송해야 합니다. "true" 값은 서버에 결과를 삭제하도록 요청합니다. "false" 값은 서버에 STOP 요청을 수신한 시점까지 얻은 검증 결과를 STOP 응답으로 반환하도록 요청합니다.

```text
   abort-verification   =  "Abort-Verification " ":" BOOLEAN CRLF
```

---
#### **11.4.21.  Start-Input-Timers**

이 헤더 필드는 VERIFY 요청의 일부로 전송될 수 있습니다. "false" 값은 검증자 리소스에 VERIFY 작업을 시작하지만 아직 무입력 타이머를 시작하지 말라고 알려줍니다. 검증자 리소스는 클라이언트가 리소스에 START-INPUT-TIMERS 요청을 보낼 때까지 타이머를 시작해서는 안 됩니다. 이는 검증자 리소스와 신시사이저 리소스가 동일한 세션에 속하지 않는 시나리오에서 유용합니다. 이 시나리오에서 kill-on-barge-in 프롬프트가 재생되는 경우 클라이언트는 VERIFY 요청이 동시에 활성화되어 kill-on-barge-in을 감지하고 구현할 수 있기를 원할 수 있습니다\(섹션 8.4.2 참조\). 하지만 동시에 클라이언트는 프롬프트가 완료될 때까지 검증자 리소스가 무입력 타이머를 시작하기를 원하지 않습니다. 기본값은 "true"입니다.

```text
   start-input-timers       =  "Start-Input-Timers" ":"
                               BOOLEAN CRLF
```

---
### **11.5.  Verification Message Body**

확인 응답이나 이벤트 메시지는 다음 하위 섹션에 설명된 대로 추가 데이터를 전달할 수 있습니다.

---
#### **11.5.1.  Verification Result Data**

검증 결과는 섹션 6.3에 설명된 대로 VERIFICATION-COMPLETE 이벤트의 메시지 본문이나 GET-INTERMEDIATE-RESULT 응답 메시지로 클라이언트에게 반환됩니다. NLSML 형식의 검증 부분에 대한 요소 및 속성 설명은 섹션 11.5.2에 제공되며, 섹션 16.3에 스키마의 규범적 정의가 제공됩니다.

---
#### **11.5.2.  Verification Result Elements**

모든 검증 요소는 <result\> 아래의 단일 <verification-result\> 요소에 포함됩니다. 요소는 아래에 설명되어 있으며 섹션 16.2에서 정의된 스키마를 갖습니다. 다음 요소가 정의됩니다.

```text
   1.   <voiceprint>

   2.   <incremental>

   3.   <cumulative>

   4.   <decision>

   5.   <utterance-length>

   6.   <device>

   7.   <gender>

   8.   <adapted>

   9.   <verification-score>

   10.  <vendor-specific-results>
```

---
##### **11.5.2.1.  <voiceprint> Element**

검증 결과의 이 요소는 음성 데이터가 단일 음성 지문과 어떻게 일치하는지에 대한 정보를 제공합니다. 반환된 결과 데이터에는 식별 또는 다중 검증의 경우 두 개 이상의 엔터티가 있을 수 있습니다. 각 <voiceprint\> 요소와 요소 내의 XML 데이터는 음성 데이터가 특정 음성 지문과 얼마나 잘 일치하는지에 대한 검증 결과 정보를 설명합니다. <voiceprint\> 요소 데이터 목록은 누적 검증 일치 점수에 따라 정렬되며 가장 높은 점수가 먼저 나옵니다.

---
##### **11.5.2.2.  <cumulative> Element**

각 <voiceprint\> 요소 내에는 여러 발화가 음성지와 얼마나 잘 일치하는지에 대한 누적 점수를 나타내는 <cumulative\> 요소가 반드시 있어야 합니다.

---
##### **11.5.2.3.  <incremental> Element**

첫 번째 <voiceprint\> 요소는 마지막 발화가 음성지와 얼마나 잘 일치하는지에 대한 증분 점수를 나타내는 <incremental\> 요소를 포함할 수 있습니다.

---
##### **11.5.2.4.  <Decision> Element**

이 요소는 검증 결과 내의 <incremental\> 또는 <cumulative\> 요소에서 발견됩니다. 값은 검증 결정을 나타냅니다. "accepted", "rejected" 또는 "undecided" 값을 가질 수 있습니다.

---
##### **11.5.2.5.  <utterance-length> Element**

이 요소는 첫 번째 <voiceprint\> 요소 내의 <incremental\> 또는 <cumulative\> 요소 내에 나타날 수 있습니다. 해당 값은 각각 마지막 발화 또는 누적된 발화 세트의 크기를 밀리초 단위로 나타냅니다.

---
##### **11.5.2.6.  <device> Element**

이 요소는 검증 결과 내의 <incremental\> 또는 <cumulative\> 요소에서 발견됩니다. 해당 값은 검증자 리소스에서 결정한 대로 호출자가 사용하는 장치의 명백한 유형을 나타냅니다. "cellular-phone", "electret-phone", "carbon-button-phone" 또는 "unknown" 값을 가질 수 있습니다.

---
##### **11.5.2.7.  <gender> Element**

이 요소는 검증 결과 내의 <incremental\> 또는 <cumulative\> 요소에서 발견됩니다. 해당 값은 검증 리소스에서 결정한 화자의 명백한 성별을 나타냅니다. "남성", "여성" 또는 "알 수 없음" 값을 가질 수 있습니다.

---
##### **11.5.2.8.  <adapted> Element**

이 요소는 검증 결과 내의 첫 번째 <voiceprint\> 요소에서 발견됩니다. 검증이 음성 지문을 확인하려고 할 때, 이는 음성 지문이 소스 발화를 분석한 결과로 조정되었는지 여부를 나타냅니다. 검증 훈련 중에는 반환되지 않습니다. 값은 "true" 또는 "false"일 수 있습니다.

---
##### **11.5.2.9.  <verification-score> Element**

이 요소는 검증 결과 내의 <incremental\> 또는 <cumulative\> 요소 내에서 발견됩니다. 그 값은 검증에 의해 결정된 마지막 발화의 점수를 나타냅니다.

검증하는 동안 점수가 높을수록 화자가 음성 지문 발화를 말한 사람과 동일할 가능성이 높습니다. 훈련하는 동안 점수가 높을수록 화자가 분석된 모든 발화를 말했을 가능성이 높습니다. 값은 -1.0과 1.0 사이의 부동 소수점입니다. 그러한 발화가 없으면 점수는 -1입니다. 검증 점수는 확률 값이 아니라는 점에 유의하세요.

---
##### **11.5.2.10.  <vendor-specific-results> Element**

MRCPv2 서버는 MRCPv2 정의 요소에서 제공하는 정보를 보강하는 구현별 데이터가 포함된 검증 결과를 보낼 수 있습니다. 이러한 데이터는 이러한 스키마 확장을 해석하는 방법에 대한 비공개 지식이 있는 클라이언트에게 유용할 수 있습니다. 검증 결과 스키마에 대한 구현별 추가 사항은 공급업체의 자체 네임스페이스에 속해야 합니다. 결과 구조에서 결과 내에 선언된 네임스페이스 접두사로 표시되거나 해당 네임스페이스에 속하는 것으로 식별된 요소의 자식이어야 합니다.

다음 예는 세 가지 음성 지문의 결과를 보여줍니다. 첫 번째 음성 지문은 검증 점수 임계값을 넘었고 화자는 수락되었습니다. 음성 지문은 또한 가장 최근의 발화로 조정되었습니다.

```text
   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           grammar="What-Grammar-URI">
     <verification-result>
       <voiceprint id="johnsmith">
         <adapted> true </adapted>
         <incremental>
           <utterance-length> 500 </utterance-length>
           <device> cellular-phone </device>
           <gender> male </gender>
           <decision> accepted </decision>
           <verification-score> 0.98514 </verification-score>
         </incremental>
         <cumulative>
           <utterance-length> 10000 </utterance-length>
           <device> cellular-phone </device>
           <gender> male </gender>
           <decision> accepted </decision>
           <verification-score> 0.96725</verification-score>
         </cumulative>
       </voiceprint>

       <voiceprint id="marysmith">
         <cumulative>
           <verification-score> 0.93410 </verification-score>
         </cumulative>
       </voiceprint>
       <voiceprint uri="juniorsmith">
         <cumulative>
           <verification-score> 0.74209 </verification-score>
         </cumulative>
       </voiceprint>
     </verification-result>
   </result>

                      Verification Results Example 1
```

다음 예에서 검증자는 화자를 거부하기로 결정할 만큼 충분한 정보를 갖고 있습니다.

```text
   <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           xmlns:xmpl="http://www.example.org/2003/12/mrcpv2"
           grammar="What-Grammar-URI">
     <verification-result>
       <voiceprint id="johnsmith">
         <incremental>
           <utterance-length> 500 </utterance-length>
           <device> cellular-phone </device>
           <gender> male </gender>
           <verification-score> 0.88514 </verification-score>
           <xmpl:raspiness> high </xmpl:raspiness>
           <xmpl:emotion> sadness </xmpl:emotion>
         </incremental>
         <cumulative>
           <utterance-length> 10000 </utterance-length>
           <device> cellular-phone </device>
           <gender> male </gender>
           <decision> rejected </decision>
           <verification-score> 0.9345 </verification-score>
         </cumulative>
       </voiceprint>
     </verification-result>
   </result>

                      Verification Results Example 2
```

---
### **11.6.  START-SESSION**

START-SESSION 메서드는 화자 검증 또는 화자 식별 세션을 시작합니다. 이 메서드를 실행하면 검증자 리소스가 초기 상태로 돌아갑니다. 진행 중인 검증 세션 중에 이 메서드를 호출하면 이전 세션이 암묵적으로 중단됩니다. VERIFY 또는 VERIFY-FROM-BUFFER가 활성화되어 있을 때 이 메서드를 호출하면 메서드가 실패하고 서버는 상태 코드 402를 반환합니다.

START-SESSION 메서드가 완료되면 검증 리소스는 진행 중인 모든 검증 세션을 종료하고 모든 음성 지문 지정을 지워야 합니다.

검증 세션은 세션 중에 사용될 음성 지문 저장소와 연관됩니다. 이는 Repository-URI 헤더 필드를 통해 지정됩니다\(섹션 11.4.1 참조\).

START-SESSION 방법은 또한 Voiceprint-Identifier 헤더 필드를 통해 검증 세션 동안 어떤 음성 지문을 일치시키거나 훈련시킬지 설정합니다. 이것이 식별 세션이거나 클라이언트가 다중 검증을 수행하려는 경우 Voiceprint-Identifier 헤더 필드에는 세미콜론으로 구분된 음성 지문 식별자 목록이 포함됩니다.

Adapt-Model 헤더 필드는 세션 중에 수집된 데이터에 따라 음성 지문을 조정할지 여부를 나타내기 위해 START-SESSION 요청에도 존재할 수 있습니다\(음성 지문 검증 단계가 성공한 경우\). 기본적으로 음성 지문 모델은 검증 세션의 데이터로 조정되어서는 안 됩니다.

START-SESSION은 세션이 train을 위한 것인지 음성 지문을 검증하기 위한 것인지도 결정합니다. 따라서 Verification-Mode 헤더 필드는 모든 START-SESSION 요청에서 반드시 전송되어야 합니다. Verification-Mode 헤더 필드의 값은 "train" 또는 "verify" 중 하나여야 합니다.

검증/식별 세션이 시작되기 전에 클라이언트는 검증자 리소스에서 VERIFY-ROLLBACK 및 일반 SET-PARAMS 및 GET-PARAMS 작업이 수행되도록 요청할 수 있습니다. 서버는 다른 모든 검증 작업에 대해 상태 코드 402 "이 상태에서는 메서드가 유효하지 않음"을 반환해야 합니다.

검증 리소스는 한 번에 두 개 이상의 세션을 활성화해서는 안 됩니다.

```text
   C->S:  MRCP/2.0 ... START-SESSION 314161
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/voiceprintdbase/
          Voiceprint-Mode:verify
          Voiceprint-Identifier:johnsmith.voiceprint
          Adapt-Model:true

   S->C:  MRCP/2.0 ... 314161 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
```

---
### **11.7.  END-SESSION**

END-SESSION 메서드는 진행 중인 검증 세션을 종료하고 검증 음성 프린트 리소스를 해제합니다. 세션은 다음 세 가지 방법 중 하나로 종료될 수 있습니다.

1. 중단 - 음성문 적응 또는 생성이 중단되어 음성문이 변경되지 않거나 생성되지 않을 수 있습니다.

1. 커밋 - 음성 지문 훈련 세션을 종료하면 새로운 음성 지문이 저장소에 커밋됩니다.

1. 적응 - 성공적인 검증을 통해 기존 음성 지문이 수정됩니다.

Abort-Model 헤더 필드는 END-SESSION에 포함되어 음성 지문에 대한 보류 중인 변경 사항을 중단할지 여부를 제어할 수 있습니다. 기본 동작은 지정된 음성 지문에 대한 보류 중인 변경 사항을 커밋\(중단하지 않음\)하는 것입니다.

END-SESSION 메서드는 START-SESSION 메서드를 먼저 실행하지 않고도 안전하게 여러 번 실행할 수 있습니다. START-SESSION 메서드를 개입하여 사용하지 않고 이 메서드를 추가로 실행해도 검증자 리소스에 영향을 미치지 않습니다다음 예에서는 훈련 세션 또는 검증 세션이 진행 중이라고 가정합니다.

```text
   C->S:  MRCP/2.0 ... END-SESSION 314174
          Channel-Identifier:32AECB23433801@speakverify
          Abort-Model:true

   S->C:  MRCP/2.0 ... 314174 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
```

---
### **11.8.  QUERY-VOICEPRINT**

QUERY-VOICEPRINT 방식은 특정 음성문에 대한 상태 정보를 얻는 데 사용되며 클라이언트가 음성문이나 저장소가 있는지, 훈련된 음성문이 포함되어 있는지 확인하는 데 사용할 수 있습니다.

QUERY-VOICEPRINT 요청에 대한 응답에는 Voiceprint-Exists 헤더 필드에 지정된 음성지문의 상태가 포함되어 있어 클라이언트가 확인을 위해 현재 음성지문을 사용할지, 새로운 음성지문을 학습할지 또는 다른 음성지문을 선택할지 결정할 수 있습니다.

음성 지문은 저장소 위치와 음성 지문 식별자를 제공하여 완전히 지정됩니다. 저장소 내의 특정 음성 지문 또는 ID는 저장소 내에서 고유한 문자열 식별자로 지정됩니다. Voiceprint-Identifier 헤더 필드는 주어진 저장소 내에서 이 고유한 음성 지문 식별자를 전달합니다.

다음 예에서는 검증 세션이 진행 중이고 음성 지문이 음성 지문 저장소에 있다고 가정합니다.

```text
   C->S:  MRCP/2.0 ... QUERY-VOICEPRINT 314168
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/voiceprints/
          Voiceprint-Identifier:johnsmith.voiceprint

   S->C:  MRCP/2.0 ... 314168 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/voiceprints/
          Voiceprint-Identifier:johnsmith.voiceprint
          Voiceprint-Exists:true
```

다음 예제에서는 Repository-URI 헤더 필드에 제공된 URI가 잘못된 URI라고 가정합니다.

```text
   C->S:  MRCP/2.0 ... QUERY-VOICEPRINT 314168
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/bad-uri/
          Voiceprint-Identifier:johnsmith.voiceprint

   S->C:  MRCP/2.0 ... 314168 405 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/bad-uri/
          Voiceprint-Identifier:johnsmith.voiceprint
          Completion-Cause:007 repository-uri-failure
```

---
### **11.9.  DELETE-VOICEPRINT**

DELETE-VOICEPRINT 메서드는 저장소에서 음성 지문을 제거합니다. 이 메서드는 Repository-URI 및 Voiceprint-Identifier 헤더 필드를 포함해야 합니다.

MRCPv2 서버는 MRCPv2 클라이언트가 인증 및 허가되지 않은 한 401 상태 코드와 함께 DELETE-VOICEPRINT 요청을 거부해야 합니다. MRCPv2에는 이에 대한 표준 메커니즘이 없습니다. 섹션 12.8을 참조하세요.

해당 음성 지문이 존재하지 않으면 DELETE-VOICEPRINT 메서드는 200 상태 코드를 반환해야 합니다.

다음 예제는 특정 음성 지문을 제거하기 위한 DELETE-VOICEPRINT 작업을 보여줍니다.

```text
   C->S:  MRCP/2.0 ... DELETE-VOICEPRINT 314168
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/bad-uri/
          Voiceprint-Identifier:johnsmith.voiceprint

   S->C:  MRCP/2.0 ... 314168 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
```

---
### **11.10.  VERIFY**

VERIFY 방법은 검증자 리소스가 음성 지문을 훈련/적응하거나 주장된 신원을 검증/식별하도록 요청하는 데 사용됩니다. 음성 지문이 새 것이거나 이전 DELETE-VOICEPRINT 방법으로 삭제된 경우 VERIFY 방법은 음성 지문을 훈련합니다. 음성 지문이 이미 있는 경우 VERIFY 명령으로 다시 훈련되지 않고 적응됩니다.

```text
   C->S:  MRCP/2.0 ... VERIFY 543260
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 543260 200 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speakverify
```

VERIFY 요청이 완료되면, MRCPv2 서버는 클라이언트에 VERIFICATION-COMPLETE 이벤트를 보내야 합니다.

---
### **11.11.  VERIFY-FROM-BUFFER**

VERIFY-FROM-BUFFER 메서드는 검증자 리소스가 음성 지문과 버퍼링된 오디오를 검증하도록 지시합니다. 검증자 리소스에 대해 한 번에 하나의 VERIFY 또는 VERIFY-FROM-BUFFER 메서드만 활성화될 수 있습니다.

버퍼링된 오디오는 이 메서드에서 소모되지 않으므로 클라이언트가 여러 음성 지문에 대한 검증을 시도하기 위해 VERIFY-FROM-BUFFER를 여러 번 호출할 수 있습니다.

VERIFY-FROM-BUFFER 메서드의 경우 서버는 선택적으로 VERIFICATION-COMPLETE 이벤트 전에 IN-PROGRESS 응답을 반환할 수 있습니다.

VERIFY-FROM-BUFFER 메서드가 호출되고 검증 버퍼가 이를 공유하는 다른 리소스에 의해 사용 중이면 서버는 IN-PROGRESS 응답을 반환하고 버퍼를 사용할 수 있을 때까지 기다려야 합니다. 검증 버퍼는 검증자 리소스가 소유하지만 동일한 세션의 다른 입력 리소스에서 쓰기 액세스와 공유됩니다. 따라서 이 버퍼를 공유하는 리소스에서 Ver-Buffer-Utterance 헤더 필드가 "true"로 설정된 RECORD 또는 RECOGNIZE와 같은 읽기 또는 쓰기 작업이 있는 경우 사용 중인 것으로 간주됩니다. RECORD 또는 RECOGNIZE 메서드가 실패 원인 코드와 함께 반환되는 경우 해당 버퍼를 처리하기 위해 기다리는 VERIFY-FROM-BUFFER 요청도 Completion-Cause 005\(버퍼 비어 있음\)로 실패해야 합니다.

다음 예는 일부 버퍼링 방법의 사용을 보여줍니다. 이 시나리오에서 클라이언트는 먼저 라이브 검증을 수행했지만 발언이 거부되었습니다. 그 사이에 발언도 오디오 버퍼에 저장됩니다. 그런 다음 다른 음성 지문을 사용하여 오디오 버퍼에 대한 검증을 수행하고 발언이 수락됩니다. 이 예에서는 Num-Min-Verification-Phrases와 Num-Max-Verification-Phrases가 모두 1이라고 가정합니다.

```text
   C->S:  MRCP/2.0 ... START-SESSION 314161
          Channel-Identifier:32AECB23433801@speakverify
          Verification-Mode:verify
          Adapt-Model:true
          Repository-URI:http://www.example.com/voiceprints
          Voiceprint-Identifier:johnsmith.voiceprint

   S->C:  MRCP/2.0 ... 314161 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify

   C->S:  MRCP/2.0 ... VERIFY 314162
          Channel-Identifier:32AECB23433801@speakverify
          Ver-buffer-utterance:true

   S->C:  MRCP/2.0 ... 314162 200 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... VERIFICATION-COMPLETE 314162 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
          Completion-Cause:000 success
          Content-Type:application/nlsml+xml
          Content-Length:...

          <?xml version="1.0"?>
          <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                  grammar="What-Grammar-URI">
            <verification-result>
              <voiceprint id="johnsmith">
                <incremental>
                  <utterance-length> 500 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> female </gender>
                  <decision> rejected </decision>
                  <verification-score> 0.05465 </verification-score>
                </incremental>
                <cumulative>
                  <utterance-length> 500 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> female </gender>
                  <decision> rejected </decision>
                  <verification-score> 0.05465 </verification-score>
                </cumulative>
              </voiceprint>
            </verification-result>
          </result>

      C->S:  MRCP/2.0 ... QUERY-VOICEPRINT 314163
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/voiceprints/
          Voiceprint-Identifier:johnsmith

   S->C:  MRCP/2.0 ... 314163 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
          Repository-URI:http://www.example.com/voiceprints/
          Voiceprint-Identifier:johnsmith.voiceprint
          Voiceprint-Exists:true

   C->S:  MRCP/2.0 ... START-SESSION 314164
          Channel-Identifier:32AECB23433801@speakverify
          Verification-Mode:verify
          Adapt-Model:true
          Repository-URI:http://www.example.com/voiceprints
          Voiceprint-Identifier:marysmith.voiceprint

   S->C:  MRCP/2.0 ... 314164 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify

   C->S:  MRCP/2.0 ... VERIFY-FROM-BUFFER 314165
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 314165 200 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... VERIFICATION-COMPLETE 314165 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
          Completion-Cause:000 success
          Content-Type:application/nlsml+xml
          Content-Length:...

          <?xml version="1.0"?>
          <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                  grammar="What-Grammar-URI">
            <verification-result>
              <voiceprint id="marysmith">
                <incremental>
                  <utterance-length> 1000 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> female </gender>
                  <decision> accepted </decision>
                  <verification-score> 0.98 </verification-score>
                </incremental>
                <cumulative>
                  <utterance-length> 1000 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> female </gender>
                  <decision> accepted </decision>
                  <verification-score> 0.98 </verification-score>
                </cumulative>
              </voiceprint>
            </verification-result>
          </result>

   C->S:  MRCP/2.0 ... END-SESSION 314166
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 314166 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify

                        VERIFY-FROM-BUFFER Example
```

---
### **11.12.  VERIFY-ROLLBACK**

VERIFY-ROLLBACK 방법은 버퍼링된 마지막 발화를 삭제하거나 마지막 라이브 발화를 삭제합니다\(모드가 "train" 또는 "verify"일 때\). 클라이언트는 사용자가 비음성 잡음, 횡설수설, 문법에 어긋나는 발화, 명령 등과 같은 바람직하지 않은 입력을 제공할 때 이 방법을 호출하고자 할 것입니다. 이 방법은 롤백 상태 스택을 제공하지 않는다는 점에 유의하십시오. 개입 인식 작업 없이 VERIFY-ROLLBACK을 연속으로 두 번 실행해도 두 번째 시도에는 영향을 미치지 않습니다.

```text
   C->S:  MRCP/2.0 ... VERIFY-ROLLBACK 314165
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 314165 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify

                          VERIFY-ROLLBACK Example
```

---
### **11.13.  STOP**

클라이언트에서 서버로의 STOP 메서드는 VERIFY 또는 VERIFY-FROM-BUFFER 요청이 활성화되어 있으면 해당 요청을 중지하도록 검증자 리소스에 지시합니다. 해당 요청이 활성화되어 있고 STOP 요청이 성공적으로 종료한 경우 응답 헤더 섹션에는 종료된 VERIFY 또는 VERIFY-FROM-BUFFER 요청의 요청 ID를 포함하는 Active-Request-Id-List 헤더 필드가 포함됩니다. 이 경우 종료된 요청에 대해 VERIFICATION-COMPLETE 이벤트가 전송되지 않습니다. 활성화된 검증 요청이 없는 경우 응답에는 Active-Request-Id-List 헤더 필드가 포함되어서는 안 됩니다. 어느 쪽이든 응답에는 200 "성공" 상태 코드가 포함되어야 합니다.

STOP 메서드는 Abort-Verification 헤더 필드를 포함할 수 있으며, 이 헤더 필드는 해당 지점까지의 검증 결과를 삭제하거나 반환해야 하는지 여부를 지정합니다. 이 헤더 필드가 없거나 값이 "true"인 경우 검증 결과는 삭제되고 STOP 응답에는 결과 데이터가 포함되지 않습니다. 헤더 필드가 있고 값이 "false"인 경우 STOP 응답에는 Completion-Cause 헤더 필드가 포함되어야 하며 본문에 Verification 결과 데이터가 포함되어야 합니다.

중단된 VERIFY 요청은 자동 롤백을 수행하므로 누적 점수에 영향을 미치지 않습니다. Abort-Verification 헤더 필드가 없거나 Abort-Verification 헤더 필드가 "false"로 설정된 상태에서 중단된 VERIFY 요청은 누적 점수에 영향을 미치며 클라이언트가 누적 점수에서 검증 결과를 고려하지 않으려는 경우 명시적으로 롤백해야 합니다.

다음 예에서는 음성 지문 신원이 이미 확립되었다고 가정합니다.

```text
   C->S:  MRCP/2.0 ... VERIFY 314177
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 314177 200 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speakverify

   C->S:  MRCP/2.0 ... STOP 314178
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 314178 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
          Active-Request-Id-List:314177

                         STOP Verification Example
```

---
### **11.14.  START-INPUT-TIMERS**

이 요청은 클라이언트에서 검증 리소스로 전송되어 무입력 타이머를 시작합니다. 이는 일반적으로 클라이언트가 사용자에게 전달된 모든 오디오 프롬프트가 완전히 재생되었음을 확인한 후에 실행됩니다.

```text
   C->S:  MRCP/2.0 ... START-INPUT-TIMERS 543260
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 543260 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
```

---
### **11.15.  VERIFICATION-COMPLETE**

VERIFICATION-COMPLETE 이벤트는 VERIFY 또는 VERIFY-FROM-BUFFER에 대한 호출을 따르며 클라이언트에 검증 결과를 전달하는 데 사용됩니다. 이벤트 메시지 본문에는 검증 결과만 포함됩니다.

```text
   S->C:  MRCP/2.0 ... VERIFICATION-COMPLETE 543259 COMPLETE
          Completion-Cause:000 success
          Content-Type:application/nlsml+xml
          Content-Length:...

          <?xml version="1.0"?>
          <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                  grammar="What-Grammar-URI">
            <verification-result>
              <voiceprint id="johnsmith">

                <incremental>
                  <utterance-length> 500 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> male </gender>
                  <decision> accepted </decision>
                  <verification-score> 0.85 </verification-score>
                </incremental>
                <cumulative>
                  <utterance-length> 1500 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> male </gender>
                  <decision> accepted </decision>
                  <verification-score> 0.75 </verification-score>
                </cumulative>
              </voiceprint>
            </verification-result>
          </result>
```

---
### **11.16.  START-OF-INPUT**

START-OF-INPUT 이벤트는 서버가 음성을 감지하면 서버에서 클라이언트로 반환됩니다. 이 이벤트는 인식기 및 검증기 리소스가 동일한 세션을 공유하는지 여부와 관계없이 음성이 감지되면 항상 검증기 리소스에서 반환됩니다.

```text
   S->C:  MRCP/2.0 ... START-OF-INPUT 543259 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speakverify
```

---
### **11.17.  CLEAR-BUFFER*CLEAR-BUFFER 메서드는 검증 버퍼를 지우는 데 사용할 수 있습니다. 이 버퍼는 나중에 VERIFY-FROM-BUFFER에서 사용할 수 있는 인식, 기록 또는 검증 작업 중에 음성을 버퍼링하는 데 사용됩니다. 앞서 언급했듯이 검증자 리소스와 연관된 버퍼는 인식기 및 레코더와 같은 다른 입력 리소스에서 공유합니다. 따라서 검증 버퍼가 사용 중이면 CLEAR-BUFFER 요청이 실패합니다. 이는 이 버퍼를 공유하는 입력 리소스 중 하나에 RECORD, RECOGNIZE 또는 VERIFY와 같은 활성 읽기 또는 쓰기 작업이 있고 Ver-Buffer-Utterance 헤더 필드가 "true"로 설정된 경우 발생할 수 있습니다.

```text
   C->S:  MRCP/2.0 ... CLEAR-BUFFER 543260
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 543260 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
```

---
### **11.18.  GET-INTERMEDIATE-RESULT**

클라이언트는 GET-INTERMEDIATE-RESULT 메서드를 사용하여 진행 중인 검증 요청의 중간 결과를 폴링할 수 있습니다. 이 메서드를 호출해도 리소스의 상태는 변경되지 않습니다. 검증자 리소스는 누적된 검증 결과를 수집하여 메서드 응답에 정보를 반환합니다. GET-INTERMEDIATE-RESULT REQUEST에 대한 응답의 메시지 본문에는 검증 결과만 포함됩니다. 요청이 아직 완료되지 않았으므로 메서드 응답에는 Completion-Cause 헤더 필드가 포함되어서는 안 됩니다. 리소스에 진행 중인 검증이 없는 경우 응답에는 402 실패 상태 코드가 있고 본문에 결과가 없습니다.

```text
   C->S:  MRCP/2.0 ... GET-INTERMEDIATE-RESULT 543260
          Channel-Identifier:32AECB23433801@speakverify

   S->C:  MRCP/2.0 ... 543260 200 COMPLETE
          Channel-Identifier:32AECB23433801@speakverify
          Content-Type:application/nlsml+xml
          Content-Length:...

          <?xml version="1.0"?>
          <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                  grammar="What-Grammar-URI">
            <verification-result>
              <voiceprint id="marysmith">
                <incremental>
                  <utterance-length> 50 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> female </gender>
                  <decision> undecided </decision>
                  <verification-score> 0.85 </verification-score>
                </incremental>
                <cumulative>
                  <utterance-length> 150 </utterance-length>
                  <device> cellular-phone </device>
                  <gender> female </gender>
                  <decision> undecided </decision>
                  <verification-score> 0.65 </verification-score>
                </cumulative>
              </voiceprint>
            </verification-result>
          </result>
```

---
## **12.  Security Considerations**

MRCPv2는 SPEECHSC 요구 사항 \[RFC4313\]에 문서화된 보안 관련 요구 사항을 준수하도록 설계되었습니다. MRCPv2의 구현자 및 사용자는 \[RFC4313\]의 보안 고려 사항 섹션을 읽어볼 것을 강력히 권장합니다. 해당 문서에는 음성을 생체 인증 기술로 활용하는 것과 관련된 여러 가지 중요한 보안 문제와 녹음된 음성을 저장하고, 방대한 음성 지문을 포함하고, 음성 입력을 인식기로 보내거나 합성기에서 음성 출력을 기반으로 민감한 정보를 송수신하는 시스템에 대한 위협에 대한 논의가 포함되어 있기 때문입니다. MRCPv2에서 사용하는 구체적인 보안 조치는 다음 하위 섹션에 요약되어 있습니다. 보안 관련 기계가 개별 프로토콜 작업에서 어떻게 호출되는지에 대해서는 이 사양의 해당 섹션을 참조하십시오.

---
### **12.1.  Rendezvous and Session Establishment**

MRCPv2 제어 세션은 SIP 대화의 컨텍스트 내에서 SDP가 설명하는 미디어 세션으로 설정됩니다. MRCPv2 클라이언트와 서버 간의 안전한 랑데부를 보장하기 위해 다음이 필요합니다.

1. MRCPv2 클라이언트 및 서버의 SIP 구현은 SIP 다이제스트 인증\[RFC3261\]을 지원해야 하며 이를 사용해야 합니다.

1. MRCPv2 클라이언트와 서버의 SIP 구현은 'sips' URI를 지원해야 하며 'sips' URI를 사용해야 합니다. 여기에는 클라이언트와 서버가 TLS\[RFC5246\] 연결을 설정해야 한다는 것도 포함됩니다.

1. 미디어 스트림 암호화 키잉이 SDP를 통해 수행되는 경우\(예: \[RFC4568\] 사용\), MRCPv2 클라이언트와 서버는 'sips' URI를 사용해야 합니다.

1. SIP에 TLS가 사용되는 경우 클라이언트는 \[RFC5922\]에 정의된 규칙 및 지침에 따라 연결하는 서버의 ID를 확인해야 합니다.

---
### **12.2.  Control Channel Protection**

민감한 데이터는 MRCPv2 제어 채널을 통해 전송됩니다. 여기에는 음성 인식 작업의 출력, 화자 검증 결과, 텍스트-음성 변환 입력, 개인 식별 문법 등이 포함됩니다. 이러한 이유로 MRCPv2 서버는 적절하게 인증되어야 하며 제어 채널은 데이터에 대한 기밀성과 무결성을 모두 사용할 수 있도록 허용해야 합니다. 제어 채널 보호를 보장하기 위해 MRCPv2 클라이언트와 서버는 TLS를 지원해야 하며 대안이 없는 한 기본적으로 이를 활용해야 합니다.

제어 채널 보호가 사용됩니다. TLS가 사용되는 경우 클라이언트는 \[RFC4572\]에 정의된 규칙 및 지침에 따라 연결하는 서버의 ID를 확인해야 합니다. 클라이언트와 서버 간에 여러 개의 TLS 보호 채널이 있는 경우 서버는 서버 또는 클라이언트의 TLS ID가 서버가 해당 요청을 수신한 채널과 다른 채널을 통해 클라이언트에 응답을 보내서는 안 됩니다. 원하는 경우 대체 제어 채널 보호를 사용할 수 있습니다\(예: 인터넷 프로토콜\(IPsec\) 보안 아키텍처\[RFC4301\]\).

---
### **12.3.  Media Session Protection**

민감한 데이터는 MRCPv2 서버에서 종료되는 미디어 세션에서도 전송됩니다\(미디어 채널의 다른 쪽 끝은 MRCPv2 클라이언트에 있을 수도 있고 그렇지 않을 수도 있음\). 이 데이터에는 사용자의 음성 발화와 텍스트-음성 작업의 출력이 포함됩니다. MRCPv2 서버는 오디오 미디어 세션을 보호하기 위한 보안 메커니즘을 지원해야 합니다. 오디오를 시작하거나 소비하는 MRCPv2 클라이언트도 마찬가지로 오디오를 보호하기 위한 보안 메커니즘을 지원해야 합니다. 그러한 메커니즘 중 하나는 SRTP\(Secure Real-time Transport Protocol\)\[RFC3711\]입니다.

---
### **12.4.  Indirect Content Access**

MCRPv2는 콘텐츠 간접화를 광범위하게 사용합니다. 콘텐츠는 MRCPv2 클라이언트나 서버 이외의 시스템에서 URI 주소 지정을 기반으로 페치되거나 저장될 수 있습니다. 저장된 콘텐츠가 모두 반드시 민감한 것은 아니지만\(예: XML 스키마\) 대부분은 일반적으로 보호가 필요하고 음성 녹음 및 음성 지문과 같은 일부 간접 콘텐츠는 매우 민감하므로 항상 보호해야 합니다. MRCPv2 클라이언트와 서버는 간접 콘텐츠 액세스를 위해 HTTPS를 구현해야 하며 모든 민감한 간접 콘텐츠에 대해 보안 액세스를 사용해야 합니다. 보안 FTP\(FTPS\) \[RFC4217\]와 같은 다른 보안 URI 체계도 사용할 수 있습니다. 인증에 필요한 경우 MRCPv2 클라이언트와 서버 간에 쿠키 정보를 전송하는 데 사용되는 헤더 필드에 대해서는 섹션 6.2.15를 참조하십시오.

서서버에서 제공하는 URI에 대한 액세스는 고려해야 할 위험을 초래합니다. RFC 6454\[RFC6454\]는 MRCPv2가 URI를 제한하지 않는 동일 출처 정책을 논의하고 집중하지만 RFC의 섹션 3에서 서버가 제공하는 URI를 맹목적으로 따르는 것의 함정에 대한 훌륭한 설명을 제공합니다. 서버는 또한 클라이언트가 서버를 긴 또는 문제가 있는 문서 페치에 묶어두도록 설계된 사이트에 URI를 제공할 수 있다는 사실을 알고 있어야 합니다. MRCPv2 서버와 액세스하는 서비스는 항상 이러한 서비스 거부 공격 가능성에 대비해야 합니다.

MRCPv2는 URI와 관련된 수명 및 액세스 제어에 대한 본질적인 가정을 하지 않습니다. 예를 들어, 인증이나 체계별 액세스 제어를 사용하지 않는 경우 URI의 누출은 콘텐츠의 누출과 동일합니다. 게다가 MRCPv2는 URI의 수명에 대한 구체적인 요구 사항을 하지 않습니다. 서버가 URI를 제공하고 클라이언트가 해당 URI에 액세스하는 데 오랜 시간이 걸리는 경우 서버는 중간 기간에 리소스를 제거했을 수 있습니다. MRCPv2는 HTTPS의 경우 404와 같은 URI 액세스 체계의 '리소스를 찾을 수 없음' 오류를 사용하여 이 사례를 처리합니다. 서버가 동적 리소스를 사용 가능한 상태로 유지해야 하는 기간은 애플리케이션과 컨텍스트에 따라 크게 달라집니다. 그러나 서버는 클라이언트가 리소스를 필요로 할 때 리소스를 사용할 수 있도록 합리적인 시간 동안 리소스를 사용 가능한 상태로 유지해야 합니다. 반대로 상태 소진 공격을 완화하기 위해 MRCPv2 서버는 리소스와 리소스 상태를 영구적으로 유지할 의무가 없습니다. 서버는 세션이 종료되면 MRCPv2 세션과 연관된 동적으로 생성된 리소스를 삭제해야 합니다.

리소스 누출을 방지하는 한 가지 방법은 서버가 추측하기 어려운 일회성 리소스 URI를 사용하는 것입니다. 이 경우 주어진 URI를 사용하여 기본 리소스에 대한 액세스는 단 하나뿐입니다. 이 접근 방식의 단점은 공격자가 클라이언트가 URI를 사용하기 전에 URI를 사용하면 클라이언트가 리소스를 거부한다는 것입니다. 다른 방법은 URLAUTH IMAP 확장\[RFC4467\]과 유사한 메커니즘을 채택하는 것입니다. 여기서 서버는 URI 사용에 대한 암호화 검사와 만료, 해지 등의 기능을 설정합니다. 이러한 메커니즘을 지정하는 것은 이 문서의 범위를 벗어납니다.

---
### **12.5.  Protection of Stored Media**

MRCPv2 애플리케이션은 종종 저장된 미디어를 사용해야 합니다. 음성 녹음은 저장\(예: 진단 및 시스템 튜닝용\)되고 페치\(발화를 여러 MRCPv2 리소스로 재생\)됩니다. 음성 지문은 화자 식별 및 검증 기능에 기본이 됩니다. 이 데이터는 매우 민감할 수 있으며 도난당하면 상당한 개인 정보 보호 및 사칭 위험이 발생할 수 있습니다. MRCPv2를 사용하는 시스템은 이러한 위험을 최소화하는 방식으로 배포해야 합니다. SPEECHSC 요구 사항 RFC \[RFC4313\]에는 이러한 위험과 이를 완화할 수 있는 방법에 대한 보다 광범위한 논의가 포함되어 있습니다.

---
### **12.6.  DTMF and Recognition Buffers**

DTMF 버퍼와 인식 버퍼는 서버의 기능을 초과할 만큼 커질 수 있으며, 서버는 리소스 소비를 우아하게 처리할 준비가 되어 있어야 합니다. 서버는 리소스가 부족할 위험이 있는 경우 적절한 인식이 완료되지 않은 상태로 응답할 수 있습니다.

---
### **12.7.  Client-Set Server Parameters**

MRCPv2에는 URI 리소스 페치와 같이 서버가 클라이언트를 대신하여 수행하는 몇 가지 작업이 있습니다. 이 동작을 제어하기 위해 MRCPv2에는 클라이언트가 구성할 수 있는 여러 서버 매개변수가 있습니다. 이러한 매개변수 중 하나인 Fetch-Timeout\(섹션 6.2.12\)을 사용하면 악의적인 클라이언트가 매우 큰 값을 설정한 다음 서버에 존재하지 않는 문서를 페치하도록 요청할 수 있습니다. 서버는 다른 클라이언트 설정 매개변수에 대해 긴 시간 초과 값이나 비정상적으로 큰 값을 허용하는 데 신중해야 합니다.

---
### **12.8.  DELETE-VOICEPRINT and Authorization**

이 사양은 DELETE-VOICEPRINT\(섹션 11.9\)를 요청할 때 인증 및 권한 부여를 위한 특정 메커니즘을 의무화하지 않으므로 MRCPv2 서버가 인증 및 권한 부여를 위해 이러한 검사를 수행하지 않을 위험이 있습니다. 실제로 음성 생체 인식 솔루션의 각 공급자는 이 사양 외부에서 자체 인증 및 권한 부여 메커니즘을 고집하므로 이는 큰 문제가 되지 않을 가능성이 큽니다. 미래에 음성 생체 인식 공급자가 이러한 메커니즘을 표준화하면 향후 버전의 MRCP에서 이를 의무화할 수 있습니다.

---
## **13.  IANA Considerations**
---
### **13.1.  New Registries**

이 섹션에서는 IANA가 생성하여 현재 유지 관리하는 MRCPv2의 네임 스페이스\(레지스트리\)를 설명합니다. 할당/등록 정책은 RFC 5226\[RFC5226\]에 설명되어 있습니다.

---
#### **13.1.1.  MRCPv2 Resource Types**

IANA는 "MRCPv2 리소스 유형"의 새로운 네임 스페이스를 만들었습니다. 이 네임 스페이스 내의 모든 유지 관리 및 콘텐츠 추가는 "표준 조치" 등록 정책에 따라야 합니다. 섹션 4.2에 정의된 레지스트리의 초기 콘텐츠는 다음과 같습니다.

```text
   Resource type  Resource description  Reference
   -------------  --------------------  ---------
   speechrecog    Speech Recognizer     [RFC6787]
   dtmfrecog      DTMF Recognizer       [RFC6787]
   speechsynth    Speech Synthesizer    [RFC6787]
   basicsynth     Basic Synthesizer     [RFC6787]
   speakverify    Speaker Verifier      [RFC6787]
   recorder       Speech Recorder       [RFC6787]
```

---
#### **13.1.2.  MRCPv2 Methods and Events**

IANA는 "MRCPv2 Methods and Events"라는 새로운 네임스페이스를 만들었습니다. 이 네임스페이스 내의 모든 유지관리 및 내용 추가는 "Standards Action" 등록 정책에 따라야 합니다. 섹션 15의 "method-name" 및 "event-name" BNF에 의해 정의되고 섹션 5.2 및 5.5에서 설명된 레지스트리의 초기 내용은 아래와 같습니다.

```te   Name                     Resource type  Method/Event  Reference
   ----                     -------------  ------------  ---------
   SET-PARAMS               Generic        Method        [RFC6787]
   GET-PARAMS               Generic        Method        [RFC6787]
   SPEAK                    Synthesizer    Method        [RFC6787]
   STOP                     Synthesizer    Method        [RFC6787]
   PAUSE                    Synthesizer    Method        [RFC6787]
   RESUME                   Synthesizer    Method        [RFC6787]
   BARGE-IN-OCCURRED        Synthesizer    Method        [RFC6787]
   CONTROL                  Synthesizer    Method        [RFC6787]
   DEFINE-LEXICON           Synthesizer    Method        [RFC6787]
   DEFINE-GRAMMAR           Recognizer     Method        [RFC6787]
   RECOGNIZE                Recognizer     Method        [RFC6787]
   INTERPRET                Recognizer     Method        [RFC6787]
   GET-RESULT               Recognizer     Method        [RFC6787]
   START-INPUT-TIMERS       Recognizer     Method        [RFC6787]
   STOP                     Recognizer     Method        [RFC6787]
   START-PHRASE-ENROLLMENT  Recognizer     Method        [RFC6787]
   ENROLLMENT-ROLLBACK      Recognizer     Method        [RFC6787]
   END-PHRASE-ENROLLMENT    Recognizer     Method        [RFC6787]
   MODIFY-PHRASE            Recognizer     Method        [RFC6787]
   DELETE-PHRASE            Recognizer     Method        [RFC6787]
   RECORD                   Recorder       Method        [RFC6787]
   STOP                     Recorder       Method        [RFC6787]
   START-INPUT-TIMERS       Recorder       Method        [RFC6787]
   START-SESSION            Verifier       Method        [RFC6787]
   END-SESSION              Verifier       Method        [RFC6787]
   QUERY-VOICEPRINT         Verifier       Method        [RFC6787]
   DELETE-VOICEPRINT        Verifier       Method        [RFC6787]
   VERIFY                   Verifier       Method        [RFC6787]
```

```text
   VERIFY-FROM-BUFFER       Verifier       Method        [RFC6787]
   VERIFY-ROLLBACK          Verifier       Method        [RFC6787]
   STOP                     Verifier       Method        [RFC6787]
   START-INPUT-TIMERS       Verifier       Method        [RFC6787]
   GET-INTERMEDIATE-RESULT  Verifier       Method        [RFC6787]
   SPEECH-MARKER            Synthesizer    Event         [RFC6787]
   SPEAK-COMPLETE           Synthesizer    Event         [RFC6787]
   START-OF-INPUT           Recognizer     Event         [RFC6787]
   RECOGNITION-COMPLETE     Recognizer     Event         [RFC6787]
   INTERPRETATION-COMPLETE  Recognizer     Event         [RFC6787]
   START-OF-INPUT           Recorder       Event         [RFC6787]
   RECORD-COMPLETE          Recorder       Event         [RFC6787]
   VERIFICATION-COMPLETE    Verifier       Event         [RFC6787]
   START-OF-INPUT           Verifier       Event         [RFC6787]
```

---
#### **13.1.3.  MRCPv2 Header Fields**

IANA는 "MRCPv2 헤더 필드"의 새로운 네임 스페이스를 만들었습니다. 이 네임 스페이스 내의 모든 유지 관리 및 내용 추가는 "표준 조치" 등록 정책에 따라야 합니다. 섹션 15의 "메시지 헤더" BNF에 의해 정의되고 섹션 5.1에서 설명된 레지스트리의 초기 내용은 아래와 같습니다. "Vendor-Specific-Parameters" 매개변수에 허용되는 값은 다른 정책에 따라 관리됩니다. 섹션 13.1.6을 참조하세요.

```text
   Name                               Resource type    Reference
   ----                               -------------    ---------
   Channel-Identifier                 Generic          [RFC6787]
   Accept                             Generic          [RFC2616]
   Active-Request-Id-List             Generic          [RFC6787]
   Proxy-Sync-Id                      Generic          [RFC6787]
   Accept-Charset                     Generic          [RFC2616]
   Content-Type                       Generic          [RFC6787]
   Content-ID                         Generic
                             [RFC2392], [RFC2046], and [RFC5322]
   Content-Base                       Generic          [RFC6787]
   Content-Encoding                   Generic          [RFC6787]
   Content-Location                   Generic          [RFC6787]
   Content-Length                     Generic          [RFC6787]
   Fetch-Timeout                      Generic          [RFC6787]
   Cache-Control                      Generic          [RFC6787]
   Logging-Tag                        Generic          [RFC6787]
   Set-Cookie                         Generic          [RFC6787]
   Vendor-Specific                    Generic          [RFC6787]
   Jump-Size                          Synthesizer      [RFC6787]
   Kill-On-Barge-In                   Synthesizer      [RFC6787]
   Speaker-Profile                    Synthesizer      [RFC6787]

   Completion-Cause                   Synthesizer      [RFC6787]
   Completion-Reason                  Synthesizer      [RFC6787]
   Voice-Parameter                    Synthesizer      [RFC6787]
   Prosody-Parameter                  Synthesizer      [RFC6787]
   Speech-Marker                      Synthesizer      [RFC6787]
   Speech-Language                    Synthesizer      [RFC6787]
   Fetch-Hint                         Synthesizer      [RFC6787]
   Audio-Fetch-Hint                   Synthesizer      [RFC6787]
   Failed-URI                         Synthesizer      [RFC6787]
   Failed-URI-Cause                   Synthesizer      [RFC6787]
   Speak-Restart                      Synthesizer      [RFC6787]
   Speak-Length                       Synthesizer      [RFC6787]
   Load-Lexicon                       Synthesizer      [RFC6787]
   Lexicon-Search-Order               Synthesizer      [RFC6787]
   Confidence-Threshold               Recognizer       [RFC6787]
   Sensitivity-Level                  Recognizer       [RFC6787]
   Speed-Vs-Accuracy                  Recognizer       [RFC6787]
   N-Best-List-Length                 Recognizer       [RFC6787]
   Input-Type                         Recognizer       [RFC6787]
   No-Input-Timeout                   Recognizer       [RFC6787]
   Recognition-Timeout                Recognizer       [RFC6787]
   Waveform-URI                       Recognizer       [RFC6787]
   Input-Waveform-URI                 Recognizer       [RFC6787]
   Completion-Cause                   Recognizer       [RFC6787]
   Completion-Reason                  Recognizer       [RFC6787]
   Recognizer-Context-Block           Recognizer       [RFC6787]
   Start-Input-Timers                 Recognizer       [RFC6787]
   Speech-Complete-Timeout            Recognizer       [RFC6787]
   Speech-Incomplete-Timeout          Recognizer       [RFC6787]
   Dtmf-Interdigit-Timeout            Recognizer       [RFC6787]
   Dtmf-Term-Timeout                  Recognizer       [RFC6787]
   Dtmf-Term-Char                     Recognizer       [RFC6787]
   Failed-URI                         Recognizer       [RFC6787]
   Failed-URI-Cause                   Recognizer       [RFC6787]
   Save-Waveform                      Recognizer       [RFC6787]
   Media-Type                         Recognizer       [RFC6787]
   New-Audio-Channel                  Recognizer       [RFC6787]
   Speech-Language                    Recognizer       [RFC6787]
   Ver-Buffer-Utterance               Recognizer       [RFC6787]
   Recognition-Mode                   Recognizer       [RFC6787]
   Cancel-If-Queue                    Recognizer       [RFC6787]
   Hotword-Max-Duration               Recognizer       [RFC6787]
   Hotword-Min-Duration               Recognizer       [RFC6787]
   Interpret-Text                     Recognizer       [RFC6787]
   Dtmf-Buffer-Time                   Recognizer       [RFC6787]
   Clear-Dtmf-Buffer                  Recognizer       [RFC6787]
   Early-No-Match                     Recognizer       [RFC6787]
   Num-Min-Consistent-Pronunciations  Recognizer       [RFC6787]

      Consistency-Threshold              Recognizer       [RFC6787]
   Clash-Threshold                    Recognizer       [RFC6787]
   Personal-Grammar-URI               Recognizer       [RFC6787]
   Enroll-Utterance                   Recognizer       [RFC6787]
   Phrase-ID                          Recognizer       [RFC6787]
   Phrase-NL                          Recognizer       [RFC6787]
   Weight                             Recognizer       [RFC6787]
   Save-Best-Waveform                 Recognizer       [RFC6787]
   New-Phrase-ID                      Recognizer       [RFC6787]
   Confusable-Phrases-URI             Recognizer       [RFC6787]
   Abort-Phrase-Enrollment            Recognizer       [RFC6787]
   Sensitivity-Level                  Recorder         [RFC6787]
   No-Input-Timeout                   Recorder         [RFC6787]
   Completion-Cause                   Recorder         [RFC6787]
   Completion-Reason                  Recorder         [RFC6787]
   Failed-URI                         Recorder         [RFC6787]
   Failed-URI-Cause                   Recorder         [RFC6787]
   Record-URI                         Recorder         [RFC6787]
   Media-Type                         Recorder         [RFC6787]
   Max-Time                           Recorder         [RFC6787]
   Trim-Length                        Recorder         [RFC6787]
   Final-Silence                      Recorder         [RFC6787]
   Capture-On-Speech                  Recorder         [RFC6787]
   Ver-Buffer-Utterance               Recorder         [RFC6787]
   Start-Input-Timers                 Recorder         [RFC6787]
   New-Audio-Channel                  Recorder         [RFC6787]
   Repository-URI                     Verifier         [RFC6787]
   Voiceprint-Identifier              Verifier         [RFC6787]
   Verification-Mode                  Verifier         [RFC6787]
   Adapt-Model                        Verifier         [RFC6787]
   Abort-Model                        Verifier         [RFC6787]
   Min-Verification-Score             Verifier         [RFC6787]
   Num-Min-Verification-Phrases       Verifier         [RFC6787]
   Num-Max-Verification-Phrases       Verifier         [RFC6787]
   No-Input-Timeout                   Verifier         [RFC6787]
   Save-Waveform                      Verifier         [RFC6787]
   Media-Type                         Verifier         [RFC6787]
   Waveform-URI                       Verifier         [RFC6787]
   Voiceprint-Exists                  Verifier         [RFC6787]
   Ver-Buffer-Utterance               Verifier         [RFC6787]
   Input-Waveform-URI                 Verifier         [RFC6787]
   Completion-Cause                   Verifier         [RFC6787]
   Completion-Reason                  Verifier         [RFC6787]
   Speech-Complete-Timeout            Verifier         [RFC6787]
   New-Audio-Channel                  Verifier         [RFC6787]
   Abort-Verification                 Verifier         [RFC6787]
   Start-Input-Timers                 Verifier         [RFC6787]
   Input-Type                         Verifier         [RFC6787]
```

---
#### **13.1.4.  MRCPv2 Status Codes**

IANA는 섹션 5.4에 정의된 초기 값을 사용하여 "MRCPv2 상태 코드"의 새 이름 공간을 만들었습니다. 이 이름 공간 내의 모든 유지 관리 및 내용 추가는 "전문가 검토가 필요한 사양" 등록 정책에 따라야 합니다.

---
#### **13.1.5.  Grammar Reference List Parameters**

IANA는 "문법 참조 목록 매개변수"라는 새로운 네임스페이스를 만들었습니다. 이 네임스페이스 내의 모든 유지 관리 및 내용 추가는 "전문가 검토에 필요한 사양" 등록 정책에 따라야 합니다. 아래에 표시된 대로 초기 매개변수는 하나뿐입니다.

```text
   Name                       Reference
   ----                       -------------
   weight                     [RFC6787]
```

---
#### **13.1.6.  MRCPv2 Vendor-Specific Parameters**

IANA는 "MRCPv2 공급업체별 매개변수"의 새로운 이름 공간을 만들었습니다. 이 이름 공간 내의 모든 유지 관리 및 내용 추가는 다음과 같이 "계층적 할당" 등록 정책에 따라야 합니다. 각 이름\("vendor-av-pair-name" ABNF 프로덕션에 해당\)은 RFC 1035 \[RFC1035\]의 섹션 2.3.1에 설명된 대로 인터넷 도메인 이름의 구문 요구 사항을 충족해야 하며\(연속된 RFC에서 업데이트되거나 폐기됨\) 한 가지 예외로 도메인 이름의 순서가 반전됩니다. 예를 들어, example.com의 공급업체별 매개변수 "foo"는 "com.example.foo" 형식이 됩니다. 첫 번째 또는 최상위 도메인은 IANA에서 정의한 최상위 인터넷 도메인 세트로 정확히 제한되며 해당 세트가 변경될 때에만 IANA에서 업데이트됩니다. 매개변수 이름 내의 2차 및 모든 하위 도메인은 "선착순" 정책에 따라 할당되어야 합니다. 할당 요청은 조직, 기관, 법인 등에 대한 기존 인터넷 도메인 이름 할당을 준수하는 것이 좋습니다.

레지스트리에는 공급업체 등록 매개변수 목록이 포함되어 있으며, 정의된 각 매개변수는 담당자와 연관되어 있으며 매개변수 정의에 대한 선택적 참조\(바람직하게는 RFC\)가 포함됩니다. 레지스트리는 처음에는 비어 있습니다.

---
### **13.2.  NLSML-Related Registrations**
---
#### **13.2.1.  'application/nlsml+xml' Media Type Registration**

IANA는 RFC 4288 \[RFC4288\]에 정의된 프로세스에 따라 다음 미디어 유형을 등록했습니다.

```text
   To:  ietf-types@iana.org
```

제목 : 미디어 유형 application/nlsml+xml 등록

```text
   MIME media type name:  application

   MIME subtype name:  nlsml+xml

   Required parameters:  none

   Optional parameters:
```

- charset: RFC 3023 \[RFC3023\]에 설명된 모든 고려 사항은 application/nlsml+xml 미디어 유형에도 적용됩니다.

인코딩 고려 사항: RFC 3023에 설명된 모든 고려 사항은 'application/nlsml+xml' 미디어 유형에도 적용됩니다.

보안 고려 사항: HTML과 마찬가지로 NLSML 문서에는 다른 데이터 저장소\(문법, 검증 리소스 등\)에 대한 링크가 포함되어 있습니다. 그러나 HTML과 달리 데이터 저장소는 렌더링할 미디어로 처리되지 않습니다. 그럼에도 불구하고 링크된 파일 자체에 보안 고려 사항이 있을 수 있으며, 이는 개별 등록된 유형의 보안 고려 사항입니다. 또한 이 미디어 유형에는 RFC 3023에 설명된 모든 보안 고려 사항이 있습니다.

상호 운용성 고려 사항: NLSML 문서 자체는 완전한 XML 문서이지만, NLSML 문서 수신자는 문서에 링크된 리소스에 액세스하여 내용을 보다 완전하게 해석하고자 할 수 있습니다. NLSML 프로세서가 이러한 링크된 리소스에 액세스하거나 처리할 수 없으면 데이터의 최종 소비자가 다른 동작을 할 수 있습니다.

```text
   Published specification:  RFC 6787
```

이 미디어 유형을 사용하는 애플리케이션: MRCPv2 클라이언트 및 서버

```text
   Additional information:  none
```

매직 넘버: NLSML 파일에는 항상 존재하는 단일 초기 옥텟 시퀀스가 없습니다.

추가 정보를 문의할 수 있는 사람 및 이메일 주소: - Sarvi Shanmugham, sarvi@cisco.com

의도된 사용: 이 미디어 유형은 MRCPv2와 함께만 사용하도록 예상됩니다.

---
### **13.3.  NLSML XML Schema Registration**

IANA는 다음 XML 스키마를 등록하고 현재 유지 관리하고 있습니다. 제공되는 정보는 RFC 3688 \[RFC3688\]의 템플릿을 따릅니다.

```text
   XML element type:  schema

   URI:  urn:ietf:params:xml:schema:nlsml

   Registrant Contact:  IESG

   XML:  See Section 16.1.
```

---
### **13.4.  MRCPv2 XML Namespace Registration**

IANA는 다음 XML 이름 공간을 등록하고 현재 유지 관리하고 있습니다. 제공되는 정보는 RFC 3688 \[RFC3688\]의 템플릿을 따릅니다.

```te   XML element type:  ns

   URI:  urn:ietf:params:xml:ns:mrcpv2

   Registrant Contact:  IESG

   XML:  RFC 6787
```

---
### **13.5.  Text Media Type Registrations**

IANA는 RFC 4288 \[RFC4288\]에 정의된 프로세스에 따라 다음 텍스트 미디어 유형을 등록했습니다.

---
#### **13.5.1.  text/grammar-ref-list**

```text
   To:  ietf-types@iana.org
```

제목: 미디어 유형 text/grammar-ref-list 등록

```text
   MIME media type name:  text

   MIME subtype name:  text/grammar-ref-list

   Required parameters:  none

   Optional parameters:  none
```

인코딩 고려사항: 전송 프로토콜에 따라 매우 긴 회선을 처리하기 위해 전송 인코딩이 필요할 수 있습니다.

보안 고려 사항: 이 미디어 유형에는 외부 리소스에 대한 참조를 나타낼 수 있는 URI가 포함되어 있습니다. 이러한 리소스는 음성 인식 문법으로 간주되므로 미디어 유형 'application/srgs' 및 'application/srgs+xml'과 유사한 고려 사항이 적용됩니다.

상호 운용성 고려 사항: '\>'는 RFC 3986 \[RFC3986\]에 따라 URI로 퍼센트 인코딩되어야 합니다.

게시된 사양: MRCP 프로토콜의 RECOGNIZE 방법은 입력을 문법 집합과 일치시키는 인식 작업을 수행합니다. 두 개 이상의 문법과 일치시킬 때 개별 문법에 대해 다른 가중치를 사용해야 하는 경우가 있습니다. 이러한 가중치는 문법 리소스 자체의 속성이 아니지만 RECOGNIZE 방법으로 시작된 특정 인식 작업에 대해 해당 문법에 대한 참조를 한정합니다. 제안된 'text/grammar-ref-list' 미디어 유형의 형식은 다음과 같습니다.

```text
      body       = *reference
      reference  = "<" uri ">" [parameters] CRLF
      parameters = ";" parameter *(";" parameter)
      parameter  = attribute "=" value
```

- 이 사양은 현재 '가중치' 매개변수만 정의하지만, 이 사양을 통해 확립된 "문법 참조 목록 매개변수" IANA 레지스트리를 통해 새로운 매개변수를 추가할 수 있습니다. 예:

```text
            <http://example.com/grammars/field1.gram>
            <http://example.com/grammars/field2.gram>;weight="0.85"
            <session:field3@form-level.store>;weight="0.9"
            <http://example.com/grammars/universals.gram>;weight="0.75"
```

이 미디어 유형을 사용하는 애플리케이션: MRCPv2 클라이언트 및 서버

```text
   Additional information:  none

   Magic number(s):  none
```

추가 정보를 문의할 수 있는 사람 및 이메일 주소: - Sarvi Shanmugham, sarvi@cisco.com

의도된 사용: 이 미디어 유형은 MRCPv2와 함께만 사용하도록 예상됩니다.

---
### **13.6.  'session' URI Scheme Registration**

IANA는 다음의 새로운 URI 체계를 등록했습니다. 아래 정보는 RFC 4395 \[RFC4395\]에 제공된 템플릿을 따릅니다.

```text
   URI scheme name:  session

   Status:  Permanent
```

URI 체계 구문: 이 체계의 구문은 RFC 2392 \[RFC2392\] 섹션 2의 "cid" 체계에 대해 정의된 구문과 동일합니다.

URI 체계 의미론: URI는 이전에 네트워크 컴퓨팅 리소스에 제공된 데이터 리소스를 식별하기 위한 것입니다. 이 체계의 목적은 리소스를 저장하는 엔터티와의 세션 수명 동안 특정 리소스에 대한 액세스를 허용하는 것입니다. 리소스의 미디어 유형은 다양할 수 있습니다. 미디어 유형의 통신을 위한 명시적 메커니즘은 없습니다. 이 체계는 현재 기존 구현에서 내부적으로 널리 사용되고 있으며, 등록은 이 체계가 다른 곳에서 사용되는 드문\(그리고 불행한\) 경우에 정보를 제공하기 위한 것입니다. 이 체계는 개방형 인터넷 프로토콜에 사용해서는 안 됩니다.

인코딩 고려 사항: RFC 3986 \[RFC3986\]에 설명되지 않은 '세션' URI에 대한 다른 인코딩 고려 사항은 없습니다.

이 URI 체계 이름을 사용하는 애플리케이션/프로토콜: 이 체계 이름은 MRCPv2 클라이언트와 서버에서 사용됩니다.

상호 운용성 고려 사항: MCRPv2 세션이 종료된 후에는 어떤 리소스에도 액세스할 수 없으므로 이 계획의 이름이 붙었습니다. 구현 중인 전체 음성 애플리케이션에 대해 하나의 MRCPv2 세션만 설정하는 클라이언트의 경우 이것으로 충분하지만 성능이나 확장성 이유로 MRCP 세션을 만들고, 종료하고, 다시 만드는 클라이언트는 이전 세션에서 설정한 리소스에 대한 액세스를 잃게 됩니다.

보안 고려 사항: RFC 3986 \[RFC3986\]에 설명된 URI에 대한 일반적인 보안 고려 사항이 이 체계에도 적용됩니다. 여기에 정의된 URI는 식별 메커니즘만 제공합니다. 클라이언트와 서버 간의 통신 채널이 안전하다는 점, 서버가 연결된 리소스에 올바르게 액세스한다는 점을 감안할 때

- URI를 사용하고, 서버가 각 URI에 대해 세션 전용 수명과 액세스를 보장하는 경우 유일한 추가적인 보안 문제는 URI가 참조하는 미디어 유형과 관련된 문제입니다.

```text
   Contact:  Sarvi Shanmugham, sarvi@cisco.com

   Author/Change controller:  IESG, iesg@ietf.org
```

참고문헌: 본 사양, 특히 섹션 6.2.7, 8.5.2, 9.5.1 및 9.9.

---
### **13.7.  SDP Parameter Registrations**

IANA는 다음 SDP 매개변수 값을 등록했습니다. 각 정보는 RFC 4566 \[RFC4566\] 부록 B에 제공된 템플릿을 따릅니다.

---
#### **13.7.1.  Sub-Registry "proto"**

"proto" 매개변수의 "TCP/MRCPv2" 값

연락처 이름, 이메일 주소 및 전화번호: Sarvi Shanmugham, sarvi@cisco.com, +1.408.902.3875

등록되는 이름\(SDP에 나타날 이름\): TCP/MRCPv2

영어 긴 형식 이름: MCRPv2 over TCP

이름의 유형: proto

이름 설명: 이 이름은 TCP를 통해 전달되는 MCRPv2 프로토콜을 나타냅니다.

이름 사양 참조: RFC 6787

"proto" 매개변수의 "TCP/TLS/MRCPv2" 값

연락처 이름, 이메일 주소 및 전화번호: Sarvi Shanmugham, sarvi@cisco.com, +1.408.902.3875

등록되는 이름\(SDP에 나타나는 이름\): TCP/TLS/MRCPv2

영어 긴 형식 이름: TLS를 통한 MCRPv2, TCP를 통한 MCRPv2

이름의 유형: proto

이름 설명: 이 이름은 TCP를 통한 TLS에서 전달되는 MCRPv2 프로토콜을 나타냅니다.

이름 사양 참조: RFC 6787

---
#### **13.7.2.  Sub-Registry "att-field (media-level)"**

"att-field" 매개변수의 "resource" 값

연락처 이름, 이메일 주소 및 전화번호: Sarvi Shanmugham, sarvi@cisco.com, +1.408.902.3875

속성 이름\(SDP에 표시되는 이름\): resource

영어로 된 긴 형식 속성 이름: MRCPv2 리소스 유형

속성 유형: 미디어 수준

charset 속성에 따라?아니요

속성 설명: 설명과 예는 RFC 6787의 섹션 4.2를 참조하세요.

적절한 속성 값의 사양: RFC 6787의 섹션 13.1.1을 참조하세요.

"att-field" 매개변수의 "channel" 값

연락처 이름, 이메일 주소 및 전화번호: Sarvi Shanmugham, sarvi@cisco.com, +1.408.902.3875

속성 이름\(SDP에 표시되는 이름\): channel

영어로 된 긴 형식 속성 이름: MRCPv2 리소스 채널 식별자

속성 유형: 미디어 수준

charset 속성에 따라?아니요

속성 설명: 설명과 예는 RFC 6787의 섹션 4.2를 참조하세요.

적절한 속성 값의 사양: 섹션 4.2 및 RFC 6787의 "channel-id" ABNF 생성 규칙을 참조하세요.

"att-field" 매개변수의 "cmid" 값

연락처 이름, 이메일 주소 및 전화번호: Sarvi Shanmugham, sarvi@cisco.com, +1.408.902.3875

속성 이름\(SDP에 표시되는 이름\): cmid

영어로 된 긴 형식 속성 이름: MRCPv2 리소스 채널 미디어 식별자

속성 유형: 미디어 수준

charset 속성에 따라?아니요

속성 설명: 설명과 예는 RFC 6787의 섹션 4.4를 참조하세요.

적절한 속성 값의 지정: 섹션 4.4 및 RFC 6787의 "cmid-attribute" ABNF 생성 규칙을 참조하세요.

---
## **14.14.  Examples**
---
### **14.1.  Message Flow**

다음은 클라이언트와 서버 간의 음성 합성 및 인식의 일반적인 MRCPv2 세션의 예입니다. 이러한 예의 SDP "s=" 속성에는 예를 이해하는 데 도움이 되는 텍스트 설명 값이 있지만 RFC 3264 \[RFC3264\]에서는 실제로 와이어에 넣은 메시지에 공백이나 대시를 사용할 것을 권장한다는 점을 명심하세요.

아래 그림은 MRCPv2 서버에 세션을 여는 것을 보여줍니다. 이 교환은 리소스를 할당하거나 미디어를 설정하지 않습니다. 단순히 MRCPv2 서버와 SIP 세션을 설정합니다.

```text
   C->S:
          INVITE sip:mresources@example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg1
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323123 INVITE
          Contact:<sip:sarvi@client.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=sarvi 2614933546 2614933546 IN IP4 192.0.2.12
          s=Set up MRCPv2 control and audio
          i=Initial contact
          c=IN IP4 192.0.2.12

   S->C:
          SIP/2.0 200 OK
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg1;received=192.0.32.10
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323123 INVITE
          Contact:<sip:mresources@server.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=- 3000000001 3000000001 IN IP4 192.0.2.11
          s=Set up MRCPv2 control and audio
          i=Initial contact
          c=IN IP4 192.0.2.11

   C->S:
          ACK sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg2
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:Sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323123 ACK
          Content-Length:0
```

클라이언트는 서버에 음성 합성을 위한 신디사이저 리소스 제어 채널을 생성하도록 요청합니다. 이렇게 하면 생성된 음성을 보내는 미디어 스트림도 추가됩니다. 이 예에서 클라이언트는 클라이언트와 서버 간에 새로운 MRCPv2 TCP 스트림을 요청합니다. 다음 요청에서 클라이언트는 기존 연결을 사용하도록 요청합니다.

```text
   C->S:
          INVITE sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg3
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323124 INVITE
          Contact:<sip:sarvi@client.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=sarvi 2614933546 2614933547 IN IP4 192.0.2.12
          s=Set up MRCPv2 control and audio
          i=Add TCP channel, synthesizer and one-way audio
          c=IN IP4 192.0.2.12
          t=0 0
          m=application 9  TCP/MRCPv2 1
          a=setup:active
          a=connection:new
          a=resource:speechsynth
          a=cmid:1
          m=audio 49170 RTP/AVP 0 96
          a=rtpmap:0 pcmu/8000
          a=rtpmap:96 telephone-event/8000
          a=fmtp:96 0-15
          a=recvonly
          a=mid:1

   S->C:
          SIP/2.0 200 OK
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg3;received=192.0.32.10
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323124 INVITE
          Contact:<sip:mresources@server.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=- 3000000001 3000000002 IN IP4 192.0.2.11
          s=Set up MRCPv2 control and audio
          i=Add TCP channel, synthesizer and one-way audio
          c=IN IP4 192.0.2.11
          t=0 0
          m=application 32416  TCP/MRCPv2 1
          a=setup:passive
          a=connection:new
          a=channel:32AECB23433801@speechsynth
          a=cmid:1
          m=audio 48260 RTP/AVP 0
          a=rtpmap:0 pcmu/8000
          a=sendonly
          a=mid:1

   C->S:
          ACK sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg4
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:Sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323124 ACK
          Content-Length:0
```

이 교환은 인식기에 대한 추가 리소스 제어 채널을 할당합니다. 인식기는 인식을 위해 오디오 스트림을 수신해야 하므로 이 상호 작용은 오디오 스트림을 sendrecv로 업데이트하여 양방향 오디오 스트림을 만듭니다.

```text
   C->S:
          INVITE sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg5
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323125 INVITE
          Contact:<sip:sarvi@client.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=sarvi 2614933546 2614933548 IN IP4 192.0.2.12
          s=Set up MRCPv2 control and audio
          i=Add recognizer and duplex the audio
          c=IN IP4 192.0.2.12
          t=0 0
          m=application 9  TCP/MRCPv2 1
          a=setup:active
          a=connection:existing
          a=resource:speechsynth
          a=cmid:1
          m=audio 49170 RTP/AVP 0 96
          a=rtpmap:0 pcmu/8000
          a=rtpmap:96 telephone-event/8000
          a=fmtp:96 0-15
          a=recvonly
          a=mid:1
          m=application 9  TCP/MRCPv2 1
          a=setup:active

          a=connection:existing
          a=resource:speechrecog
          a=cmid:2
          m=audio 49180 RTP/AVP 0 96
          a=rtpmap:0 pcmu/8000
          a=rtpmap:96 telephone-event/8000
          a=fmtp:96 0-15
          a=sendonly
          a=mid:2

   S->C:
          SIP/2.0 200 OK
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg5;received=192.0.32.10
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323125 INVITE
          Contact:<sip:mresources@server.example.com>
          Content-Type:application/sdp
          Content-Length:...

          v=0
          o=- 3000000001 3000000003 IN IP4 192.0.2.11
          s=Set up MRCPv2 control and audio
          i=Add recognizer and duplex the audio
          c=IN IP4 192.0.2.11
          t=0 0
          m=application 32416  TCP/MRCPv2 1
          a=channel:32AECB23433801@speechsynth
          a=cmid:1
          m=audio 48260 RTP/AVP 0
          a=rtpmap:0 pcmu/8000
          a=sendonly
          a=mid:1
          m=application 32416  TCP/MRCPv2 1
          a=channel:32AECB23433801@speechrecog
          a=cmid:2
          m=audio 48260 RTP/AVP 0
          a=rtpmap:0 pcmu/8000
          a=rtpmap:96 telephone-event/8000
          a=fmtp:96 0-15
          a=recvonly
          a=mid:   C->S:
          ACK sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg6
          Max-Forwards:6
          To:MediaServer <sip:mresources@example.com>;tag=62784
          From:Sarvi <sip:sarvi@example.com>;tag=1928301774
          Call-ID:a84b4c76e66710
          CSeq:323125 ACK
          Content-Length:0
```

MRCPv2 SPEAK 요청은 음성을 시작합니다.

```text
   C->S:
          MRCP/2.0 ... SPEAK 543257
          Channel-Identifier:32AECB23433801@speechsynth
          Kill-On-Barge-In:false
          Voice-gender:neutral
          Voice-age:25
          Prosody-volume:medium
          Content-Type:application/ssml+xml
          Content-Length:...

          <?xml version="1.0"?>
          <speak version="1.0"
                 xmlns="http://www.w3.org/2001/10/synthesis"
                 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                 xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                 http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                 xml:lang="en-US">
            <p>
              <s>You have 4 new messages.</s>
              <s>The first is from Stephanie Williams
                <mark name="Stephanie"/>
                and arrived at <break/>
                <say-as interpret-as="vxml:time">0345p</say-as>.</s>
              <s>The subject is <prosody
                 rate="-20%">ski trip</prosody></s>
            </p>
          </speak>

   S->C:
          MRCP/2.0 ... 543257 200 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speechsynth
          Speech-Marker:timestamp=857205015059
```

합성기는 말할 메시지의 특수 마커를 맞추고 고객에게 이벤트를 충실하게 알립니다.

```text
   S->C:  MRCP/2.0 ... SPEECH-MARKER 543257 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speechsynth
          Speech-Marker:timestamp=857206027059;Stephanie
```

신시사이저는 SPEAK 요청으로 마무리됩니다.

```text
   S->C:  MRCP/2.0 ... SPEAK-COMPLETE 543257 COMPLETE
          Channel-Identifier:32AECB23433801@speechsynth
          Speech-Marker:timestamp=857207685213;Stephanie
```

인식자에게 고객 선택을 청취하라는 요청이 전송됩니다.

```text
   C->S:  MRCP/2.0 ... RECOGNIZE 543258
          Channel-Identifier:32AECB23433801@speechrecog
          Content-Type:application/srgs+xml
          Content-Length:...

          <?xml version="1.0"?>
          <!-- the default grammar language is US English -->
          <grammar xmlns="http://www.w3.org/2001/06/grammar"
                   xml:lang="en-US" version="1.0" root="request">
          <!-- single language attachment to a rule expansion -->
            <rule id="request">
              Can I speak to
              <one-of xml:lang="fr-CA">
                <item>Michel Tremblay</item>
                <item>Andre Roy</item>
              </one-of>
            </rule>
          </grammar>

   S->C:  MRCP/2.0 ... 543258 200 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speechrecog
```

클라이언트는 다음 MRCPv2 SPEAK 메서드를 실행합니다.

```text
   C->S:  MRCP/2.0 ... SPEAK 543259
          Channel-Identifier:32AECB23433801@speechsynth
          Kill-On-Barge-In:true
          Content-Type:application/ssml+xml
          Content-Length:...

          <?xml version="1.0"?>
          <speak version="1.0"
                 xmlns="http://www.w3.org/2001/10/synthesis"
                 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                 xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
                 http://www.w3.org/TR/speech-synthesis/synthesis.xsd"
                 xml:lang="en-US">
            <p>
              <s>Welcome to ABC corporation.</s>
              <s>Who would you like to talk to?</s>
            </p>
          </speak>

   S->C:  MRCP/2.0 ... 543259 200 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speechsynth
          Speech-Marker:timestamp=857207696314
```

이 진행 중인 예제의 다음 섹션에서는 kill-on-barge-in 지원이 작동하는 방식을 보여줍니다. 이 마지막 SPEAK 요청에서 Kill-On-Barge-In이 "true"로 설정되어 있기 때문에 인식기\(서버\)가 SPEAK가 활성화된 동안 START-OF-INPUT 이벤트를 생성했을 때 클라이언트는 즉시 BARGE-IN-OCCURRED 메서드를 합성기 리소스에 발행했습니다. 그런 다음 음성 합성기는 재생을 종료하고 클라이언트에 알렸습니다. 완료 원인 코드는 이것이 정상적인 완료가 아니라 kill-on-barge-in 중단이라는 표시를 제공했습니다.

인식 및 합성기 리소스가 동일한 서버의 동일한 세션에 있으므로 더 빠른 응답을 얻기 위해 서버는 예상된 BARGE-IN-OCCURRED 이벤트를 수신하기 전에 합성기에 직접 입력 시작 조건을 내부적으로 전달했을 수 있습니다. 그러나 그러한 통신은 MRCPv2의 범위를 벗어납니다.

```text
   S->C:  MRCP/2.0 ... START-OF-INPUT 543258 IN-PROGRESS
          Channel-Identifier:32AECB23433801@speechrecog
          Proxy-Sync-Id:987654321

   C->S:  MRCP/2.0 ... BARGE-IN-OCCURRED 543259
          Channel-Identifier:32AECB23433801@speechsynth
          Proxy-Sync-Id:987654321

   S->C:  MRCP/2.0 ... 543259 200 COMPLETE
          Channel-Identifier:32AECB23433801@speechsynth
          Active-Request-Id-List:543258
          Speech-Marker:timestamp=857206096314

   S->C:  MRCP/2.0 ... SPEAK-COMPLETE 543259 COMPLETE
          Channel-Identifier:32AECB23433801@speechsynth
          Completion-Cause:001 barge-in
          Speech-Marker:timestamp=857207685213
```

인식기 리소스는 말한 스트림을 문법과 매치하고 결과를 생성했습니다. 인식 결과는 RECOGNITION-COMPLETE 이벤트의 일부로 서버에서 반환됩니다.

```text
   S->C:  MRCP/2.0 ... RECOGNITION-COMPLETE 543258 COMPLETE
          Channel-Identifier:32AECB23433801@speechrecog
          Completion-Cause:000 success
          Waveform-URI:<http://web.media.com/session123/audio.wav>;
                       size=423523;duration=25432
          Content-Type:application/nlsml+xml
          Content-Length:...

          <?xml version="1.0"?>
          <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
                  xmlns:ex="http://www.example.com/example"
                  grammar="session:request1@form-level.store">
              <interpretation>
                  <instance name="Person">
                      <ex:Person>
                          <ex:Name> Andre Roy </ex:Name>
                      </ex:Person>
                  </instance>
                  <input>   may I speak to Andre Roy </input>
              </interpretation>
          </result>
```

클라이언트가 이제 모든 리소스를 포함하여 세션을 마쳤으므로 SIP BYE 요청을 발행하여 SIP 세션을 닫았습니다. 이로 인해 세션에서 할당된 모든 제어 채널과 리소스가 할당 해제되었습니다.

```text
   C->S:  BYE sip:mresources@server.example.com SIP/2.0
          Via:SIP/2.0/TCP client.atlanta.example.com:5060;
           branch=z9hG4bK74bg7
          Max-Forwards:6
          From:Sarvi <sip:sarvi@example.com>;tag=1928301774
          To:MediaServer <sip:mresources@example.com>;tag=62784
          Call-ID:a84b4c76e66710
          CSeq:323126 BYE
          Content-Length:0
```

---
### **14.2.  Recognition Result Examples**
---
#### **14.2.1.  Simple ASR Ambiguity**

시스템: 어느 도시로 여행할 건가요? 사용자: 피츠버그로 가고 싶어요.

```text
      <?xml version="1.0"?>
   <result xmlns="urn:ietf:params:xml:ns:mrcpv2"
           xmlns:ex="http://www.example.com/example"
           grammar="http://www.example.com/flight">
     <interpretation confidence="0.6">
        <instance>
           <ex:airline>
              <ex:to_city>Pittsburgh</ex:to_city>
           <ex:airline>
        <instance>
        <input mode="speech">
           I want to go to Pittsburgh
        </input>
     </interpretation>
     <interpretation confidence="0.4"
        <instance>
           <ex:airline>
              <ex:to_city>Stockholm</ex:to_city>
           </ex:airline>
        </instance>
        <input>I want to go to Stockholm</input>
     </interpretation>
   </result>
```

---
#### **14.2.2.  Mixed Initiative**

```text
   System: What would you like?
   User:   I would like 2 pizzas, one with pepperoni and cheese,
           one with sausage and a bottle of coke, to go.
```

이 예에는 "food\_item", "drink\_item", "delivery\_method"라는 이름의 객체를 포함하는 order 객체가 포함됩니다. 이 표현은 음성 또는 자연어 처리에 모호성이 없다고 가정합니다. 이 표현은 또한 어느 정도의 문장 내 대명사 해결, 즉 두 개의 "one"을 "pizza"로 해결한다고 가정합니다.

```text
   <?xml version="1.0"?>
   <nl:result xmlns:nl="urn:ietf:params:xml:ns:mrcpv2"
              xmlns="http://www.example.com/example"
              grammar="http://www.example.com/foodorder">

     <nl:interpretation confidence="1.0" >
        <nl:instance>
         <order>
           <food_item confidence="1.0">
             <pizza>
               <ingredients confidence="1.0">
                 pepperoni
               </ingredients>
               <ingredients confidence="1.0">
                 cheese
               </ingredients>
             </pizza>
             <pizza>
               <ingredients>sausage</ingredients>
             </pizza>
           </food_item>
           <drink_item confidence="1.0">
             <size>2-liter</size>
           </drink_item>
           <delivery_method>to go</delivery_method>
         </order>
       </nl:instance>
       <nl:input mode="speech">I would like 2 pizzas,
            one with pepperoni and cheese, one with sausage
            and a bottle of coke, to go.
       </nl:input>
     </nl:interpretation>
   </nl:result>
```

---
#### **14.2.3.  DTMF Input**

DTMF 입력과 음성의 조합은 중첩된 입력 요소를 사용하여 표현됩니다. 예: 사용자: 내 핀은 \(dtmf 1 2 3 4\)입니다.

<input\> <input mode="speech" confidence ="1.0" timestamp-start="2000-04-03T0:00:00" timestamp-end="2000-04-03T0:00:01.5"\>내 핀은 </input\> <input mode="dtmf" confidence ="1.0" timestamp-start="2000-04-03T0:00:01.5" timestamp-end="2000-04-03T0:00:02.0"\>1 2 3 4 </input\> </input\>

현재 SRGS에서는 음성과 DTMF의 혼합을 인식하는 문법이 가능하지 않습니다. 그러나 이러한 표현은 NLSML의 다른 응용 프로그램에 필요할 수 있으며, 이러한 혼합 기능은 SRGS의 향후 버전에서 도입될 수 있습니다.

---
#### **14.2.4.  Interpreting Meta-Dialog and Meta-Task Utterances**

자연어 커뮤니케이션은 메타 대화 및 메타 작업 발화를 사용합니다. 이 사양은 충분히 유연하여 다른 표준 마크업이 필요 없이 응용 프로그램별로 메타 발화를 표현할 수 있습니다.

메타 작업과 메타 대화 발화가 어떻게 표현될 수 있는지에 대한 두 가지 예는 다음과 같습니다.

시스템: 피자에 어떤 토핑을 원하시나요? 사용자: 어떤 토핑을 원하시나요?

```text
<interpretation grammar="http://www.example.com/toppings">
   <instance>
      <question>
         <questioned_item>toppings<questioned_item>
         <questioned_property>
          availability
         </questioned_property>
      </question>
   </instance>
   <input mode="speech">
     what toppings do you have?
   </input>
</interpretation>
```

---
# **User:   slow down.**

```text
<interpretation grammar="http://www.example.com/generalCommandsGrammar">
   <instance>
    <command>
       <action>reduce speech rate</action>
       <doer>system</doer>
    </command>
   </instance>
  <input mode="speech">slow down</input>
</interpretation>
```

---
#### **14.2.5.  Anaphora and Deixis**

이 사양은 해결되지 않은 대명사 및 지시어 참조를 포함하는 발화를 나타내는 데 애플리케이션별로 사용할 수 있습니다. 대명사와 명확한 명사 구를 포함하는 대명사 참조는 이전 언어적 맥락에서 언급된 것을 나타내며, 지시어 참조는 비언어적 맥락에 존재하는 것을 나타내며, 해석에서 정확한 역할을 결정하기에 충분한 명확한 언어적 맥락이 없을 수 있다는 점에서 유사한 문제를 나타냅니다. 이 사양을 사용하여 해결되지 않은 대명사와 지시어를 나타내기 위해 개발자가 참조 해석의 구체적인 세부 사항을 열어두는 보다 표면 지향적 표현을 정의하는 것이 한 가지 전략이 될 것입니다. \(이는 이후 구성 요소가 실제로 참조를 해결하는 책임이 있다고 가정합니다.\)

```text
   Example: (ignoring the issue of representing the input from the
             pointing gesture.)
```

시스템: 뭐 드시겠어요? 사용자: 이거 주세요. \(큰 루트비어 사진을 클릭\)

```text
   <?xml version="1.0"?>
   <nl:result xmlns:nl="urn:ietf:params:xml:ns:mrcpv2"
           xmlns="http://www.example.com/example"
           grammar="http://www.example.com/beverages.grxml">
      <nl:interpretation>
         <nl:instance>
          <doer>I</doer>
          <action>want</action>
          <object>this</object>
         </nl:instance>
         <nl:input mode="speech">I want this</nl:input>
      </nl:interpretation>
   </nl:result>
```

---
#### **14.2.6.  Distinguishing Individual Items from Sets with One Member**

프로그래밍 편의를 위해 의미 결과의 XML 표현에서 개별 항목과 하나의 항목을 포함하는 세트를 구별할 수 있는 것이 유용합니다. 예를 들어, 피자 주문은 정확히 피자 한 개로 구성될 수 있지만 피자에는 토핑이 0개 이상 포함될 수 있습니다. XML에서 이러한 구별을 직접 표시하는 표준 방법이 없으므로 현재 프레임워크에서는 개발자가 XML 마크업에서 이 정보를 전달하는 모든 규칙을 자유롭게 채택할 수 있습니다. 한 가지 전략은 개발자가 다음 예와 같이 그룹화 요소에 항목 세트를 래핑하는 것입니다.

```text
   <order>
      <pizza>
         <topping-group>
            <topping>mushrooms</topping>
         </topping-group>
      </pizza>
      <drink>coke</drink>
   </order>
```

이 예에서 프로그래머는 주문에 피자 한 개와 음료 한 개가 정확히 포함되어 있다고 가정할 수 있지만, 토핑이 하나뿐인 것은 이 특정 피자 주문의 우연입니다.

클라이언트는 문법과 문법이 일치할 때 반환되는 의미를 모두 제어하므로 MRCPv2 사용자는 해석이 사용자에게 명확하게 전달되는 방식으로 NLSML로 결과가 반환되도록 할 수 있는 전적인 권한이 있습니다.

---
#### **14.2.7.  Extensibility**

NLSML의 확장성은 메타 발화와 대명사에 대한 논의에서 설명된 대로 결과 내용의 유연성을 통해 제공됩니다. NLSML은 정교한 시스템에서 쉽게 사용하여 더 기본적인 시스템에서 사용하지 않는 애플리케이션별 정보\(예: 언어 행위 정의\)를 전달할 수 있습니다.

---
## **15.  ABNF Normative Definition**

다음 프로덕션은 RFC 5234 \[RFC5234\]의 섹션 B.1에 정의된 핵심 규칙을 활용합니다.

---
# **LWS    =    [*WSP CRLF] 1*WSP ; linear whitespace**
---
# **SWS    =    [LWS] ; sep whitespace**

```teUTF8-NONASCII    =    %xC0-DF 1UTF8-CONT
                 /    %xE0-EF 2UTF8-CONT
                 /    %xF0-F7 3UTF8-CONT
                 /    %xF8-FB 4UTF8-CONT
                 /    %xFC-FD 5UTF8-CONT

UTF8-CONT        =    %x80-BF
UTFCHAR          =    %x21-7E
                 /    UTF8-NONASCII
param            =    *pchar

quoted-string    =    SWS DQUOTE *(qdtext / quoted-pair )
                      DQUOTE

qdtext           =    LWS / %x21 / %x23-5B / %x5D-7E
                 /    UTF8-NONASCII
```

---
# **quoted-pair      =    "\" (%x00-09 / %x0B-0C / %x0E-7F)**

```text
token            =    1*(alphanum / "-" / "." / "!" / "%" / "*"
                      / "_" / "+" / "`" / "'" / "~" )

reserved         =    ";" / "/" / "?" / ":" / "@" / "&" / "="
                      / "+" / "$" / ","

mark             =    "-" / "_" / "." / "!" / "~" / "*" / "'"
                 /    "(" / ")"
```

---
# **unreserved       =    alphanum / mark**

```text
pchar            =    unreserved / escaped
                 /    ":" / "@" / "&" / "=" / "+" / "$" / ","
```

---
# **alphanum         =    ALPHA / DIGIT**
---
# **BOOLEAN          =    "true" / "false"**
---
# **FLOAT            =    *DIGIT ["." *DIGIT]**
---
# **escaped          =    "%" HEXDIG HEXDIG**
---
# **fragment         =    *uric**

```text
uri              =    [ absoluteURI / relativeURI ]
                      [ "#" fragment ]
```

---
# **absoluteURI      =    scheme ":" ( hier-part / opaque-part )**

```text
relativeURI      =    ( net-path / abs-path / rel-path )
                      [ "?" query ]
```

---
# **hier-part        =    ( net-path / abs-path ) [ "?" query ]**
---
# **net-path         =    "//" authority [ abs-path ]**
---
# **abs-path         =    "/" path-segments**
---
# **rel-path         =    rel-segment [ abs-path ]**

```text
rel-segment      =    1*( unreserved / escaped / ";" / "@"
                 /    "&" / "=" / "+" / "$" / "," )
```

---
# **opaque-part      =    uric-no-slash *uric**
---
# **uric             =    reserved / unreserved / escaped**

```text
uric-no-slash    =    unreserved / escaped / ";" / "?" / ":"
                      / "@" / "&" / "=" / "+" / "$" / ","
```

---
# **path-segments    =    segment *( "/" segment )**
---
# **segment          =    *pchar *( ";" param )**
---
# **scheme           =    ALPHA *( ALPHA / DIGIT / "+" / "-" / "." )**
---
# **authority        =    srvr / reg-name**
---
# **srvr             =    [ [ userinfo "@" ] hostport ]**

```text
reg-name         =    1*( unreserved / escaped / "$" / ","
                 /     ";" / ":" / "@" / "&" / "=" / "+" )
```

---
# **query            =    *uric**
---
# **userinfo         =    ( user ) [ ":" password ] "@"**

```text
user             =    1*( unreserved / escaped
                 /    user-unreserved )

user-unreserved  =    "&" / "=" / "+" / "$" / "," / ";"
                 /    "?" / "/"

password         =    *( unreserved / escaped
                 /    "&" / "=" / "+" / "$" / "," )
```

---
# **hostport         =    host [ ":" port ]**
---
# **host             =    hostname / IPv4address / IPv6reference**
---
# **hostname         =    *( domainlabel "." ) toplabel [ "." ]**

```text
domainlabel      =    alphanum / alphanum *( alphanum / "-" )
                      alphanum

toplabel         =    ALPHA / ALPHA *( alphanum / "-" )
                      alphanum

IPv4address      =    1*3DIGIT "." 1*3DIGIT "." 1*3DIGIT "."
                      1*3DIGIT
```

---
# **IPv6reference    =    "[" IPv6address "]"**
---
# **IPv6address      =    hexpart [ ":" IPv4address ]**

```text
hexpart          =    hexseq / hexseq "::" [ hexseq ] / "::"
                      [ hexseq ]
```

---
# **hexseq           =    hex4 *( ":" hex4)**
---
# **hex4             =    1*4HEXDIG**
---
# **port             =    1*19DIGIT**

; generic-message는 최상위 규칙입니다.

```text
generic-message  =    start-line message-header CRLF
                      [ message-body ]
```

---
# **message-body     =    *OCTET**
---
# **start-line       =    request-line / response-line / event-line**

```text
request-line     =    mrcp-version SP message-length SP method-name
                      SP request-id CRLF

response-line    =    mrcp-version SP message-length SP request-id
                      SP status-code SP request-state CRLF

event-line       =    mrcp-version SP message-length SP event-name
                      SP request-id SP request-state CRLF

method-name      =    generic-method
                 /    synthesizer-method
                 /    recognizer-method
                 /    recorder-method
                 /    verifier-method

generic-method   =    "SET-PARAMS"
                 /    "GET-PARAMS"

request-state    =    "COMPLETE"
                 /    "IN-PROGRESS"
                 /    "PENDING"

event-name       =    synthesizer-event
                 /    recognizer-event
                 /    recorder-event
                 /    verifier-event
```

---
# **message-header   =  1*(generic-header / resource-header / generic-field)**

```text
generic-field    =    field-name ":" [ field-value ]
field-name       =    token
field-value      =    *LWS field-content *( CRLF 1*LWS field-content)
field-content    =    <the OCTETs making up the field-value
                      and consisting of either *TEXT or combinations
                      of token, separators, and quoted-string>

resource-header  =    synthesizer-header
                 /    recognizer-header
                 /    recorder-header
                 /    verifier-header

generic-header   =    channel-identifier
                 /    accept
                 /    active-request-id-list
                 /    proxy-sync-id
                 /    accept-charset
                 /    content-type
                 /    content-id
                 /    content-base
                 /    content-encoding
                 /    content-location
                 /    content-length
                 /    fetch-timeout
                 /    cache-control
                 /    logging-tag
                 /    set-cookie
                 /    vendor-specific
```

; -- content-id는 RFC 2392, RFC 2046 및 RFC 5322에 정의된 대로입니다. ; -- accept 및 accept-charset은 RFC 2616에 정의된 대로입니다.

---
# **mrcp-version     =    "MRCP" "/" 1*2DIGIT "." 1*2DIGIT**
---
# **message-length   =    1*19DIGIT**
---
# **request-id       =    1*10DIGIT**
---
# **status-code      =    3DIGIT**

```text
channel-identifier =  "Channel-Identifier" ":"
                      channel-id CRLF
```

---
# **channel-id       =    1*alphanum "@" 1*alphanum**

```text
active-request-id-list = "Active-Request-Id-List" ":"
                         request-id *("," request-id) CRLF
```

---
# **proxy-sync-id    =    "Proxy-Sync-Id" ":" 1*VCHAR CRLF**
---
# **content-base     =    "Content-Base" ":" absoluteURI CRLF**
---
# **content-length   =    "Content-Length" ":" 1*19DIGIT CRLF**
---
# **content-type     =    "Content-Type" ":" media-type-value CRLF**
---
# **media-type-value =    type "/" subtype *( ";" parameter )**
---
# **type             =    token**
---
# **subtype          =    token**
---
# **parameter        =    attribute "=" value**
---
# **attribute        =    token**
---
# **value            =    token / quoted-string**

```text
content-encoding =    "Content-Encoding" ":"
                      *WSP content-coding
                      *(*WSP "," *WSP content-coding *WSP )
                      CRLF
```

---
# **content-coding   =    token**

```text
content-location =    "Content-Location" ":"
                      ( absoluteURI / relativeURI )  CRLF

cache-control    =    "Cache-Control" ":"
                      [*WSP cache-directive
                      *( *WSP "," *WSP cache-directive *WSP )]
                      CRLF
```

---
# **fetch-timeout    =    "Fetch-Timeout" ":" 1*19DIGIT CRLF**

```text
cache-directive  =    "max-age" "=" delta-seconds
                 /    "max-stale" ["=" delta-seconds ]
                 /    "min-fresh" "=" delta-seconds
```

---
# **delta-seconds    =    1*19DIGIT**
**
---
# **logging-tag      =    "Logging-Tag" ":" 1*UTFCHAR CRLF**

```text
vendor-specific  =    "Vendor-Specific-Parameters" ":"
                      [vendor-specific-av-pair
                      *(";" vendor-specific-av-pair)] CRLF

vendor-specific-av-pair = vendor-av-pair-name "="
                          value
```

---
# **vendor-av-pair-name     = 1*UTFCHAR**

```text
set-cookie        = "Set-Cookie:" SP set-cookie-string
set-cookie-string = cookie-pair *( ";" SP cookie-av )
cookie-pair       = cookie-name "=" cookie-value
cookie-name       = token
cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )
cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E
token             = <token, defined in [RFC2616], Section 2.2>

cookie-av         = expires-av / max-age-av / domain-av /
                     path-av / secure-av / httponly-av /
                     extension-av / age-av
expires-av        = "Expires=" sane-cookie-date
sane-cookie-date  = <rfc1123-date, defined in [RFC2616], Section 3.3.1>
max-age-av        = "Max-Age=" non-zero-digit *DIGIT
non-zero-digit    = %x31-39
domain-av         = "Domain=" domain-value
domain-value      = <subdomain>
path-av           = "Path=" path-value
path-value        = <any CHAR except CTLs or ";">
secure-av         = "Secure"
httponly-av       = "HttpOnly"
extension-av      = <any CHAR except CTLs or ";">
age-av            = "Age=" delta-seconds

; Synthesizer ABNF

synthesizer-method    =    "SPEAK"
                      /    "STOP"
                      /    "PAUSE"
                      /    "RESUME"
                      /    "BARGE-IN-OCCURRED"
                      /    "CONTROL"
                      /    "DEFINE-LEXICON"

synthesizer-event     =    "SPEECH-MARKER"
                      /    "SPEAK-COMPLETE"

synthesizer-header    =    jump-size
                      /    kill-on-barge-in
                      /    speaker-profile
                      /    completion-cause
                      /    completion-reason
                      /    voice-parameter
                      /    prosody-parameter
                      /    speech-marker
                      /    speech-language
                      /    fetch-hint
                      /    audio-fetch-hint
                      /    failed-uri
                      /    failed-uri-cause
                      /    speak-restart
                      /    speak-length
                      /    load-lexicon
                      /    lexicon-search-order
```

---
# **jump-size             =    "Jump-Size" ":" speech-length-value CRLF**

```text
speech-length-value   =    numeric-speech-length
                      /    text-speech-length
```

---
# **text-speech-length    =    1*UTFCHAR SP "Tag"**
---
# **numeric-speech-length =    ("+" / "-") positive-speech-length**
---
# **positive-speech-length =   1*19DIGIT SP numeric-speech-unit**

```text
numeric-speech-unit   =    "Second"
                      /    "Word"
                      /    "Sentence"
                      /    "Paragraph"

kill-on-barge-in      =    "Kill-On-Barge-In" ":" BOOLEAN
                           CRLF
```

---
# **speaker-profile       =    "Speaker-Profile" ":" uri CRLF**

```text
completion-cause         =  "Completion-Cause" ":" cause-code SP
                            cause-name CRLF
cause-code               =  3DIGIT
cause-name               =  *VCHAR

completion-reason     =    "Completion-Reason" ":"
                           quoted-string CRLF

voice-parameter       =    voice-gender
                      /    voice-age
                      /    voice-variant
                      /    voice-name
```

---
# **voice-gender          =    "Voice-Gender:" voice-gender-value CRLF**

```text
voice-gender-value    =    "male"
                      /    "female"
                      /    "neutral"
```

---
# **voice-age             =    "Voice-Age:" 1*3DIGIT CRLF**
---
# **voice-variant         =    "Voice-Variant:" 1*19DIGIT CRLF**

```text
voice-name            =    "Voice-Name:"
                           1*UTFCHAR *(1*WSP 1*UTFCHAR) CRLF

prosody-parameter     =    "Prosody-" prosody-param-name ":"
                           prosody-param-value CRLF
```

---
# **prosody-param-name    =    1*VCHAR**
---
# **prosody-param-value   =    1*VCHAR**
---
# **timestamp             =    "timestamp" "=" time-stamp-value**
---
# **time-stamp-value      =    1*20DIGIT**

```text
speech-marker         =    "Speech-Marker" ":"
                           timestamp
                           [";" 1*(UTFCHAR / %x20)] CRLF
```

---
# **speech-language       =    "Speech-Language" ":" 1*VCHAR CRLF**
---
# **fetch-hint            =    "Fetch-Hint" ":" ("prefetch" / "safe") CRLF**

```text
audio-fetch-hint      =    "Audio-Fetch-Hint" ":"
                          ("prefetch" / "safe" / "stream") CRLF
```

---
# **failed-uri            =    "Failed-URI" ":" absoluteURI CRLF**
---
# **failed-uri-cause      =    "Failed-URI-Cause" ":" 1*UTFCHAR CRLF**
---
# **speak-restart         =    "Speak-Restart" ":" BOOLEAN CRLF**

```text
speak-length          =    "Speak-Length" ":" positive-length-value
                           CRLF

positive-length-value   =  positive-speech-length
                        /  text-speech-length
```

---
# **load-lexicon          =    "Load-Lexicon" ":" BOOLEAN CRLF**

```text
lexicon-search-order  =    "Lexicon-Search-Order" ":"
          "<" absoluteURI ">" *(" " "<" absoluteURI ">") CRLF

; Recognizer ABNF

recognizer-method     =    recog-only-method
                      /    enrollment-method

recog-only-method     =    "DEFINE-GRAMMAR"
                      /    "RECOGNIZE"
                      /    "INTERPRET"
                      /    "GET-RESULT"
                      /    "START-INPUT-TIMERS"
                      /    "STOP"

enrollment-method     =    "START-PHRASE-ENROLLMENT"
                      /    "ENROLLMENT-ROLLBACK"
                      /    "END-PHRASE-ENROLLMENT"
                      /    "MODIFY-PHRASE"
                      /    "DELETE-PHRASE"

recognizer-event      =    "START-OF-INPUT"
                      /    "RECOGNITION-COMPLETE"
                      /    "INTERPRETATION-COMPLETE"

recognizer-header     =    recog-only-header
                      /    enrollment-header

recog-only-header     =    confidence-threshold
                      /    sensitivity-level
                      /    speed-vs-accuracy
                      /    n-best-list-length
                      /    input-type
                      /    no-input-timeout
                      /    recognition-timeout
                      /    waveform-uri
                      /    input-waveform-uri
                      /    completion-cause
                      /    completion-reason
                      /    recognizer-context-block

                      /    start-input-timers
                      /    speech-complete-timeout
                      /    speech-incomplete-timeout
                      /    dtmf-interdigit-timeout
                      /    dtmf-term-timeout
                      /    dtmf-term-char
                      /    failed-uri
                      /    failed-uri-cause
                      /    save-waveform
                      /    media-type
                      /    new-audio-channel
                      /    speech-language
                      /    ver-buffer-utterance
                      /    recognition-mode
                      /    cancel-if-queue
                      /    hotword-max-duration
                      /    hotword-min-duration
                      /    interpret-text
                      /    dtmf-buffer-time
                      /    clear-dtmf-buffer
                      /    early-no-matcenrollment-header     =    num-min-consistent-pronunciations
                      /    consistency-threshold
                      /    clash-threshold
                      /    personal-grammar-uri
                      /    enroll-utterance
                      /    phrase-id
                      /    phrase-nl
                      /    weight
                      /    save-best-waveform
                      /    new-phrase-id
                      /    confusable-phrases-uri
                      /    abort-phrase-enrollment

confidence-threshold  =    "Confidence-Threshold" ":"
                           FLOAT CRLF

sensitivity-level     =    "Sensitivity-Level" ":" FLOAT
                           CRLF

speed-vs-accuracy     =    "Speed-Vs-Accuracy" ":" FLOAT
                           CRLF

n-best-list-length    =    "N-Best-List-Length" ":" 1*19DIGIT
                           CRLF
```

---
# **input-type            =    "Input-Type" ":"  inputs CRLF**
---
# **inputs                =    "speech" / "dtmf"**

```text
no-input-timeout      =    "No-Input-Timeout" ":" 1*19DIGIT
                           CRLF

recognition-timeout   =    "Recognition-Timeout" ":" 1*19DIGIT
                           CRLF

waveform-uri          =    "Waveform-URI" ":" ["<" uri ">"
                           ";" "size" "=" 1*19DIGIT
                           ";" "duration" "=" 1*19DIGIT] CRLF

recognizer-context-block = "Recognizer-Context-Block" ":"
                           [1*VCHAR] CRLF

start-input-timers    =    "Start-Input-Timers" ":"
                           BOOLEAN CRLF

speech-complete-timeout =  "Speech-Complete-Timeout" ":"
                           1*19DIGIT CRLF

speech-incomplete-timeout = "Speech-Incomplete-Timeout" ":"
                            1*19DIGIT CRLF

dtmf-interdigit-timeout = "DTMF-Interdigit-Timeout" ":"
                          1*19DIGIT CRLF

dtmf-term-timeout     =    "DTMF-Term-Timeout" ":" 1*19DIGIT
                           CRLF
```

---
# **dtmf-term-char        =    "DTMF-Term-Char" ":" VCHAR CRLF**
---
# **save-waveform         =    "Save-Waveform" ":" BOOLEAN CRLF**

```text
new-audio-channel     =    "New-Audio-Channel" ":"
                           BOOLEAN CRLF

recognition-mode      =    "Recognition-Mode" ":"
                           "normal" / "hotword" CRLF
```

---
# **cancel-if-queue       =    "Cancel-If-Queue" ":" BOOLEAN CRLF**

```text
hotword-max-duration  =    "Hotword-Max-Duration" ":"
                           1*19DIGIT CRLF

hotword-min-duration  =    "Hotword-Min-Duration" ":"
                           1*19DIGIT CRLF
```

---
# **interpret-text        =    "Interpret-Text" ":" 1*VCHAR CRLF**
---
# **dtmf-buffer-time      =    "DTMF-Buffer-Time" ":" 1*19DIGIT CRLF**
---
# **clear-dtmf-buffer     =    "Clear-DTMF-Buffer" ":" BOOLEAN CRLF**
---
# **early-no-match        =    "Early-No-Match" ":" BOOLEAN CRLF**

```text
num-min-consistent-pronunciations    =
    "Num-Min-Consistent-Pronunciations" ":" 1*19DIGIT CRLF

consistency-threshold =    "Consistency-Threshold" ":" FLOAT
                           CRLF
```

---
# **clash-threshold       =    "Clash-Threshold" ":" FLOAT CRLF**
---
# **personal-grammar-uri  =    "Personal-Grammar-URI" ":" uri CRLF**
---
# **enroll-utterance      =    "Enroll-Utterance" ":" BOOLEAN CRLF**
---
# **phrase-id             =    "Phrase-ID" ":" 1*VCHAR CRLF**
---
# **phrase-nl             =    "Phrase-NL" ":" 1*UTFCHAR CRLF**
---
# **weight                =    "Weight" ":" FLOAT CRLF**

```text
save-best-waveform    =    "Save-Best-Waveform" ":"
                           BOOLEAN CRLF
```

---
# **new-phrase-id         =    "New-Phrase-ID" ":" 1*VCHAR CRLF**

```text
confusable-phrases-uri =   "Confusable-Phrases-URI" ":"
                           uri CRLF

abort-phrase-enrollment =  "Abort-Phrase-Enrollment" ":"
                           BOOLEAN CRLF

; Recorder ABNF

recorder-method       =    "RECORD"
                      /    "STOP"
                      /    "START-INPUT-TIMERS"

recorder-event        =    "START-OF-INPUT"
                      /    "RECORD-COMPLETE"

recorder-header       =    sensitivity-level
                      /    no-input-timeout
                      /    completion-cause
                      /    completion-reason
                      /    failed-uri
                      /    failed-uri-cause
                      /    record-uri
                      /    media-type
                      /    max-time
                      /    trim-length
                      /    final-silence
                      /    capture-on-speech
                      /    ver-buffer-utterance
                      /    start-input-timers
                      /    new-audio-channel

record-uri            =    "Record-URI" ":" [ "<" uri ">"
                           ";" "size" "=" 1*19DIGIT
                           ";" "duration" "=" 1*19DIGIT] CRLF
```

---
# **media-type            =    "Media-Type" ":" media-type-value CRLF**
---
# **max-time              =    "Max-Time" ":" 1*19DIGIT CRLF**
---
# **trim-length           =    "Trim-Length" ":" 1*19DIGIT CRLF**
---
# **final-silence         =    "Final-Silence" ":" 1*19DIGIT CRLF**

```text
capture-on-speech     =    "Capture-On-Speech " ":"
                           BOOLEAN CRLF

; Verifier ABNF

verifier-method       =    "START-SESSION"
                      /    "END-SESSION"
                      /    "QUERY-VOICEPRINT"
                      /    "DELETE-VOICEPRINT"
                      /    "VERIFY"
                      /    "VERIFY-FROM-BUFFER"
                      /    "VERIFY-ROLLBACK"
                      /    "STOP"
                      /    "CLEAR-BUFFER"
                      /    "START-INPUT-TIMERS"
                      /    "GET-INTERMEDIATE-RESULT"

verifier-event        =    "VERIFICATION-COMPLETE"
                      /    "START-OF-INPUT"

verifier-header       =    repository-uri
                      /    voiceprint-identifier
                      /    verification-mode
                      /    adapt-model
                      /    abort-model
                      /    min-verification-score
                      /    num-min-verification-phrases
                      /    num-max-verification-phrases
                      /    no-input-timeout
                      /    save-waveform
                      /    media-type
                      /    waveform-uri
                      /    voiceprint-exists
                      /    ver-buffer-utterance
                      /    input-waveform-uri
                      /    completion-cause
                      /    completion-reason
                      /    speech-complete-timeout
                      /    new-audio-channel
                      /    abort-verification
                      /    start-input-timers
                      /    input-type
```

---
# **repository-uri        =    "Repository-URI" ":" uri CRLF**

```text
voiceprint-identifier        =  "Voiceprint-Identifier" ":"
                                vid *[";" vid] CRLF
vid                          =  1*VCHAR ["." 1*VCHAR]

verification-mode     =    "Verification-Mode" ":"
                           verification-mode-string
```

---
# **verification-mode-string = "train" / "verify"**
---
# **adapt-model           =    "Adapt-Model" ":" BOOLEAN CRLF**
---
# **abort-model           =    "Abort-Model" ":" BOOLEAN CRLF**

```text
min-verification-score  =  "Min-Verification-Score" ":"
                           [ %x2D ] FLOAT CRLF

num-min-verification-phrases = "Num-Min-Verification-Phrases"
                               ":" 1*19DIGIT CRLF

num-max-verification-phrases = "Num-Max-Verification-Phrases"
                               ":" 1*19DIGIT CRLF

voiceprint-exists     =    "Voiceprint-Exists" ":"
                           BOOLEAN CRLF

ver-buffer-utterance  =    "Ver-Buffer-Utterance" ":"
                           BOOLEAN CRLF
```

---
# **input-waveform-uri    =    "Input-Waveform-URI" ":" uri CRLF**

```text
abort-verification    =    "Abort-Verification " ":"
                           BOOLEAN CRLF
```

다다음 프로덕션은 새로운 SDP 세션 수준 속성을 추가합니다. 단락 5 참조.

```text
   cmid-attribute     =    "a=cmid:" identification-tag

   identification-tag =    token
```

---
## **16.  XML Schemas**
---
### **16.1.  NLSML Schema Definition**

```text
 <?xml version="1.0" encoding="UTF-8"?>
 <xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema"
             targetNamespace="urn:ietf:params:xml:ns:mrcpv2"
             xmlns="urn:ietf:params:xml:ns:mrcpv2"
             elementFormDefault="qualified"
             attributeFormDefault="unqualified" >
   <xs:annotation>
     <xs:documentation> Natural Language Semantic Markup Schema
     </xs:documentation>
   </xs:annotation>
   <xs:include schemaLocation="enrollment-schema.rng"/>
   <xs:include schemaLocation="verification-schema.rng"/>
   <xs:element name="result">
     <xs:complexType>
       <xs:sequence>
         <xs:element name="interpretation" maxOccurs="unbounded">
           <xs:complexType>
             <xs:sequence>
               <xs:element name="instance">
                 <xs:complexType mixed="true">
                   <xs:sequence minOccurs="0">
                     <xs:any namespace="##other" processContents="lax"/>
                   </xs:sequence>
                 </xs:complexType>
               </xs:element>
               <xs:element name="input" minOccurs="0">

                 <xs:complexType mixed="true">
                   <xs:choice>
                     <xs:element name="noinput" minOccurs="0"/>
                     <xs:element name="nomatch" minOccurs="0"/>
                     <xs:element name="input" minOccurs="0"/>
                   </xs:choice>
                   <xs:attribute name="mode"
                                 type="xs:string"
                                 default="speech"/>
                   <xs:attribute name="confidence"
                                 type="confidenceinfo"
                                 default="1.0"/>
                   <xs:attribute name="timestamp-start"
                                 type="xs:string"/>
                   <xs:attribute name="timestamp-end"
                                 type="xs:string"/>
                 </xs:complexType>
               </xs:element>
             </xs:sequence>
             <xs:attribute name="confidence" type="confidenceinfo"
                           default="1.0"/>
             <xs:attribute name="grammar" type="xs:anyURI"
                           use="optional"/>
           </xs:complexType>
         </xs:element>
         <xs:element name="enrollment-result"
                     type="enrollment-contents"/>
         <xs:element name="verification-result"
                     type="verification-contents"/>
       </xs:sequence>
       <xs:attribute name="grammar" type="xs:anyURI"
                     use="optional"/>
     </xs:complexType>
   </xs:element>

   <xs:simpleType name="confidenceinfo">
     <xs:restriction base="xs:float">
        <xs:minInclusive value="0.0"/>
        <xs:maxInclusive value="1.0"/>
     </xs:restriction>
   </xs:simpleType>
 </xs:schema>
```

---
### **16.2.  Enrollment Results Schema Definition**

```text
   <?xml version="1.0" encoding="UTF-8"?>

   <!-- MRCP Enrollment Schema
   (See http://www.oasis-open.org/committees/relax-ng/spec.html)
   -->

   <grammar datatypeLibrary="http://www.w3.org/2001/XMLSchema-datatypes"
            ns="urn:ietf:params:xml:ns:mrcpv2"
            xmlns="http://relaxng.org/ns/structure/1.0">

     <start>
       <element name="enrollment-result">
         <ref name="enrollment-content"/>
       </element>
     </start>

     <define name="enrollment-content">
       <interleave>
         <element name="num-clashes">
           <data type="nonNegativeInteger"/>
         </element>
         <element name="num-good-repetitions">
           <data type="nonNegativeInteger"/>
         </element>
         <element name="num-repetitions-still-needed">
           <data type="nonNegativeInteger"/>
         </element>
         <element name="consistency-status">
           <choice>
             <value>consistent</value>
             <value>inconsistent</value>
             <value>undecided</value>
           </choice>
         </element>
         <optional>
           <element name="clash-phrase-ids">
             <oneOrMore>
               <element name="item">
                 <data type="token"/>
               </element>
             </oneOrMore>
           </element>
         </optional>
         <optional>
           <element name="transcriptions">
             <oneOrMore>

               <element name="item">
                 <text/>
               </element>
             </oneOrMore>
           </element>
         </optional>
         <optional>
           <element name="confusable-phrases">
             <oneOrMore>
               <element name="item">
                 <text/>
               </element>
             </oneOrMore>
           </element>
         </optional>
       </interleave>
     </define>

   </grammar>

16.3.  Verification Results Schema Definition
   <?xml version="1.0" encoding="UTF-8"?>

   <!--    MRCP Verification Results Schema
           (See http://www.oasis-open.org/committees/relax-ng/spec.html)
      -->

   <grammar datatypeLibrary="http://www.w3.org/2001/XMLSchema-datatypes"
            ns="urn:ietf:params:xml:ns:mrcpv2"
            xmlns="http://relaxng.org/ns/structure/1.0">

     <start>
       <element name="verification-result">
         <ref name="verification-contents"/>
       </element>
     </start>

     <define name="verification-contents">
       <element name="voiceprint">
         <ref name="firstVoiceprintContent"/>
       </element>
       <zeroOrMore>
         <element name="voiceprint">
           <ref name="restVoiceprintContent"/>
         </element>
       </zeroOrMore>
     </define>

     <define name="firstVoiceprintContent">
       <attribute name="id">
         <data type="string"/>
       </attribute>
       <interleave>
         <optional>
           <element name="adapted">
             <data type="boolean"/>
           </element>
         </optional>
         <optional>
           <element name="needmoredata">
             <ref name="needmoredataContent"/>
           </element>
         </optional>
         <optional>
           <element name="incremental">
             <ref name="firstCommonContent"/>
           </element>
         </optional>
         <element name="cumulative">
           <ref name="firstCommonContent"/>
         </element>
       </interleave>
     </define>

     <define name="restVoiceprintContent">
       <attribute name="id">
         <data type="string"/>
       </attribute>
       <element name="cumulative">
         <ref name="restCommonContent"/>
       </element>
     </define>

     <define name="firstCommonContent">
       <interleave>
         <element name="decision">
           <ref name="decisionContent"/>
         </element>
         <optional>
           <element name="utterance-length">
             <ref name="utterance-lengthContent"/>
           </element>
         </optional>
         <optional>
           <element name="device">
             <ref name="deviceContent"/>

           </element>
         </optional>
         <optional>
           <element name="gender">
             <ref name="genderContent"/>
           </element>
         </optional>
         <zeroOrMore>
           <element name="verification-score">
             <ref name="verification-scoreContent"/>
           </element>
         </zeroOrMore>
       </interleave>
     </define     <define name="restCommonContent">
       <interleave>
         <optional>
           <element name="decision">
             <ref name="decisionContent"/>
           </element>
         </optional>
         <optional>
           <element name="device">
             <ref name="deviceContent"/>
           </element>
         </optional>
         <optional>
           <element name="gender">
             <ref name="genderContent"/>
           </element>
         </optional>
        <zeroOrMore>
           <element name="verification-score">
             <ref name="verification-scoreContent"/>
           </element>
        </zeroOrMore>
        </interleave>
     </define>

     <define name="decisionContent">
       <choice>
         <value>accepted</value>
         <value>rejected</value>
         <value>undecided</value>
       </choice>
     </define>

     <define name="needmoredataContent">
       <data type="boolean"/>
     </define>

     <define name="utterance-lengthContent">
       <data type="nonNegativeInteger"/>
     </define>

     <define name="deviceContent">
       <choice>
         <value>cellular-phone</value>
         <value>electret-phone</value>
         <value>carbon-button-phone</value>
         <value>unknown</value>
       </choice>
     </define>

     <define name="genderContent">
       <choice>
         <value>male</value>
         <value>female</value>
         <value>unknown</value>
       </choice>
     </define>

     <define name="verification-scoreContent">
       <data type="float">
         <param name="minInclusive">-1</param>
         <param name="maxInclusive">1</param>
       </data>
     </define>

   </grammar>
```

---
## **17.  References**
---
### **17.1.  Normative References**

```text
   [ISO.8859-1.1987]
              International Organization for Standardization,
              "Information technology - 8-bit single byte coded graphic
              - character sets - Part 1: Latin alphabet No. 1, JTC1/
              SC2", ISO Standard 8859-1, 1987.

   [RFC0793]  Postel, J., "Transmission Control Protocol", STD 7,
              RFC 793, September 1981.

   [RFC1035]  Mockapetris, P., "Domain names - implementation and
              specification", STD 13, RFC 1035, November 1987.

   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
              Requirement Levels", BCP 14, RFC 2119, March 1997.

   [RFC2326]  Schulzrinne, H., Rao, A., and R. Lanphier, "Real Time
              Streaming Protocol (RTSP)", RFC 2326, April 1998.

   [RFC2392]  Levinson, E., "Content-ID and Message-ID Uniform Resource
              Locators", RFC 2392, August 1998.

   [RFC2483]  Mealling, M. and R. Daniel, "URI Resolution Services
              Necessary for URN Resolution", RFC 2483, January 1999.

   [RFC2616]  Fielding, R., Gettys, J., Mogul, J., Frystyk, H.,
              Masinter, L., Leach, P., and T. Berners-Lee, "Hypertext
              Transfer Protocol -- HTTP/1.1", RFC 2616, June 1999.

   [RFC3023]  Murata, M., St. Laurent, S., and D. Kohn, "XML Media
              Types", RFC 3023, January 2001.

   [RFC3261]  Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston,
              A., Peterson, J., Sparks, R., Handley, M., and E.
              Schooler, "SIP: Session Initiation Protocol", RFC 3261,
              June 2002.

   [RFC3264]  Rosenberg, J. and H. Schulzrinne, "An Offer/Answer Model
              with Session Description Protocol (SDP)", RFC 3264,
              June 2002.

   [RFC3550]  Schulzrinne, H., Casner, S., Frederick, R., and V.
              Jacobson, "RTP: A Transport Protocol for Real-Time
              Applications", STD 64, RFC 3550, July 2003.

   [RFC3629]  Yergeau, F., "UTF-8, a transformation format of ISO
              10646", STD 63, RFC 3629, November 2003.

   [RFC3688]  Mealling, M., "The IETF XML Registry", BCP 81, RFC 3688,
              January 2004.

   [RFC3711]  Baugher, M., McGrew, D., Naslund, M., Carrara, E., and K.
              Norrman, "The Secure Real-time Transport Protocol (SRTP)",
              RFC 3711, March 2004.

   [RFC3986]  Berners-Lee, T., Fielding, R., and L. Masinter, "Uniform
              Resource Identifier (URI): Generic Syntax", STD 66,
              RFC 3986, January 2005.

   [RFC4145]  Yon, D. and G. Camarillo, "TCP-Based Media Transport in
              the Session Description Protocol (SDP)", RFC 4145,
              September 2005.

   [RFC4288]  Freed, N. and J. Klensin, "Media Type Specifications and
              Registration Procedures", BCP 13, RFC 4288, December 2005.

   [RFC4566]  Handley, M., Jacobson, V., and C. Perkins, "SDP: Session
              Description Protocol", RFC 4566, July 2006.

   [RFC4568]  Andreasen, F., Baugher, M., and D. Wing, "Session
              Description Protocol (SDP) Security Descriptions for Media
              Streams", RFC 4568, July 2006.

   [RFC4572]  Lennox, J., "Connection-Oriented Media Transport over the
              Transport Layer Security (TLS) Protocol in the Session
              Description Protocol (SDP)", RFC 4572, July 2006.

   [RFC5226]  Narten, T. and H. Alvestrand, "Guidelines for Writing an
              IANA Considerations Section in RFCs", BCP 26, RFC 5226,
              May 2008.

   [RFC5234]  Crocker, D. and P. Overell, "Augmented BNF for Syntax
              Specifications: ABNF", STD 68, RFC 5234, January 2008.

   [RFC5246]  Dierks, T. and E. Rescorla, "The Transport Layer Security
              (TLS) Protocol Version 1.2", RFC 5246, August 2008.

   [RFC5322]  Resnick, P., Ed., "Internet Message Format", RFC 5322,
              October 2008.

   [RFC5646]  Phillips, A. and M. Davis, "Tags for Identifying
              Languages", BCP 47, RFC 5646, September 2009.

   [RFC5888]  Camarillo, G. and H. Schulzrinne, "The Session Description
              Protocol (SDP) Grouping Framework", RFC 5888, June 2010.

   [RFC5905]  Mills, D., Martin, J., Burbank, J., and W. Kasch, "Network
              Time Protocol Version 4: Protocol and Algorithms
              Specification", RFC 5905, June 2010.

   [RFC5922]  Gurbani, V., Lawrence, S., and A. Jeffrey, "Domain
              Certificates in the Session Initiation Protocol (SIP)",
              RFC 5922, June 2010.

   [RFC6265]  Barth, A., "HTTP State Management Mechanism", RFC 6265,
              April 2011.

   [W3C.REC-semantic-interpretation-20070405]
              Tichelen, L. and D. Burke, "Semantic Interpretation for
              Speech Recognition (SISR) Version 1.0", World Wide Web
              Consortium Recommendation REC-semantic-
              interpretation-20070405, April 2007,
              <http://www.w3.org/TR/2007/
              REC-semantic-interpretation-20070405>.

   [W3C.REC-speech-grammar-20040316]
              McGlashan, S. and A. Hunt, "Speech Recognition Grammar
              Specification Version 1.0", World Wide Web Consortium
              Recommendation REC-speech-grammar-20040316, March 2004,
              <http://www.w3.org/TR/2004/REC-speech-grammar-20040316>.

   [W3C.REC-speech-synthesis-20040907]
              Walker, M., Burnett, D., and A. Hunt, "Speech Synthesis
              Markup Language (SSML) Version 1.0", World Wide Web
              Consortium Recommendation REC-speech-synthesis-20040907,
              September 2004,
              <http://www.w3.org/TR/2004/REC-speech-synthesis-20040907>.

   [W3C.REC-xml-names11-20040204]
              Layman, A., Bray, T., Hollander, D., and R. Tobin,
              "Namespaces in XML 1.1", World Wide Web Consortium First
              Edition REC-xml-names11-20040204, February 2004,
              <http://www.w3.org/TR/2004/REC-xml-names11-20040204>.
```

---
### **17.2.  Informative References**

```text
   [ISO.8601.1988]
              International Organization for Standardization, "Data
              elements and interchange formats - Information interchange
              - Representation of dates and times", ISO Standard 8601,
              June 1988.

   [Q.23]     International Telecommunications Union, "Technical
              Features of Push-Button Telephone Sets", ITU-T Q.23, 1993.

      [RFC2046]  Freed, N. and N. Borenstein, "Multipurpose Internet Mail
              Extensions (MIME) Part Two: Media Types", RFC 2046,
              November 1996.

   [RFC2818]  Rescorla, E., "HTTP Over TLS", RFC 2818, May 2000.

   [RFC4217]  Ford-Hutchinson, P., "Securing FTP with TLS", RFC 4217,
              October 2005.

   [RFC4267]  Froumentin, M., "The W3C Speech Interface Framework Media
              Types: application/voicexml+xml, application/ssml+xml,
              application/srgs, application/srgs+xml, application/
              ccxml+xml, and application/pls+xml", RFC 4267,
              November 2005.

   [RFC4301]  Kent, S. and K. Seo, "Security Architecture for the
              Internet Protocol", RFC 4301, December 2005.

   [RFC4313]  Oran, D., "Requirements for Distributed Control of
              Automatic Speech Recognition (ASR), Speaker
              Identification/Speaker Verification (SI/SV), and Text-to-
              Speech (TTS) Resources", RFC 4313, December 2005.

   [RFC4395]  Hansen, T., Hardie, T., and L. Masinter, "Guidelines and
              Registration Procedures for New URI Schemes", BCP 35,
              RFC 4395, February 2006.

   [RFC4463]  Shanmugham, S., Monaco, P., and B. Eberman, "A Media
              Resource Control Protocol (MRCP) Developed by Cisco,
              Nuance, and Speechworks", RFC 4463, April 2006.

   [RFC4467]  Crispin, M., "Internet Message Access Protocol (IMAP) -
              URLAUTH Extension", RFC 4467, May 2006.

   [RFC4733]  Schulzrinne, H. and T. Taylor, "RTP Payload for DTMF
              Digits, Telephony Tones, and Telephony Signals", RFC 4733,
              December 2006.

   [RFC4960]  Stewart, R., "Stream Control Transmission Protocol",
              RFC 4960, September 2007.

   [RFC6454]  Barth, A., "The Web Origin Concept", RFC 6454,
              December 2011.

   [W3C.REC-emma-20090210]
              Johnston, M., Baggia, P., Burnett, D., Carter, J., Dahl,
              D., McCobb, G., and D. Raggett, "EMMA: Extensible
              MultiModal Annotation markup language", World Wide Web
              Consortium Recommendation REC-emma-20090210,
              February 2009,
              <http://www.w3.org/TR/2009/REC-emma-20090210>.

   [W3C.REC-pronunciation-lexicon-20081014]
              Baggia, P., Bagshaw, P., Burnett, D., Carter, J., and F.
              Scahill, "Pronunciation Lexicon Specification (PLS)",
              World Wide Web Consortium Recommendation
              REC-pronunciation-lexicon-20081014, October 2008,
              <http://www.w3.org/TR/2008/
              REC-pronunciation-lexicon-20081014>.

   [W3C.REC-voicexml20-20040316]
              Danielsen, P., Porter, B., Hunt, A., Rehor, K., Lucas, B.,
              Burnett, D., Ferrans, J., Tryphonas, S., McGlashan, S.,
              and J. Carter, "Voice Extensible Markup Language
              (VoiceXML) Version 2.0", World Wide Web Consortium
              Recommendation REC-voicexml20-20040316, March 2004,
              <http://www.w3.org/TR/2004/REC-voicexml20-20040316>.

   [refs.javaSpeechGrammarFormat]
              Sun Microsystems, "Java Speech Grammar Format Version
              1.0", October 1998.
```

---
# **Appendix A.  Contributors**

```text
   Pierre Forgues
   Nuance Communications Ltd.
   1500 University Street
   Suite 935
   Montreal, Quebec
   Canada H3A 3S7

   EMail:  forgues@nuance.com

   Charles Galles
   Intervoice, Inc.
   17811 Waterview Parkway
   Dallas, Texas 75252
   USA

   EMail:  charles.galles@intervoice.com

   Klaus Reifenrath
   Scansoft, Inc
   Guldensporenpark 32
   Building D
   9820 Merelbeke
   Belgium

   EMail: klaus.reifenrath@scansoft.com
```

---
# **Appendix B.  Acknowledgements**

```text
   Andre Gillet (Nuance Communications)
   Andrew Hunt (ScanSoft)
   Andrew Wahbe (Genesys)
   Aaron Kneiss (ScanSoft)
   Brian Eberman (ScanSoft)
   Corey Stohs (Cisco Systems, Inc.)
   Dave Burke (VoxPilot)
   Jeff Kusnitz (IBM Corp)
   Ganesh N. Ramaswamy (IBM Corp)
   Klaus Reifenrath (ScanSoft)
   Kristian Finlator (ScanSoft)
   Magnus Westerlund (Ericsson)
   Martin Dragomirecky (Cisco Systems, Inc.)
   Paolo Baggia (Loquendo)
   Peter Monaco (Nuance Communications)
   Pierre Forgues (Nuance Communications)

   Ran Zilca (IBM Corp)
   Suresh Kaliannan (Cisco Systems, Inc.)
   Skip Cave (Intervoice, Inc.)
   Thomas Gal (LumenVox)
```

SPEECHSC 작업 그룹의 의장은 Eric Burger\(조지타운 대학교\)와 Dave Oran\(시스코 시스템즈\)입니다.

특히 로버트 스파크스, 알렉스 아그라노프스키, 헨리 판에게 많은 감사를 전합니다. 그들은 마지막까지 모든 것을 꼼꼼히 체크하고 꼼꼼하게 준비했습니다.

---
# **Authors' Addresses**

```text
   Daniel C. Burnett
   Voxeo
   189 South Orange Avenue #1000
   Orlando, FL  32801
   USA

   EMail: dburnett@voxeo.com

   Saravanan Shanmugham
   Cisco Systems, Inc.
   170 W. Tasman Dr.
   San Jose, CA  95134
   USA

   EMail: sarvi@cisco.com
```